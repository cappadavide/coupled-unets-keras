{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setGPU: Setting GPU to: 0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import setGPU\n",
    "import gc\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "160\n",
      "240\n",
      "320\n",
      "96\n",
      "192\n",
      "288\n",
      "384\n",
      "112\n",
      "224\n",
      "336\n",
      "448\n",
      "128\n",
      "256\n",
      "384\n",
      "512\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 128, 128, 128 9600        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 128, 128, 128 512         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 128, 128, 128 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 128, 128, 64) 73728       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 128, 128, 64) 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 128, 128, 64) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 64, 64, 64)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 64, 64, 64)   256         max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 64, 64, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 64, 64, 64)   4096        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 64, 64, 64)   256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 64, 64, 64)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 64, 16)   9216        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 64, 64, 80)   0           max_pooling2d[0][0]              \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 64, 64, 80)   320         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 64, 64, 80)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 64)   5120        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 64)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 64)   256         max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 64)   4096        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 64)   256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 16)   9216        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 80)   0           max_pooling2d_1[0][0]            \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 80)   320         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 80)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 64)   5120        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 64)   0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 64)   256         max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 64)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 64)   4096        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 64)   256         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 64)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 16)   9216        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 16, 16, 80)   0           max_pooling2d_2[0][0]            \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 80)   320         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 80)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 64)   5120        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 64)     0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 8, 8, 64)     256         max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 8, 8, 64)     0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 8, 8, 64)     4096        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 8, 8, 64)     256         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 8, 8, 64)     0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 8, 8, 16)     9216        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 8, 8, 80)     0           max_pooling2d_3[0][0]            \n",
      "                                                                 conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 8, 8, 80)     320         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 8, 8, 80)     0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 8, 8, 64)     5120        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 4, 4, 64)     0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 4, 4, 64)     256         max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 4, 4, 64)     0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 4, 4, 64)     4096        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 4, 4, 64)     256         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 4, 4, 64)     0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 8, 8, 80)     320         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 4, 4, 16)     9216        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 8, 8, 80)     0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 4, 4, 80)     0           max_pooling2d_4[0][0]            \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 8, 8, 64)     5120        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 8, 8, 80)     0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 8, 8, 144)    0           conv2d_17[0][0]                  \n",
      "                                                                 up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 8, 8, 144)    576         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 8, 8, 144)    0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 8, 8, 64)     9216        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 8, 8, 64)     256         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 8, 8, 64)     0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 80)   320         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 8, 8, 16)     9216        activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 80)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 8, 8, 160)    0           concatenate_5[0][0]              \n",
      "                                                                 conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 64)   5120        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 16, 16, 160)  0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 16, 16, 224)  0           conv2d_13[0][0]                  \n",
      "                                                                 up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 16, 224)  896         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 224)  0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 16, 16, 64)   14336       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 64)   256         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 80)   320         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 16)   9216        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 80)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 16, 16, 240)  0           concatenate_7[0][0]              \n",
      "                                                                 conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 64)   5120        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 32, 32, 240)  0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 32, 32, 304)  0           conv2d_9[0][0]                   \n",
      "                                                                 up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 32, 32, 304)  1216        concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 32, 32, 304)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 32, 32, 64)   19456       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 32, 32, 64)   256         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 32, 32, 64)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 64, 64, 80)   320         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 32, 32, 16)   9216        activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 64, 64, 80)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 32, 32, 320)  0           concatenate_9[0][0]              \n",
      "                                                                 conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 64)   5120        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 64, 64, 320)  0           concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 64, 64, 384)  0           conv2d_5[0][0]                   \n",
      "                                                                 up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 64, 64, 384)  1536        concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 64, 64, 384)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 64, 64, 64)   24576       activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 64, 64, 64)   256         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 64, 64, 64)   0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 64, 64, 16)   9216        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 64, 64, 400)  0           concatenate_11[0][0]             \n",
      "                                                                 conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 64, 64, 464)  0           max_pooling2d[0][0]              \n",
      "                                                                 concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 64, 64, 464)  1856        concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 64, 64, 464)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 64, 64, 64)   29696       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 64, 64, 80)   0           conv2d_32[0][0]                  \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 64, 64, 80)   320         concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 64, 64, 80)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 64, 64, 64)   5120        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 64, 64, 64)   256         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 64, 64, 64)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 64, 64, 16)   9216        activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 64, 64, 96)   0           concatenate_14[0][0]             \n",
      "                                                                 conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 64, 64, 96)   384         concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 64, 64, 96)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 64, 64, 64)   6144        activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 32, 32, 64)   0           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 32, 32, 80)   0           max_pooling2d_5[0][0]            \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 32, 32, 80)   320         concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 32, 32, 80)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 32, 32, 64)   5120        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 32, 32, 64)   256         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 32, 32, 64)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 32, 32, 16)   9216        activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 32, 32, 96)   0           concatenate_16[0][0]             \n",
      "                                                                 conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 32, 32, 96)   384         concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 32, 32, 96)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 32, 32, 64)   6144        activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 16, 16, 64)   0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 16, 16, 80)   0           max_pooling2d_6[0][0]            \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 16, 16, 80)   320         concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 16, 16, 80)   0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 16, 16, 64)   5120        activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 16, 16, 64)   256         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 16, 16, 64)   0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 16, 16, 16)   9216        activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 16, 16, 96)   0           concatenate_18[0][0]             \n",
      "                                                                 conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 16, 16, 96)   384         concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 16, 16, 96)   0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 16, 16, 64)   6144        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 8, 8, 64)     0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 8, 8, 80)     0           max_pooling2d_7[0][0]            \n",
      "                                                                 conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 8, 8, 80)     320         concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 8, 8, 80)     0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 8, 8, 64)     5120        activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 8, 8, 64)     256         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 8, 8, 64)     0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 8, 8, 16)     9216        activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 8, 8, 96)     0           concatenate_20[0][0]             \n",
      "                                                                 conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 8, 8, 96)     384         concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 8, 8, 96)     0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 8, 8, 64)     6144        activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 4, 4, 64)     0           conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 4, 4, 80)     0           max_pooling2d_8[0][0]            \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 4, 4, 80)     320         concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 4, 4, 80)     0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 4, 4, 64)     5120        activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 4, 4, 64)     256         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 4, 4, 64)     0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 8, 8, 96)     384         concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 4, 4, 16)     9216        activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 8, 8, 96)     0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 4, 4, 96)     0           concatenate_22[0][0]             \n",
      "                                                                 conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 8, 8, 64)     6144        activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 8, 8, 96)     0           concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 8, 8, 176)    0           conv2d_48[0][0]                  \n",
      "                                                                 up_sampling2d_4[0][0]            \n",
      "                                                                 conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 8, 8, 176)    704         concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 8, 8, 176)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 8, 8, 64)     11264       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 8, 8, 64)     256         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 8, 8, 64)     0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 16, 16, 96)   384         concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 8, 8, 16)     9216        activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 16, 16, 96)   0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 8, 8, 192)    0           concatenate_24[0][0]             \n",
      "                                                                 conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 16, 16, 64)   6144        activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 16, 16, 192)  0           concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 16, 16, 272)  0           conv2d_44[0][0]                  \n",
      "                                                                 up_sampling2d_5[0][0]            \n",
      "                                                                 conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 16, 16, 272)  1088        concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 16, 16, 272)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 16, 16, 64)   17408       activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 16, 16, 64)   256         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 16, 16, 64)   0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 32, 32, 96)   384         concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 16, 16, 16)   9216        activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 32, 32, 96)   0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 16, 16, 288)  0           concatenate_26[0][0]             \n",
      "                                                                 conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 32, 32, 64)   6144        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2D)  (None, 32, 32, 288)  0           concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 32, 32, 368)  0           conv2d_40[0][0]                  \n",
      "                                                                 up_sampling2d_6[0][0]            \n",
      "                                                                 conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 32, 32, 368)  1472        concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 32, 32, 368)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 32, 32, 64)   23552       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 32, 32, 64)   256         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 32, 32, 64)   0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 64, 64, 96)   384         concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 32, 32, 16)   9216        activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 64, 64, 96)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 32, 32, 384)  0           concatenate_28[0][0]             \n",
      "                                                                 conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 64, 64, 64)   6144        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2D)  (None, 64, 64, 384)  0           concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 64, 64, 464)  0           conv2d_36[0][0]                  \n",
      "                                                                 up_sampling2d_7[0][0]            \n",
      "                                                                 conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 64, 64, 464)  1856        concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 64, 64, 464)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 64, 64, 64)   29696       activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 64, 64, 64)   256         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 64, 64, 64)   0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 64, 64, 16)   9216        activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 64, 64, 480)  0           concatenate_30[0][0]             \n",
      "                                                                 conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 64, 64, 544)  0           max_pooling2d[0][0]              \n",
      "                                                                 concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 64, 64, 544)  2176        concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 64, 64, 544)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 64, 64, 64)   34816       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 64, 64, 96)   0           conv2d_64[0][0]                  \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "                                                                 conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 64, 64, 96)   384         concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 64, 64, 96)   0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 64, 64, 64)   6144        activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 64, 64, 64)   256         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 64, 64, 64)   0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 64, 64, 16)   9216        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 64, 64, 112)  0           concatenate_33[0][0]             \n",
      "                                                                 conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 64, 64, 112)  448         concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 64, 64, 112)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 64, 64, 64)   7168        activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 32, 32, 64)   0           conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 32, 32, 96)   0           max_pooling2d_9[0][0]            \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "                                                                 conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 32, 32, 96)   384         concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 32, 32, 96)   0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 32, 32, 64)   6144        activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 32, 32, 64)   256         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 32, 32, 64)   0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 32, 32, 16)   9216        activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 32, 32, 112)  0           concatenate_35[0][0]             \n",
      "                                                                 conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 32, 32, 112)  448         concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 32, 32, 112)  0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 32, 32, 64)   7168        activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 16, 16, 64)   0           conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)    (None, 16, 16, 96)   0           max_pooling2d_10[0][0]           \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "                                                                 conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 16, 16, 96)   384         concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 16, 16, 96)   0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 16, 16, 64)   6144        activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 16, 16, 64)   256         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 16, 16, 64)   0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 16, 16, 16)   9216        activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)    (None, 16, 16, 112)  0           concatenate_37[0][0]             \n",
      "                                                                 conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 16, 16, 112)  448         concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 16, 16, 112)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 16, 16, 64)   7168        activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 8, 8, 64)     0           conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 8, 8, 96)     0           max_pooling2d_11[0][0]           \n",
      "                                                                 conv2d_15[0][0]                  \n",
      "                                                                 conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 8, 8, 96)     384         concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 8, 8, 96)     0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 8, 8, 64)     6144        activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 8, 8, 64)     256         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 8, 8, 64)     0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 8, 8, 16)     9216        activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 8, 8, 112)    0           concatenate_39[0][0]             \n",
      "                                                                 conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 8, 8, 112)    448         concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 8, 8, 112)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 8, 8, 64)     7168        activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 4, 4, 64)     0           conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 4, 4, 96)     0           max_pooling2d_12[0][0]           \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "                                                                 conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 4, 4, 96)     384         concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 4, 4, 96)     0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 4, 4, 64)     6144        activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 4, 4, 64)     256         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 4, 4, 64)     0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 8, 8, 112)    448         concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 4, 4, 16)     9216        activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 8, 8, 112)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)    (None, 4, 4, 112)    0           concatenate_41[0][0]             \n",
      "                                                                 conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 8, 8, 64)     7168        activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_8 (UpSampling2D)  (None, 8, 8, 112)    0           concatenate_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 8, 8, 208)    0           conv2d_80[0][0]                  \n",
      "                                                                 up_sampling2d_8[0][0]            \n",
      "                                                                 conv2d_22[0][0]                  \n",
      "                                                                 conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 8, 8, 208)    832         concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 8, 8, 208)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 8, 8, 64)     13312       activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 8, 8, 64)     256         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 8, 8, 64)     0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 16, 16, 112)  448         concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 8, 8, 16)     9216        activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 16, 16, 112)  0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 8, 8, 224)    0           concatenate_43[0][0]             \n",
      "                                                                 conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 16, 16, 64)   7168        activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_9 (UpSampling2D)  (None, 16, 16, 224)  0           concatenate_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 16, 16, 320)  0           conv2d_76[0][0]                  \n",
      "                                                                 up_sampling2d_9[0][0]            \n",
      "                                                                 conv2d_25[0][0]                  \n",
      "                                                                 conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 16, 16, 320)  1280        concatenate_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 16, 16, 320)  0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 16, 16, 64)   20480       activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 16, 16, 64)   256         conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 16, 16, 64)   0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 32, 32, 112)  448         concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 16, 16, 16)   9216        activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 32, 32, 112)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 16, 16, 336)  0           concatenate_45[0][0]             \n",
      "                                                                 conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 32, 32, 64)   7168        activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_10 (UpSampling2D) (None, 32, 32, 336)  0           concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 32, 32, 432)  0           conv2d_72[0][0]                  \n",
      "                                                                 up_sampling2d_10[0][0]           \n",
      "                                                                 conv2d_28[0][0]                  \n",
      "                                                                 conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 32, 32, 432)  1728        concatenate_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 32, 32, 432)  0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 32, 32, 64)   27648       activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 32, 32, 64)   256         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 32, 32, 64)   0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 64, 64, 112)  448         concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 32, 32, 16)   9216        activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 64, 64, 112)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_48 (Concatenate)    (None, 32, 32, 448)  0           concatenate_47[0][0]             \n",
      "                                                                 conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 64, 64, 64)   7168        activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_11 (UpSampling2D) (None, 64, 64, 448)  0           concatenate_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_49 (Concatenate)    (None, 64, 64, 544)  0           conv2d_68[0][0]                  \n",
      "                                                                 up_sampling2d_11[0][0]           \n",
      "                                                                 conv2d_31[0][0]                  \n",
      "                                                                 conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 64, 64, 544)  2176        concatenate_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 64, 64, 544)  0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 64, 64, 64)   34816       activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 64, 64, 64)   256         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 64, 64, 64)   0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 64, 64, 16)   9216        activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_50 (Concatenate)    (None, 64, 64, 560)  0           concatenate_49[0][0]             \n",
      "                                                                 conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_51 (Concatenate)    (None, 64, 64, 624)  0           max_pooling2d[0][0]              \n",
      "                                                                 concatenate_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 64, 64, 624)  2496        concatenate_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 64, 64, 624)  0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 64, 64, 64)   39936       activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_52 (Concatenate)    (None, 64, 64, 112)  0           conv2d_96[0][0]                  \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "                                                                 conv2d_34[0][0]                  \n",
      "                                                                 conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 64, 64, 112)  448         concatenate_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 64, 64, 112)  0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 64, 64, 64)   7168        activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 64, 64, 64)   256         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 64, 64, 64)   0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 64, 64, 16)   9216        activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_53 (Concatenate)    (None, 64, 64, 128)  0           concatenate_52[0][0]             \n",
      "                                                                 conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 64, 64, 128)  512         concatenate_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 64, 64, 128)  0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 64, 64, 64)   8192        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 32, 32, 64)   0           conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_54 (Concatenate)    (None, 32, 32, 112)  0           max_pooling2d_13[0][0]           \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "                                                                 conv2d_38[0][0]                  \n",
      "                                                                 conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 32, 32, 112)  448         concatenate_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 32, 32, 112)  0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 32, 32, 64)   7168        activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 32, 32, 64)   256         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 32, 32, 64)   0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 32, 32, 16)   9216        activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_55 (Concatenate)    (None, 32, 32, 128)  0           concatenate_54[0][0]             \n",
      "                                                                 conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 32, 32, 128)  512         concatenate_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 32, 32, 128)  0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 32, 32, 64)   8192        activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 16, 16, 64)   0           conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_56 (Concatenate)    (None, 16, 16, 112)  0           max_pooling2d_14[0][0]           \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "                                                                 conv2d_42[0][0]                  \n",
      "                                                                 conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 16, 16, 112)  448         concatenate_56[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 16, 16, 112)  0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 16, 16, 64)   7168        activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 16, 16, 64)   256         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 16, 16, 64)   0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 16, 16, 16)   9216        activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_57 (Concatenate)    (None, 16, 16, 128)  0           concatenate_56[0][0]             \n",
      "                                                                 conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 16, 16, 128)  512         concatenate_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 16, 16, 128)  0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 16, 16, 64)   8192        activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 8, 8, 64)     0           conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_58 (Concatenate)    (None, 8, 8, 112)    0           max_pooling2d_15[0][0]           \n",
      "                                                                 conv2d_15[0][0]                  \n",
      "                                                                 conv2d_46[0][0]                  \n",
      "                                                                 conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 8, 8, 112)    448         concatenate_58[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 8, 8, 112)    0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 8, 8, 64)     7168        activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 8, 8, 64)     256         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 8, 8, 64)     0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 8, 8, 16)     9216        activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_59 (Concatenate)    (None, 8, 8, 128)    0           concatenate_58[0][0]             \n",
      "                                                                 conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 8, 8, 128)    512         concatenate_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 8, 8, 128)    0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 8, 8, 64)     8192        activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, 4, 4, 64)     0           conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_60 (Concatenate)    (None, 4, 4, 112)    0           max_pooling2d_16[0][0]           \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "                                                                 conv2d_50[0][0]                  \n",
      "                                                                 conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 4, 4, 112)    448         concatenate_60[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 4, 4, 112)    0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 4, 4, 64)     7168        activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 4, 4, 64)     256         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 4, 4, 64)     0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 8, 8, 128)    512         concatenate_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 4, 4, 16)     9216        activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 8, 8, 128)    0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_61 (Concatenate)    (None, 4, 4, 128)    0           concatenate_60[0][0]             \n",
      "                                                                 conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 8, 8, 64)     8192        activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_12 (UpSampling2D) (None, 8, 8, 128)    0           concatenate_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_62 (Concatenate)    (None, 8, 8, 240)    0           conv2d_112[0][0]                 \n",
      "                                                                 up_sampling2d_12[0][0]           \n",
      "                                                                 conv2d_22[0][0]                  \n",
      "                                                                 conv2d_53[0][0]                  \n",
      "                                                                 conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 8, 8, 240)    960         concatenate_62[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 8, 8, 240)    0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 8, 8, 64)     15360       activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 8, 8, 64)     256         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 8, 8, 64)     0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 16, 16, 128)  512         concatenate_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 8, 8, 16)     9216        activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 16, 16, 128)  0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_63 (Concatenate)    (None, 8, 8, 256)    0           concatenate_62[0][0]             \n",
      "                                                                 conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 16, 16, 64)   8192        activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_13 (UpSampling2D) (None, 16, 16, 256)  0           concatenate_63[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_64 (Concatenate)    (None, 16, 16, 368)  0           conv2d_108[0][0]                 \n",
      "                                                                 up_sampling2d_13[0][0]           \n",
      "                                                                 conv2d_25[0][0]                  \n",
      "                                                                 conv2d_56[0][0]                  \n",
      "                                                                 conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 16, 16, 368)  1472        concatenate_64[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 16, 16, 368)  0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 16, 16, 64)   23552       activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 16, 16, 64)   256         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 16, 16, 64)   0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 32, 32, 128)  512         concatenate_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 16, 16, 16)   9216        activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 32, 32, 128)  0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_65 (Concatenate)    (None, 16, 16, 384)  0           concatenate_64[0][0]             \n",
      "                                                                 conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 32, 32, 64)   8192        activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_14 (UpSampling2D) (None, 32, 32, 384)  0           concatenate_65[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_66 (Concatenate)    (None, 32, 32, 496)  0           conv2d_104[0][0]                 \n",
      "                                                                 up_sampling2d_14[0][0]           \n",
      "                                                                 conv2d_28[0][0]                  \n",
      "                                                                 conv2d_59[0][0]                  \n",
      "                                                                 conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 32, 32, 496)  1984        concatenate_66[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 32, 32, 496)  0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 32, 32, 64)   31744       activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 32, 32, 64)   256         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 32, 32, 64)   0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 64, 64, 128)  512         concatenate_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 32, 32, 16)   9216        activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 64, 64, 128)  0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_67 (Concatenate)    (None, 32, 32, 512)  0           concatenate_66[0][0]             \n",
      "                                                                 conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 64, 64, 64)   8192        activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_15 (UpSampling2D) (None, 64, 64, 512)  0           concatenate_67[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_68 (Concatenate)    (None, 64, 64, 624)  0           conv2d_100[0][0]                 \n",
      "                                                                 up_sampling2d_15[0][0]           \n",
      "                                                                 conv2d_31[0][0]                  \n",
      "                                                                 conv2d_62[0][0]                  \n",
      "                                                                 conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 64, 64, 624)  2496        concatenate_68[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 64, 64, 624)  0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 64, 64, 64)   39936       activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 64, 64, 64)   256         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 64, 64, 64)   0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 64, 64, 16)   9216        activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_69 (Concatenate)    (None, 64, 64, 640)  0           concatenate_68[0][0]             \n",
      "                                                                 conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 64, 64, 480)  1920        concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 64, 64, 560)  2240        concatenate_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 64, 64, 640)  2560        concatenate_69[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 64, 64, 480)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 64, 64, 560)  0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 64, 64, 640)  0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 64, 64, 16)   7680        activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 64, 64, 16)   8960        activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 64, 64, 16)   10240       activation_127[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 1,294,272\n",
      "Trainable params: 1,261,344\n",
      "Non-trainable params: 32,928\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Definizione Modello\n",
    "def getUnit1(layerPrec, filters, kernel_size = (1, 1), activation='relu', kernel_initializer='he_normal'):\n",
    "  l = BatchNormalization()(layerPrec)\n",
    "  l = Activation('relu')(l)\n",
    "  l = Conv2D(filters, kernel_size, kernel_initializer=kernel_initializer, padding='same',use_bias=False)(l)\n",
    "  return l\n",
    "\n",
    "def getUnit2(layerPrec, filters, kernel_size = (3, 3), activation='relu', kernel_initializer='he_normal'):\n",
    "  l = BatchNormalization()(layerPrec)\n",
    "  l = Activation('relu')(l)\n",
    "  l = Conv2D(filters, kernel_size, kernel_initializer=kernel_initializer, padding='same',use_bias=False)(l)\n",
    "  return l\n",
    "\n",
    "def getDownBlock(layerPrec,m,n,indexBlock):\n",
    "  l = getUnit1(layerPrec,4*n)\n",
    "  l = getUnit2(l,n)\n",
    "  nets[\"layers\"][f\"down{indexBlock}\"].append(l)\n",
    "\n",
    "  concat = Concatenate()([layerPrec,l])\n",
    "  l = getUnit1(concat,m)\n",
    "  maxPooling = MaxPool2D(padding='same')(l)\n",
    "  return maxPooling, getUnit1(concat,m)\n",
    "\n",
    "def getUpBlock(layerPrec,skipConn,m,n,indexBlock,upLayers=[]):\n",
    "  l = getUnit1(layerPrec,m)\n",
    "  l = UpSampling2D()(layerPrec)\n",
    "  concat = Concatenate()([skipConn,l]+upLayers)\n",
    "  l = getUnit1(concat,4*n)\n",
    "  l = getUnit2(l,n)\n",
    "  nets[\"layers\"][f\"up{indexBlock}\"].append(l)\n",
    "  concat = Concatenate()([concat,l])\n",
    "  return concat\n",
    "\n",
    "def getUNet(input,m,n,indexUNet,nUNet, nBlocks):\n",
    "  layerPrec = input\n",
    "  listSkipConn = []\n",
    "\n",
    "  if indexUNet != 0:\n",
    "    layerPrec = nets[f\"unet{indexUNet-1}\"]\n",
    "    #layerPrec = Concatenate()([input,layerPrec]) #l'abbiamo fatto gi con l'if dopo l'up\n",
    "    layerPrec = getUnit1(layerPrec,m)\n",
    "\n",
    "  # down\n",
    "  for i in range(nBlocks):\n",
    "    if nets[\"layers\"][f\"down{i}\"]:\n",
    "        layerPrec = Concatenate()([layerPrec]+nets[\"layers\"][f\"down{i}\"])\n",
    "    layerPrec, skipConn = getDownBlock(layerPrec,m,n,i)\n",
    "    listSkipConn.append(skipConn)\n",
    "\n",
    "  # bottle neck\n",
    "  if nets[\"layers\"][f\"bn\"]:\n",
    "      layerPrec = Concatenate()([layerPrec]+nets[\"layers\"][f\"bn\"])\n",
    "\n",
    "  l = getUnit1(layerPrec,4*n)\n",
    "  l = getUnit2(l,n)\n",
    "  nets[\"layers\"][\"bn\"].append(l)\n",
    "  concat = Concatenate()([layerPrec,l])\n",
    "\n",
    "  # up\n",
    "  layerPrec = concat\n",
    "  for i in range(nBlocks):\n",
    "    layerPrec = getUpBlock(layerPrec,listSkipConn[-(i+1)],m,n,i,upLayers=nets[\"layers\"][f\"up{i}\"])\n",
    "\n",
    "\n",
    "  if indexUNet != nUNet - 1:\n",
    "    l = Concatenate()([input,layerPrec])\n",
    "  else:\n",
    "    l = getUnit1(layerPrec,16,activation=\"sigmoid\") #era linear\n",
    "    \n",
    "  inter = []\n",
    "  if indexUNet == 1 or indexUNet == 2:\n",
    "    inter.append(getUnit1(layerPrec,16,activation=\"sigmoid\"))\n",
    "  \n",
    "\n",
    "  return l, inter\n",
    "\n",
    "def trasformationInput(x, filters):\n",
    "  #x = BatchNormalization()(x)\n",
    "  #x = Activation('relu')(x)\n",
    "  #x = Conv2D(filters, kernel_size=(7,7), strides=(2,2), kernel_initializer=\"he_normal\", padding='same',use_bias=False)(x)\n",
    "  #maxPooling = MaxPool2D(padding='same')(x)\n",
    "  \n",
    "  x = Conv2D(filters*2, kernel_size=(5,5), strides=(1,1), kernel_initializer=\"he_normal\", padding='same',use_bias=False)(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = Conv2D(filters, kernel_size=(3,3), strides=(1,1), kernel_initializer=\"he_normal\", padding='same',use_bias=False)(x) #era 3x3\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = MaxPool2D(padding='same')(x)\n",
    "\n",
    "  return x#maxPooling\n",
    "\n",
    "def getCUNet(shape,m,n,nUNet,nBlocks):\n",
    "  for i in range(nUNet):\n",
    "    nets[f\"unet{i}\"] = None\n",
    "\n",
    "  for j in range(nBlocks):\n",
    "    nets[\"layers\"][f\"down{j}\"] = []\n",
    "    nets[\"layers\"][f\"up{j}\"] = []\n",
    "    \n",
    "  input = Input(shape=shape)\n",
    "  \n",
    "  t_input = trasformationInput(input,m) # per le heatmap da 64x64\n",
    "\n",
    "  output = []\n",
    "  for i in range(nUNet):\n",
    "    nets[f\"unet{i}\"],inter = getUNet(t_input,m,n,i,nUNet,nBlocks)\n",
    "    if inter is not None:\n",
    "        output.extend(inter)\n",
    "  output.append(nets[f\"unet{nUNet-1}\"])\n",
    "\n",
    "  return Model(inputs=input, outputs=output)\n",
    "\n",
    "nets = {}\n",
    "nets[\"layers\"] = {}\n",
    "nets[\"layers\"][\"bn\"] = []\n",
    "shape = (128,128,3)\n",
    "m = 64\n",
    "n = 16\n",
    "nUNet = 4\n",
    "nBlocks = 4\n",
    "#mirrored_strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\n",
    "#with mirrored_strategy.scope():\n",
    "net = getCUNet(shape,m,n,nUNet,nBlocks)\n",
    "\n",
    "layers = net.layers\n",
    "#print(layers[57].input)\n",
    "for i in range(len(layers)):\n",
    "    if isinstance(layers[i], tf.python.keras.layers.convolutional.Conv2D):\n",
    "        if isinstance(layers[i-1].input,list):\n",
    "            in_chan = 0\n",
    "            for k in layers[i-1].input:\n",
    "                in_chan = in_chan + k.shape[-1]\n",
    "            print(in_chan)\n",
    "        else:\n",
    "            in_chan = layers[i-1].input.shape[-1]\n",
    "            \n",
    "        n1 = layers[i].kernel_size[0] * layers[i].kernel_size[1] * in_chan\n",
    "        stdv = 1/math.sqrt(n1)\n",
    "        layers[i].kernel_initializer = tf.keras.initializers.RandomUniform(minval=-stdv, maxval=stdv)\n",
    "\n",
    "net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_preds(heatmaps):\n",
    "    \"\"\"Get keypoint predictions from score maps.\n",
    "    Note:\n",
    "        batch_size: N\n",
    "        num_keypoints: K\n",
    "        heatmap height: H\n",
    "        heatmap width: W\n",
    "    Args:\n",
    "        heatmaps (np.ndarray[N, K, H, W]): model predicted heatmaps.\n",
    "    Returns:\n",
    "        tuple: A tuple containing aggregated results.\n",
    "        - preds (np.ndarray[N, K, 2]): Predicted keypoint location.  \n",
    "        - maxvals (np.ndarray[N, K, 1]): Scores (confidence) of the keypoints. non lo restituiamo\n",
    "    \"\"\"\n",
    "    #assert isinstance(heatmaps, np.ndarray), ('heatmaps should be numpy.ndarray')\n",
    "    #assert heatmaps.ndim == 4, 'batch_images should be 4-ndim'\n",
    "\n",
    "    N, K, _, W = heatmaps.shape\n",
    "    heatmaps_reshaped = heatmaps.reshape((N, K, -1))\n",
    "    idx = np.argmax(heatmaps_reshaped, 2).reshape((N, K, 1))\n",
    "    maxvals = np.amax(heatmaps_reshaped, 2).reshape((N, K, 1))\n",
    "\n",
    "    preds = np.tile(idx, (1, 1, 2)).astype(np.float32)\n",
    "    preds[:, :, 0] = preds[:, :, 0] % W\n",
    "    preds[:, :, 1] = preds[:, :, 1] // W\n",
    "\n",
    "    preds = np.where(np.tile(maxvals, (1, 1, 2)) > 0.0, preds, -1)\n",
    "    return preds#, maxvals\n",
    "\n",
    "def calc_dists(preds, target, normalize, use_zero=False):\n",
    "    preds = preds.astype(np.float32)\n",
    "    target = target.astype(np.float32)\n",
    "    normalize = normalize.astype(np.float32)\n",
    "    dists = np.zeros((preds.shape[1], preds.shape[0]))\n",
    "    if use_zero:\n",
    "        boundary = 0\n",
    "    else:\n",
    "        boundary = 1\n",
    "    for n in range(preds.shape[0]):\n",
    "        for c in range(preds.shape[1]):\n",
    "            if target[n,c,0] > boundary and target[n, c, 1] > boundary:\n",
    "                dists[c, n] = np.linalg.norm((preds[n,c,:]- target[n,c,:])/normalize[n]) # axis ricavato da solo\n",
    "            else:\n",
    "                dists[c, n] = -1\n",
    "    return dists\n",
    "\n",
    "def dist_acc(dists, thr=0.5):\n",
    "\n",
    "  #Return percentage below threshold while ignoring values with a -1\n",
    "\n",
    "  if (dists!=-1).sum() > 0:\n",
    "\n",
    "    return ((dists<=thr) == (dists!=-1)).sum().astype(np.float32) / (dists!=-1).sum().astype(np.float32)\n",
    "\n",
    "  else:\n",
    "\n",
    "    return -1\n",
    "\n",
    "def accuracy(output, target, thr=0.5):\n",
    "  ''' Calculate accuracy according to PCK, but uses ground truth heatmap rather than x,y locations\n",
    "        First value to be returned is average accuracy across 'idxs', followed by individual accuracies\n",
    "    '''\n",
    "  #output = output.numpy()\n",
    "  #print(output.__class__)\n",
    "  #target = target.numpy()\n",
    "\n",
    "  idkp = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "  preds = get_max_preds(output)\n",
    "  gts = get_max_preds(target)\n",
    "  norm = np.ones(preds.shape[0])*output.shape[3]/10\n",
    "\n",
    "  dists = calc_dists(preds, gts, norm)\n",
    "\n",
    "  acc = np.zeros(len(idkp)+1)\n",
    "  avg_acc = 0\n",
    "  cnt = 0\n",
    "\n",
    "  for i in range(len(idkp)):\n",
    "    acc[i+1] = dist_acc(dists[idkp[i]])\n",
    "    if acc[i+1] >= 0: \n",
    "      avg_acc = avg_acc + acc[i+1]\n",
    "      cnt += 1\n",
    "            \n",
    "  if cnt != 0:  \n",
    "    acc[0] = avg_acc / cnt\n",
    "\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.misc\n",
    "import cv2\n",
    "\n",
    "# =============================================================================\n",
    "# General image processing functions\n",
    "# =============================================================================\n",
    "\n",
    "def get_transform(center, scale, res, rot=0):\n",
    "    # Generate transformation matrix\n",
    "    h = 200 * scale\n",
    "    t = np.zeros((3, 3))\n",
    "    t[0, 0] = float(res[1]) / h\n",
    "    t[1, 1] = float(res[0]) / h\n",
    "    t[0, 2] = res[1] * (-float(center[0]) / h + .5)\n",
    "    t[1, 2] = res[0] * (-float(center[1]) / h + .5)\n",
    "    t[2, 2] = 1\n",
    "    if not rot == 0:\n",
    "        rot = -rot # To match direction of rotation from cropping\n",
    "        rot_mat = np.zeros((3,3))\n",
    "        rot_rad = rot * np.pi / 180\n",
    "        sn,cs = np.sin(rot_rad), np.cos(rot_rad)\n",
    "        rot_mat[0,:2] = [cs, -sn]\n",
    "        rot_mat[1,:2] = [sn, cs]\n",
    "        rot_mat[2,2] = 1\n",
    "        # Need to rotate around center\n",
    "        t_mat = np.eye(3)\n",
    "        t_mat[0,2] = -res[1]/2\n",
    "        t_mat[1,2] = -res[0]/2\n",
    "        t_inv = t_mat.copy()\n",
    "        t_inv[:2,2] *= -1\n",
    "        t = np.dot(t_inv,np.dot(rot_mat,np.dot(t_mat,t)))\n",
    "    return t\n",
    "\n",
    "def transform(pt, center, scale, res, invert=0, rot=0):\n",
    "    # Transform pixel location to different reference\n",
    "    t = get_transform(center, scale, res, rot=rot)\n",
    "    if invert:\n",
    "        t = np.linalg.inv(t)\n",
    "    new_pt = np.array([pt[0], pt[1], 1.]).T\n",
    "    new_pt = np.dot(t, new_pt)\n",
    "    return new_pt[:2].astype(int)\n",
    "\n",
    "def crop(img, center, scale, res, rot=0):\n",
    "    # Upper left point\n",
    "    ul = np.array(transform([0, 0], center, scale, res, invert=1))\n",
    "    # Bottom right point\n",
    "    br = np.array(transform(res, center, scale, res, invert=1))\n",
    "\n",
    "    new_shape = [br[1] - ul[1], br[0] - ul[0]]\n",
    "    if len(img.shape) > 2:\n",
    "        new_shape += [img.shape[2]]\n",
    "    new_img = np.zeros(new_shape)\n",
    "\n",
    "    # Range to fill new array\n",
    "    new_x = max(0, -ul[0]), min(br[0], len(img[0])) - ul[0]\n",
    "    new_y = max(0, -ul[1]), min(br[1], len(img)) - ul[1]\n",
    "    # Range to sample from original image\n",
    "    old_x = max(0, ul[0]), min(len(img[0]), br[0])\n",
    "    old_y = max(0, ul[1]), min(len(img), br[1])\n",
    "    new_img[new_y[0]:new_y[1], new_x[0]:new_x[1]] = img[old_y[0]:old_y[1], old_x[0]:old_x[1]]\n",
    "\n",
    "    return cv2.resize(new_img, res)\n",
    "\n",
    "def inv_mat(mat):\n",
    "    ans = np.linalg.pinv(np.array(mat).tolist() + [[0,0,1]])\n",
    "    return ans[:2]\n",
    "\n",
    "def kpt_affine(kpt, mat):\n",
    "    kpt = np.array(kpt)\n",
    "    shape = kpt.shape\n",
    "    kpt = kpt.reshape(-1, 2)\n",
    "    return np.dot( np.concatenate((kpt, kpt[:, 0:1]*0+1), axis = 1), mat.T ).reshape(shape)\n",
    "\n",
    "\n",
    "def resize(im, res):\n",
    "    return np.array([cv2.resize(im[i],res) for i in range(im.shape[0])])\n",
    "\n",
    "def generateHeatmap(keypoints,output_res,num_parts):\n",
    "    #Init\n",
    "    sigma = output_res/64\n",
    "    size = 6*sigma+3\n",
    "    x = np.arange(0, size, 1, float) #crea un array composto da nove 1.0 vettore 1-D (9,)\n",
    "    y = x[:, np.newaxis] #Vettore 2-D (9,1)\n",
    "    x0, y0 = 3*sigma + 1, 3*sigma + 1 #vedi gi a tutto\n",
    "    g = np.exp(- ((x - x0) ** 2 + (y - y0) ** 2) / (2 * sigma ** 2))\n",
    "    #Generation\n",
    "    hms = np.zeros(shape = (num_parts, output_res, output_res), dtype = np.float32) #crea vettore (16,64,64), cio 16 heatmaps nere\n",
    "    for p in keypoints:\n",
    "        for idx, pt in enumerate(p): #ottiene id + [x,y] di ogni keypoint\n",
    "            if pt[0] > 0: \n",
    "                x, y = int(pt[0]), int(pt[1])\n",
    "                if x<0 or y<0 or x>=output_res or y>=output_res: #se succede questo, rimane heatmap idx-esima  tutta a 0\n",
    "                    continue\n",
    "                ul = int(x - 3*sigma - 1), int(y - 3*sigma - 1)\n",
    "                br = int(x + 3*sigma + 2), int(y + 3*sigma + 2)\n",
    "\n",
    "                c,d = max(0, -ul[0]), min(br[0], output_res) - ul[0]\n",
    "                a,b = max(0, -ul[1]), min(br[1], output_res) - ul[1]\n",
    "\n",
    "                cc,dd = max(0, ul[0]), min(br[0], output_res)\n",
    "                aa,bb = max(0, ul[1]), min(br[1], output_res)\n",
    "                hms[idx, aa:bb,cc:dd] = np.maximum(hms[idx, aa:bb,cc:dd], g[a:b,c:d])\n",
    "    return hms\n",
    "def getImgHms(img,c,s,keypoints,inp_res=(256,256),out_res=(64,64)):\n",
    "    cropped = crop(img,c,s,inp_res)\n",
    "    orig_keypoints = []\n",
    "    for i in keypoints:\n",
    "        orig_keypoints.append(np.array([i[\"x\"],i[\"y\"]]))\n",
    "    orig_keypoints = np.array(orig_keypoints).reshape((1,16,2))\n",
    "    kptmp = np.copy(orig_keypoints)\n",
    "    for i in range(orig_keypoints.shape[1]):\n",
    "        if orig_keypoints[0,i,0] > 0:\n",
    "            orig_keypoints[0,i,:2] = transform(orig_keypoints[0,i,:2], c, s, inp_res)\n",
    "    keypoints = np.copy(orig_keypoints)\n",
    "    h, w = cropped.shape[0:2]\n",
    "    center = np.array((w/2,h/2))\n",
    "    scale = max(h,w)/200\n",
    "    aug_rot = (np.random.random()*2-1)*30\n",
    "    aug_scale = np.random.random() * (1.25-0.75)+0.75\n",
    "    scale *= aug_scale\n",
    "\n",
    "    mat_mask = get_transform(center, scale, out_res, aug_rot)[:2]\n",
    "    mat = get_transform(center, scale, inp_res, aug_rot)[:2]\n",
    "    inp = cv2.warpAffine(cropped, mat, inp_res).astype(np.float32)/255\n",
    "\n",
    "    keypoints[:,:,0:2] = kpt_affine(keypoints[:,:,0:2], mat_mask) \n",
    "    \n",
    "    #print('\\n')\n",
    "\n",
    "\n",
    "    #Flip 50% probability\n",
    "    if np.random.randint(2) == 0:\n",
    "        inp = inp[:, ::-1]\n",
    "        keypoints = keypoints[:, flipped_parts['mpii']]\n",
    "        keypoints[:, :, 0] = 64 - keypoints[:, :, 0]\n",
    "        orig_keypoints = orig_keypoints[:, flipped_parts['mpii']]\n",
    "        orig_keypoints[:, :, 0] = 256 - orig_keypoints[:, :, 0]\n",
    "\n",
    "    ## set keypoints to 0 when were not visible initially (so heatmap all 0s)\n",
    "        for i in range(np.shape(orig_keypoints)[1]):\n",
    "            if kptmp[0,i,0] == 0 and kptmp[0,i,1] == 0:\n",
    "                keypoints[0,i,0] = 0\n",
    "                keypoints[0,i,1] = 0\n",
    "                orig_keypoints[0,i,0] = 0\n",
    "                orig_keypoints[0,i,1] = 0\n",
    "\n",
    "    heatmaps = generateHeatmap(keypoints,out_res[0],16)\n",
    "    return inp,heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = tf.keras.optimizers.RMSprop(\n",
    "#    learning_rate=6.7e-3, rho=0.99, momentum=0.0, epsilon=1e-08\n",
    "#)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=6.7e-3)\n",
    "\n",
    "\n",
    "def heatmapLoss(y_true,y_pred):\n",
    "    l = tf.math.square((y_pred - y_true))\n",
    "    l = tf.reduce_mean(l,axis=3)\n",
    "    l = tf.reduce_mean(l,axis=2)\n",
    "    l = tf.reduce_mean(l,axis=1)\n",
    "    return l\n",
    "\n",
    "def euclidean_loss(y_true, y_pred):\n",
    "    return K.sqrt(K.sum(K.square(y_true - y_pred)))\n",
    "\n",
    "def dice(y_true,y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + 1) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1 - dice(y_true, y_pred)\n",
    "\n",
    "def weighted_mse_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    apply weights on heatmap mse loss to only pick valid keypoint heatmap\n",
    "    since y_true would be gt_heatmap with shape\n",
    "    (batch_size, heatmap_size[0], heatmap_size[1], num_keypoints)\n",
    "    we sum up the heatmap for each keypoints and check. Sum for invalid\n",
    "    keypoint would be 0, so we can get a keypoint weights tensor with shape\n",
    "    (batch_size, 1, 1, num_keypoints)\n",
    "    and multiply to loss\n",
    "    \"\"\"\n",
    "    heatmap_sum = K.sum(K.sum(y_true, axis=1, keepdims=True), axis=2, keepdims=True)\n",
    "\n",
    "    # keypoint_weights shape: (batch_size, 1, 1, num_keypoints), with\n",
    "    # valid_keypoint = 1.0, invalid_keypoint = 0.0\n",
    "    keypoint_weights = 1.0 - K.cast(K.equal(heatmap_sum, 0.0), 'float32')\n",
    "\n",
    "    return K.sqrt(K.mean(K.square((y_true - y_pred) * keypoint_weights)))\n",
    "\n",
    "def smooth_l1_loss(y_true, y_pred):\n",
    "    diff = K.abs(y_true - y_pred)\n",
    "    less_than_one = K.cast(K.less(diff, 1.0), 'float32')\n",
    "    loss = (less_than_one * 0.5 * diff**2) + (1 - less_than_one) * (diff - 0.5)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "parts = {'mpii':['rank', 'rkne', 'rhip',\n",
    "                 'lhip', 'lkne', 'lank',\n",
    "                 'pelv', 'thrx', 'neck', 'head',\n",
    "                 'rwri', 'relb', 'rsho',\n",
    "                 'lsho', 'lelb', 'lwri']}\n",
    "\n",
    "flipped_parts = {'mpii':[5, 4, 3, 2, 1, 0, 6, 7, 8, 9, 15, 14, 13, 12, 11, 10]}\n",
    "\n",
    "part_pairs = {'mpii':[[0, 5], [1, 4], [2, 3], [6], [7], [8], [9], [10, 15], [11, 14], [12, 13]]}\n",
    "\n",
    "pair_names = {'mpii':['ankle', 'knee', 'hip', 'pelvis', 'thorax', 'neck', 'head', 'wrist', 'elbow', 'shoulder']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import imageio\n",
    "\n",
    "class Dataset(tf.keras.utils.Sequence):\n",
    "    #Costruttore\n",
    "    def __init__(self,json_path,batch_size,input_shape=(256,256,3),output_shape=(64,64,16),train=True,dataset_name=\"MPII\"):\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "        self.batch_size = batch_size\n",
    "        f = open(json_path)\n",
    "        self.dataset = json.load(f)\n",
    "        if dataset_name == \"MPII\":\n",
    "            self.dataset = self.dataset[\"dataset\"][\"MPII\"][\"people\"]\n",
    "        if train:\n",
    "            self.dataset = self.dataset[:-7221]\n",
    "        self.batch_images = np.zeros(shape=((self.batch_size,)+(self.input_shape)), dtype=np.float32)\n",
    "        self.batch_heatmaps = np.zeros(shape=((self.batch_size,)+(self.output_shape)), dtype=np.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset) // self.batch_size\n",
    "    \n",
    "    def __getitem__(self,i):\n",
    "        for n, annotation in enumerate(self.dataset[i*self.batch_size:(i+1)*self.batch_size]):\n",
    "            #sample_index = i*self.batch_size + n\n",
    "            image, gt_heatmap = self.extract_imgs_hms(annotation)\n",
    "            gt_heatmap = np.transpose(gt_heatmap,(1,2,0))\n",
    "            self.batch_images[n,:,:,:] = image\n",
    "            self.batch_heatmaps[n, :, :, :] = gt_heatmap#gt_heatmap.reshape((self.output_shape))\n",
    "            \n",
    "        return self.batch_images, self.batch_heatmaps\n",
    "#getImgHms(img,c,s,keypoints,inp_res=(256,256),out_res=(64,64)):\n",
    "    \n",
    "    def extract_imgs_hms(self,annotation):\n",
    "        inp_res = self.input_shape[0:2]\n",
    "        out_res = self.output_shape[0:2]\n",
    "        img = imageio.imread(f\"../images_mpii/{annotation['filepath']}\")\n",
    "        c = [annotation[\"objpos\"][\"x\"],annotation[\"objpos\"][\"y\"]]\n",
    "        s = annotation[\"scale\"]\n",
    "        keypoints = annotation[\"keypoints\"]\n",
    "        cropped = crop(img,c,s,inp_res)\n",
    "        \n",
    "        orig_keypoints = []\n",
    "        for i in keypoints:\n",
    "            orig_keypoints.append(np.array([i[\"x\"],i[\"y\"]]))\n",
    "        orig_keypoints = np.array(orig_keypoints).reshape((1,16,2))\n",
    "        kptmp = np.copy(orig_keypoints)\n",
    "        for i in range(orig_keypoints.shape[1]):\n",
    "            if orig_keypoints[0,i,0] > 0:\n",
    "                orig_keypoints[0,i,:2] = transform(orig_keypoints[0,i,:2], c, s, inp_res)\n",
    "        keypoints = np.copy(orig_keypoints)\n",
    "        h, w = cropped.shape[0:2]\n",
    "        center = np.array((w/2,h/2))\n",
    "        scale = max(h,w)/200\n",
    "        aug_rot = (np.random.random()*2-1)*30\n",
    "        aug_scale = np.random.random() * (1.25-0.75)+0.75\n",
    "        scale *= aug_scale\n",
    "\n",
    "        mat_mask = get_transform(center, scale, out_res, aug_rot)[:2]\n",
    "        mat = get_transform(center, scale, inp_res, aug_rot)[:2]\n",
    "        inp = cv2.warpAffine(cropped, mat, inp_res).astype(np.float32)/255\n",
    "\n",
    "        keypoints[:,:,0:2] = kpt_affine(keypoints[:,:,0:2], mat_mask) \n",
    "\n",
    "        #print('\\n')\n",
    "\n",
    "\n",
    "        #Flip 50% probability\n",
    "        if np.random.randint(2) == 0:\n",
    "            inp = inp[:, ::-1]\n",
    "            keypoints = keypoints[:, flipped_parts['mpii']]\n",
    "            keypoints[:, :, 0] = 64 - keypoints[:, :, 0]\n",
    "            orig_keypoints = orig_keypoints[:, flipped_parts['mpii']]\n",
    "            orig_keypoints[:, :, 0] = 256 - orig_keypoints[:, :, 0]\n",
    "\n",
    "        ## set keypoints to 0 when were not visible initially (so heatmap all 0s)\n",
    "            for i in range(np.shape(orig_keypoints)[1]):\n",
    "                if kptmp[0,i,0] == 0 and kptmp[0,i,1] == 0:\n",
    "                    keypoints[0,i,0] = 0\n",
    "                    keypoints[0,i,1] = 0\n",
    "                    orig_keypoints[0,i,0] = 0\n",
    "                    orig_keypoints[0,i,1] = 0\n",
    "\n",
    "        heatmaps = generateHeatmap(keypoints,out_res[0],16)\n",
    "        return inp,heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import imageio\n",
    "\n",
    "class Dataset2(tf.keras.utils.Sequence):\n",
    "    #Costruttore\n",
    "    def __init__(self,json_path,batch_size,input_shape=(256,256,3),output_shape=(64,64,16),train=True,dataset_name=\"MPII\"):\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "        self.batch_size = batch_size\n",
    "        self.images = np.load(\"../imgs_mpii.npz\")['arr_0']\n",
    "        self.hms = np.load(\"../hms_mpii.npz\")['arr_0']\n",
    "        self.hms = self.hms.reshape((self.hms.shape[0],64,64,16))\n",
    "        if dataset_name == \"MPII\":\n",
    "            self.images = self.images[\"dataset\"][\"MPII\"][\"people\"]\n",
    "        if train:\n",
    "            self.images = self.images[:-8665]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset) // self.batch_size\n",
    "    \n",
    "    def __getitem__(self,i):\n",
    "        return self.images[i*self.batch_size:(i+1)*self.batch_size], self.hms[i*self.batch_size:(i+1)*self.batch_size]\n",
    "#getImgHms(img,c,s,keypoints,inp_res=(256,256),out_res=(64,64)):\n",
    "    \n",
    "    def extract_imgs_hms(self,annotation):\n",
    "        inp_res = self.input_shape[0:2]\n",
    "        out_res = self.output_shape[0:2]\n",
    "        img = imageio.imread(f\"../images_mpii/{annotation['filepath']}\")\n",
    "        c = [annotation[\"objpos\"][\"x\"],annotation[\"objpos\"][\"y\"]]\n",
    "        s = annotation[\"scale\"]\n",
    "        keypoints = annotation[\"keypoints\"]\n",
    "        cropped = crop(img,c,s,inp_res)\n",
    "        \n",
    "        orig_keypoints = []\n",
    "        for i in keypoints:\n",
    "            orig_keypoints.append(np.array([i[\"x\"],i[\"y\"]]))\n",
    "        orig_keypoints = np.array(orig_keypoints).reshape((1,16,2))\n",
    "        kptmp = np.copy(orig_keypoints)\n",
    "        for i in range(orig_keypoints.shape[1]):\n",
    "            if orig_keypoints[0,i,0] > 0:\n",
    "                orig_keypoints[0,i,:2] = transform(orig_keypoints[0,i,:2], c, s, inp_res)\n",
    "        keypoints = np.copy(orig_keypoints)\n",
    "        h, w = cropped.shape[0:2]\n",
    "        center = np.array((w/2,h/2))\n",
    "        scale = max(h,w)/200\n",
    "        aug_rot = (np.random.random()*2-1)*30\n",
    "        aug_scale = np.random.random() * (1.25-0.75)+0.75\n",
    "        scale *= aug_scale\n",
    "\n",
    "        mat_mask = get_transform(center, scale, out_res, aug_rot)[:2]\n",
    "        mat = get_transform(center, scale, inp_res, aug_rot)[:2]\n",
    "        inp = cv2.warpAffine(cropped, mat, inp_res).astype(np.float32)/255\n",
    "\n",
    "        keypoints[:,:,0:2] = kpt_affine(keypoints[:,:,0:2], mat_mask) \n",
    "\n",
    "        #print('\\n')\n",
    "\n",
    "\n",
    "        #Flip 50% probability\n",
    "        if np.random.randint(2) == 0:\n",
    "            inp = inp[:, ::-1]\n",
    "            keypoints = keypoints[:, flipped_parts['mpii']]\n",
    "            keypoints[:, :, 0] = 64 - keypoints[:, :, 0]\n",
    "            orig_keypoints = orig_keypoints[:, flipped_parts['mpii']]\n",
    "            orig_keypoints[:, :, 0] = 256 - orig_keypoints[:, :, 0]\n",
    "\n",
    "        ## set keypoints to 0 when were not visible initially (so heatmap all 0s)\n",
    "            for i in range(np.shape(orig_keypoints)[1]):\n",
    "                if kptmp[0,i,0] == 0 and kptmp[0,i,1] == 0:\n",
    "                    keypoints[0,i,0] = 0\n",
    "                    keypoints[0,i,1] = 0\n",
    "                    orig_keypoints[0,i,0] = 0\n",
    "                    orig_keypoints[0,i,1] = 0\n",
    "\n",
    "        heatmaps = generateHeatmap(keypoints,out_res[0],16)\n",
    "        return inp,heatmaps\n",
    "####################################################################\n",
    "\n",
    "\n",
    "def get_normalize(input_shape):\n",
    "    \"\"\"\n",
    "    rescale keypoint distance normalize coefficient\n",
    "    based on input shape, used for PCK evaluation\n",
    "    NOTE: 6.4 is standard normalize coefficient under\n",
    "          input shape (256,256)\n",
    "    # Arguments\n",
    "        input_shape: input image shape as (height, width)\n",
    "    # Returns\n",
    "        scale: normalize coefficient\n",
    "    \"\"\"\n",
    "    #assert input_shape[0] == input_shape[1], 'only support square input shape.'\n",
    "\n",
    "    # use averaged scale factor for non square input shape\n",
    "    scale = float((input_shape[0] + input_shape[1]) / 2) / 256.0\n",
    "\n",
    "    return 6.4*scale\n",
    "\n",
    "global_best_acc = 0.0\n",
    "\n",
    "class EvalCallBack(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, model_input_shape, fileName, imgs,hms):\n",
    "        self.normalize = get_normalize(model_input_shape)\n",
    "        self.model_input_shape = model_input_shape\n",
    "        self.best_acc = 0.0\n",
    "        self.fileName = fileName\n",
    "        self.eval_images = imgs#np.load(\"../imgs_val_mpii128.npz\")['arr_0']\n",
    "        self.eval_hms = hms#np.load(\"../hms_val_mpii128.npz\")['arr_0']\n",
    "        self.listAcc = []\n",
    "        #self.eval_hms = np.reshape(self.eval_hms,(self.eval_hms.shape[0],64,64,16))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        global global_best_acc\n",
    "        output = []\n",
    "        #for i in range(self.eval_images.shape[0]):\n",
    "            #output.append(self.model.predict(self.eval_images[i:i+1])[2])\n",
    "        output.append(self.model.predict(self.eval_images[0:2407])[2])\n",
    "        output.append(self.model.predict(self.eval_images[2407:4814])[2])\n",
    "        output.append(self.model.predict(self.eval_images[4814:7221])[2])\n",
    "        ##output = self.model.predict(self.eval_images)[2]\n",
    "        output = np.array(output)\n",
    "        print(output.shape)\n",
    "        output = output.reshape((7221,64,64,16))\n",
    "        print(output.shape)\n",
    "        output = np.transpose(output,(0,3,1,2))\n",
    "        val_acc = accuracy(output,self.eval_hms)\n",
    "        self.listAcc.append(val_acc[0])\n",
    "        print('\\nvalidate accuracy:\\n', val_acc, '@epoch', epoch)\n",
    "        f = open(self.fileName, \"a\")\n",
    "        if val_acc[0] > self.best_acc:\n",
    "            # Save best accuray value and model checkpoint\n",
    "            #checkpoint_dir = os.path.join(self.log_dir, 'ep{epoch:03d}-loss{loss:.3f}-val_acc{val_acc:.3f}.h5'.format(epoch=(epoch+1), loss=logs.get('loss'), val_acc=val_acc))\n",
    "            #self.model.save(f\"../modelsave/ep{epoch}_acc{val_acc[0]}.h5\")\n",
    "            self.model.save_weights(f\"../cunet{nUNet}_{m}{n}_best_sigmoidAdamQuasiDef3sx12_restartsig8_4_6416_2S.h5\")\n",
    "            print('Epoch {epoch:03d}: val_acc improved from {best_acc:.3f} to {val_acc:.3f}'.format(epoch=epoch+1, best_acc=self.best_acc, val_acc=val_acc[0]))# checkpoint_dir=checkpoint_dir))\n",
    "            message = 'Epoch {epoch:03d}: val_acc improved from {best_acc:.3f} to {val_acc:.3f}. Train loss is {loss:.3f}\\n'.format(epoch=epoch+1, best_acc=self.best_acc, val_acc=val_acc[0],loss=logs.get('loss'))\n",
    "            self.best_acc = val_acc[0]\n",
    "            global_best_acc = val_acc[0]\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            message = 'Epoch {epoch:03d}: val_acc did not improve from {best_acc:.3f}. Train loss is {loss:.3f}\\n'.format(epoch=epoch+1, best_acc=self.best_acc,loss=logs.get('loss'))\n",
    "            print('Epoch {epoch:03d}: val_acc did not improve from {best_acc:.3f}'.format(epoch=epoch+1, best_acc=self.best_acc))\n",
    "        f.write(message)\n",
    "        f.close()\n",
    "        if epoch == 200:\n",
    "            np.savez_compressed(f'../cunet{nUNet}_{m}{n}_best_sigmoidAdamQuasiDef3sx12_restartsig8_4_6416_2S_accs', self.listAcc)\n",
    "        gc.collect()\n",
    "        \n",
    "        \n",
    "class CustomLearningRateScheduler(tf.keras.callbacks.Callback):\n",
    "    \"\"\"Learning rate scheduler which sets the learning rate according to schedule.\n",
    "\n",
    "  Arguments:\n",
    "      schedule: a function that takes an epoch index\n",
    "          (integer, indexed from 0) and current learning rate\n",
    "          as inputs and returns a new learning rate as output (float).\n",
    "  \"\"\"\n",
    "\n",
    "    def __init__(self, patience,factor,fileName=None):\n",
    "        super(CustomLearningRateScheduler, self).__init__()\n",
    "        self.counter = 0\n",
    "        self.patience = patience\n",
    "        self.fileName = fileName\n",
    "        self.factor = factor\n",
    "        self.best_acc = 0.0\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        global global_best_acc\n",
    "        print(f\"Counter: {self.counter}, Global: {global_best_acc}, MyBest: {self.best_acc}\\n\")\n",
    "        if not hasattr(self.model.optimizer, \"lr\"):\n",
    "            raise ValueError('Optimizer must have a \"lr\" attribute.')\n",
    "        # Get the current learning rate from model's optimizer.\n",
    "        lr = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n",
    "        # Call schedule function to get the scheduled learning rate.\n",
    "        scheduled_lr = self.schedule(epoch, lr)\n",
    "        # Set the value back to the optimizer before this epoch starts\n",
    "        tf.keras.backend.set_value(self.model.optimizer.lr, scheduled_lr)\n",
    "    \n",
    "    def schedule(self,epoch,lr):\n",
    "        global global_best_acc\n",
    "        if self.counter == self.patience:\n",
    "            self.counter = 0 \n",
    "            print(\"Epoch %03d: Updating Learning rate.. New value is %f\" % (epoch, lr*self.factor))\n",
    "            message = \"Epoch %03d: Updating Learning rate.. New value is %f\" % (epoch, lr*self.factor)\n",
    "            f = open(self.fileName, \"a\")\n",
    "            f.write(message)\n",
    "            f.close()\n",
    "            return lr*self.factor\n",
    "        if self.best_acc == global_best_acc:\n",
    "            self.counter = self.counter + 1\n",
    "        elif self.best_acc < global_best_acc:\n",
    "            self.counter = 0\n",
    "            self.best_acc = global_best_acc\n",
    "        return lr\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finito 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ndataset = Dataset(\"datasets.json\",32)\\n\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle \n",
    "with open('../imgs_train_mpii128sx12_genhm.pickle', 'rb') as handle:\n",
    "    train_images = pickle.load(handle)\n",
    "with open('../hms_train_mpii128sx12_genhm.pickle', 'rb') as handle:\n",
    "    train_hms = pickle.load(handle)\n",
    "\n",
    "eval_images = np.load(\"../imgs_val_mpii128sx12_genhm.npz\")['arr_0']\n",
    "eval_hms = np.load(\"../hms_val_mpii128sx12_genhm.npz\")['arr_0']\n",
    "\n",
    "#train_images = np.load(\"../imgs_train_mpii128.npz\")['arr_0']\n",
    "#train_hms = np.load(\"../hms_train_mpii128.npz\")['arr_0']\n",
    "train_hms = np.transpose(train_hms,(0,2,3,1))#np.reshape(train_hms,(train_hms.shape[0],64,64,16))\n",
    "eval_hms2 = np.transpose(eval_hms,(0,2,3,1))\n",
    "print(\"Finito 1\")\n",
    "\"\"\"\n",
    "dataset = Dataset(\"datasets.json\",32)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finito 2\n"
     ]
    }
   ],
   "source": [
    "evalcallback = EvalCallBack((128,128),\"../sigmoidLayersAdamSchedulingQuasiDef3sx12_restartsig8_4_6416_2S.txt\",eval_images,eval_hms)\n",
    "updateLR = CustomLearningRateScheduler(7,0.2,fileName=\"../sigmoidLayersAdamSchedulingQuasiDef3sx12_restartsig8_4_6416_2S.txt\")\n",
    "print(\"Finito 2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter: 0, Global: 0.0, MyBest: 0.0\n",
      "\n",
      "Epoch 1/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.2256 - conv2d_63_loss: 0.0782 - conv2d_95_loss: 0.0719 - conv2d_127_loss: 0.0755WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0133s vs `on_test_batch_end` time: 0.0464s). Check your callbacks.\n",
      "(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.04550723 0.02178972 0.03152247 0.06483755 0.06261723 0.03707432\n",
      " 0.03229892 0.07190394 0.06814691 0.06117319 0.04031209 0.02926622\n",
      " 0.04101124 0.04932423 0.04571429 0.03693302 0.03419045] @epoch 0\n",
      "Epoch 001: val_acc improved from 0.000 to 0.046\n",
      "1151/1151 [==============================] - 338s 294ms/step - loss: 0.2256 - conv2d_63_loss: 0.0782 - conv2d_95_loss: 0.0719 - conv2d_127_loss: 0.0755 - val_loss: 8.0184 - val_conv2d_63_loss: 4.1432 - val_conv2d_95_loss: 2.8062 - val_conv2d_127_loss: 1.0689\n",
      "Counter: 1, Global: 0.04550723498687148, MyBest: 0.0\n",
      "\n",
      "Epoch 2/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1640 - conv2d_63_loss: 0.0564 - conv2d_95_loss: 0.0536 - conv2d_127_loss: 0.0541(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.35147374 0.21006981 0.21445338 0.35552347 0.34872311 0.21036738\n",
      " 0.20540427 0.43619791 0.63021922 0.6455307  0.53388238 0.22974692\n",
      " 0.29073033 0.41925594 0.40794426 0.26541215 0.22011867] @epoch 1\n",
      "Epoch 002: val_acc improved from 0.046 to 0.351\n",
      "1151/1151 [==============================] - 326s 283ms/step - loss: 0.1640 - conv2d_63_loss: 0.0564 - conv2d_95_loss: 0.0536 - conv2d_127_loss: 0.0541 - val_loss: 0.1528 - val_conv2d_63_loss: 0.0516 - val_conv2d_95_loss: 0.0507 - val_conv2d_127_loss: 0.0505\n",
      "Counter: 0, Global: 0.35147374402731657, MyBest: 0.04550723498687148\n",
      "\n",
      "Epoch 3/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1530 - conv2d_63_loss: 0.0516 - conv2d_95_loss: 0.0506 - conv2d_127_loss: 0.050 - ETA: 0s - loss: 0.1530 - conv2d_63_loss: 0.0516 - conv2d_95_loss: 0.0506 - conv2d_127_loss: 0.0508(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.41585156 0.26676539 0.26123407 0.39725631 0.39532536 0.2685791\n",
      " 0.27211314 0.50549769 0.73425502 0.74986035 0.63675767 0.28432065\n",
      " 0.32359549 0.499791   0.48696864 0.30936667 0.26193839] @epoch 2\n",
      "Epoch 003: val_acc improved from 0.351 to 0.416\n",
      "1151/1151 [==============================] - 328s 285ms/step - loss: 0.1530 - conv2d_63_loss: 0.0516 - conv2d_95_loss: 0.0506 - conv2d_127_loss: 0.0508 - val_loss: 0.1489 - val_conv2d_63_loss: 0.0506 - val_conv2d_95_loss: 0.0492 - val_conv2d_127_loss: 0.0491\n",
      "Counter: 0, Global: 0.41585155948996544, MyBest: 0.35147374402731657\n",
      "\n",
      "Epoch 4/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1484 - conv2d_63_loss: 0.0508 - conv2d_95_loss: 0.0488 - conv2d_127_loss: 0.0488(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.3718104  0.2388407  0.24094567 0.38180506 0.37079787 0.25364873\n",
      " 0.25416932 0.4819155  0.64236838 0.65600556 0.5682705  0.22592959\n",
      " 0.28089887 0.41995263 0.42271778 0.28521276 0.22548743] @epoch 3\n",
      "Epoch 004: val_acc did not improve from 0.416\n",
      "1151/1151 [==============================] - 325s 282ms/step - loss: 0.1484 - conv2d_63_loss: 0.0508 - conv2d_95_loss: 0.0488 - conv2d_127_loss: 0.0488 - val_loss: 0.1530 - val_conv2d_63_loss: 0.0522 - val_conv2d_95_loss: 0.0505 - val_conv2d_127_loss: 0.0502\n",
      "Counter: 0, Global: 0.41585155948996544, MyBest: 0.41585155948996544\n",
      "\n",
      "Epoch 5/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1447 - conv2d_63_loss: 0.0498 - conv2d_95_loss: 0.0476 - conv2d_127_loss: 0.0473(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.50186824 0.33551934 0.34289068 0.48014441 0.49329102 0.34893474\n",
      " 0.34916613 0.59563076 0.80896521 0.81564248 0.72720706 0.32744238\n",
      " 0.42893258 0.61947888 0.62564462 0.41791883 0.31308278] @epoch 4\n",
      "Epoch 005: val_acc improved from 0.416 to 0.502\n",
      "1151/1151 [==============================] - 326s 283ms/step - loss: 0.1447 - conv2d_63_loss: 0.0498 - conv2d_95_loss: 0.0476 - conv2d_127_loss: 0.0473 - val_loss: 0.1430 - val_conv2d_63_loss: 0.0490 - val_conv2d_95_loss: 0.0471 - val_conv2d_127_loss: 0.0469\n",
      "Counter: 1, Global: 0.5018682442605495, MyBest: 0.41585155948996544\n",
      "\n",
      "Epoch 6/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1400 - conv2d_63_loss: 0.0485 - conv2d_95_loss: 0.0460 - conv2d_127_loss: 0.0456(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.49480636 0.35625133 0.37944332 0.51523465 0.48448998 0.32192585\n",
      " 0.35402152 0.50520831 0.76846808 0.81829607 0.73674327 0.2847448\n",
      " 0.4258427  0.62881428 0.62717772 0.4167954  0.29344448] @epoch 5\n",
      "Epoch 006: val_acc did not improve from 0.502\n",
      "1151/1151 [==============================] - 325s 283ms/step - loss: 0.1400 - conv2d_63_loss: 0.0485 - conv2d_95_loss: 0.0460 - conv2d_127_loss: 0.0456 - val_loss: 0.1536 - val_conv2d_63_loss: 0.0537 - val_conv2d_95_loss: 0.0476 - val_conv2d_127_loss: 0.0524\n",
      "Counter: 0, Global: 0.5018682442605495, MyBest: 0.5018682442605495\n",
      "\n",
      "Epoch 7/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1368 - conv2d_63_loss: 0.0476 - conv2d_95_loss: 0.0449 - conv2d_127_loss: 0.0443(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.55198212 0.38163739 0.39419854 0.52577615 0.53729618 0.4140245\n",
      " 0.39666456 0.65219909 0.84974164 0.85977656 0.80176276 0.39106461\n",
      " 0.47640449 0.65528774 0.6583972  0.44881338 0.3886691 ] @epoch 6\n",
      "Epoch 007: val_acc improved from 0.502 to 0.552\n",
      "1151/1151 [==============================] - 327s 284ms/step - loss: 0.1368 - conv2d_63_loss: 0.0476 - conv2d_95_loss: 0.0449 - conv2d_127_loss: 0.0443 - val_loss: 0.1390 - val_conv2d_63_loss: 0.0476 - val_conv2d_95_loss: 0.0460 - val_conv2d_127_loss: 0.0455\n",
      "Counter: 1, Global: 0.5519821178168058, MyBest: 0.5018682442605495\n",
      "\n",
      "Epoch 8/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1342 - conv2d_63_loss: 0.0469 - conv2d_95_loss: 0.0440 - conv2d_127_loss: 0.0433(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.57989213 0.41315845 0.43041584 0.56981951 0.56629634 0.43650395\n",
      " 0.4095419  0.64858216 0.86007541 0.86801678 0.81751192 0.44210377\n",
      " 0.49691013 0.6940226  0.70285714 0.50793427 0.41452387] @epoch 7\n",
      "Epoch 008: val_acc improved from 0.552 to 0.580\n",
      "1151/1151 [==============================] - 327s 284ms/step - loss: 0.1342 - conv2d_63_loss: 0.0469 - conv2d_95_loss: 0.0440 - conv2d_127_loss: 0.0433 - val_loss: 0.1370 - val_conv2d_63_loss: 0.0472 - val_conv2d_95_loss: 0.0452 - val_conv2d_127_loss: 0.0446\n",
      "Counter: 0, Global: 0.5798921268433332, MyBest: 0.5519821178168058\n",
      "\n",
      "Epoch 9/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1321 - conv2d_63_loss: 0.0463 - conv2d_95_loss: 0.0434 - conv2d_127_loss: 0.0424(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.58986977 0.40554264 0.44500336 0.5768953  0.57408744 0.38080859\n",
      " 0.39223137 0.64872688 0.86747658 0.87332404 0.81953478 0.47108725\n",
      " 0.55435395 0.71255398 0.7204181  0.53995228 0.45591974] @epoch 8\n",
      "Epoch 009: val_acc improved from 0.580 to 0.590\n",
      "1151/1151 [==============================] - 328s 285ms/step - loss: 0.1321 - conv2d_63_loss: 0.0463 - conv2d_95_loss: 0.0434 - conv2d_127_loss: 0.0424 - val_loss: 0.1374 - val_conv2d_63_loss: 0.0474 - val_conv2d_95_loss: 0.0455 - val_conv2d_127_loss: 0.0445\n",
      "Counter: 0, Global: 0.5898697674274445, MyBest: 0.5798921268433332\n",
      "\n",
      "Epoch 10/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1303 - conv2d_63_loss: 0.0459 - conv2d_95_loss: 0.0428 - conv2d_127_loss: 0.0417(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.63227321 0.44362175 0.46864522 0.61833936 0.63295341 0.48062405\n",
      " 0.44838506 0.7092014  0.88409442 0.88812852 0.84453112 0.52551961\n",
      " 0.58019662 0.74028146 0.74620211 0.58671534 0.51893193] @epoch 9\n",
      "Epoch 010: val_acc improved from 0.590 to 0.632\n",
      "1151/1151 [==============================] - 325s 282ms/step - loss: 0.1303 - conv2d_63_loss: 0.0459 - conv2d_95_loss: 0.0428 - conv2d_127_loss: 0.0417 - val_loss: 0.1326 - val_conv2d_63_loss: 0.0462 - val_conv2d_95_loss: 0.0437 - val_conv2d_127_loss: 0.0428\n",
      "Counter: 0, Global: 0.6322732102125883, MyBest: 0.5898697674274445\n",
      "\n",
      "Epoch 11/201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1288 - conv2d_63_loss: 0.0455 - conv2d_95_loss: 0.0422 - conv2d_127_loss: 0.0410(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.64387364 0.46393061 0.49765259 0.62844765 0.63569468 0.50880724\n",
      " 0.47012877 0.7175926  0.88409442 0.88673186 0.84713191 0.53456807\n",
      " 0.5939607  0.74780548 0.75665504 0.59345597 0.5353207 ] @epoch 10\n",
      "Epoch 011: val_acc improved from 0.632 to 0.644\n",
      "1151/1151 [==============================] - 325s 283ms/step - loss: 0.1288 - conv2d_63_loss: 0.0455 - conv2d_95_loss: 0.0422 - conv2d_127_loss: 0.0410 - val_loss: 0.1318 - val_conv2d_63_loss: 0.0461 - val_conv2d_95_loss: 0.0434 - val_conv2d_127_loss: 0.0423\n",
      "Counter: 0, Global: 0.643873643130064, MyBest: 0.6322732102125883\n",
      "\n",
      "Epoch 12/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1272 - conv2d_63_loss: 0.0451 - conv2d_95_loss: 0.0417 - conv2d_127_loss: 0.0404(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.64565517 0.46752697 0.50771296 0.62772566 0.63511759 0.51367217\n",
      " 0.47878405 0.71354169 0.88507193 0.89273745 0.84929925 0.52396435\n",
      " 0.59325844 0.74892014 0.75679445 0.60174131 0.53461432] @epoch 11\n",
      "Epoch 012: val_acc improved from 0.644 to 0.646\n",
      "1151/1151 [==============================] - 328s 285ms/step - loss: 0.1272 - conv2d_63_loss: 0.0451 - conv2d_95_loss: 0.0417 - conv2d_127_loss: 0.0404 - val_loss: 0.1317 - val_conv2d_63_loss: 0.0460 - val_conv2d_95_loss: 0.0433 - val_conv2d_127_loss: 0.0423\n",
      "Counter: 0, Global: 0.6456551719456911, MyBest: 0.643873643130064\n",
      "\n",
      "Epoch 13/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1259 - conv2d_63_loss: 0.0448 - conv2d_95_loss: 0.0413 - conv2d_127_loss: 0.0399(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.65578633 0.48064312 0.52380955 0.64851987 0.6421873  0.53128672\n",
      " 0.48385054 0.73408562 0.89219385 0.89008379 0.85767955 0.54389936\n",
      " 0.60688204 0.74989551 0.76696867 0.60146046 0.53913534] @epoch 12\n",
      "Epoch 013: val_acc improved from 0.646 to 0.656\n",
      "1151/1151 [==============================] - 325s 283ms/step - loss: 0.1259 - conv2d_63_loss: 0.0448 - conv2d_95_loss: 0.0413 - conv2d_127_loss: 0.0399 - val_loss: 0.1310 - val_conv2d_63_loss: 0.0459 - val_conv2d_95_loss: 0.0431 - val_conv2d_127_loss: 0.0420\n",
      "Counter: 0, Global: 0.6557863298803568, MyBest: 0.6456551719456911\n",
      "\n",
      "Epoch 14/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1247 - conv2d_63_loss: 0.0445 - conv2d_95_loss: 0.0408 - conv2d_127_loss: 0.0394(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.67208629 0.48360482 0.52850437 0.65646207 0.66527194 0.54068106\n",
      " 0.49123919 0.73654515 0.9044826  0.90586591 0.86793816 0.57316554\n",
      " 0.63244385 0.77609026 0.78369337 0.62968683 0.57770556] @epoch 13\n",
      "Epoch 014: val_acc improved from 0.656 to 0.672\n",
      "1151/1151 [==============================] - 325s 282ms/step - loss: 0.1247 - conv2d_63_loss: 0.0445 - conv2d_95_loss: 0.0408 - conv2d_127_loss: 0.0394 - val_loss: 0.1293 - val_conv2d_63_loss: 0.0455 - val_conv2d_95_loss: 0.0424 - val_conv2d_127_loss: 0.0413\n",
      "Counter: 0, Global: 0.6720862928777933, MyBest: 0.6557863298803568\n",
      "\n",
      "Epoch 15/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1237 - conv2d_63_loss: 0.0443 - conv2d_95_loss: 0.0405 - conv2d_127_loss: 0.0390(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.67098723 0.49629787 0.53370219 0.65256315 0.6558938  0.53933907\n",
      " 0.50601649 0.73509836 0.90629798 0.90670389 0.86923856 0.57047927\n",
      " 0.63019663 0.76647621 0.77533102 0.62519312 0.56696808] @epoch 14\n",
      "Epoch 015: val_acc did not improve from 0.672\n",
      "1151/1151 [==============================] - 326s 283ms/step - loss: 0.1237 - conv2d_63_loss: 0.0443 - conv2d_95_loss: 0.0405 - conv2d_127_loss: 0.0390 - val_loss: 0.1295 - val_conv2d_63_loss: 0.0453 - val_conv2d_95_loss: 0.0427 - val_conv2d_127_loss: 0.0415\n",
      "Counter: 0, Global: 0.6720862928777933, MyBest: 0.6720862928777933\n",
      "\n",
      "Epoch 16/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1227 - conv2d_63_loss: 0.0440 - conv2d_95_loss: 0.0401 - conv2d_127_loss: 0.0385(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.6842295  0.5147028  0.55784708 0.66512638 0.66916752 0.55645025\n",
      " 0.50918305 0.73871529 0.90573943 0.90712291 0.8734287  0.59606957\n",
      " 0.64733148 0.78110629 0.78996515 0.64190423 0.59381181] @epoch 15\n",
      "Epoch 016: val_acc improved from 0.672 to 0.684\n",
      "1151/1151 [==============================] - 324s 282ms/step - loss: 0.1227 - conv2d_63_loss: 0.0440 - conv2d_95_loss: 0.0401 - conv2d_127_loss: 0.0385 - val_loss: 0.1283 - val_conv2d_63_loss: 0.0452 - val_conv2d_95_loss: 0.0421 - val_conv2d_127_loss: 0.0410\n",
      "Counter: 1, Global: 0.6842294968664646, MyBest: 0.6720862928777933\n",
      "\n",
      "Epoch 17/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1217 - conv2d_63_loss: 0.0438 - conv2d_95_loss: 0.0398 - conv2d_127_loss: 0.0381(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.68792981 0.5185107  0.55499667 0.66613716 0.67580438 0.55577922\n",
      " 0.52037156 0.75202549 0.90755481 0.90488827 0.87068343 0.59423161\n",
      " 0.65772474 0.78236032 0.79121953 0.65159386 0.60299522] @epoch 16\n",
      "Epoch 017: val_acc improved from 0.684 to 0.688\n",
      "1151/1151 [==============================] - 327s 285ms/step - loss: 0.1217 - conv2d_63_loss: 0.0438 - conv2d_95_loss: 0.0398 - conv2d_127_loss: 0.0381 - val_loss: 0.1279 - val_conv2d_63_loss: 0.0451 - val_conv2d_95_loss: 0.0420 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 0, Global: 0.6879298090934753, MyBest: 0.6842294968664646\n",
      "\n",
      "Epoch 18/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1207 - conv2d_63_loss: 0.0435 - conv2d_95_loss: 0.0394 - conv2d_127_loss: 0.0377(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.66608671 0.49735561 0.54678071 0.66873646 0.66094357 0.54856569\n",
      " 0.51171625 0.74594909 0.81371319 0.8392458  0.85869092 0.57966918\n",
      " 0.63539326 0.76494354 0.76236933 0.63670832 0.58660638] @epoch 17\n",
      "Epoch 018: val_acc did not improve from 0.688\n",
      "1151/1151 [==============================] - 325s 282ms/step - loss: 0.1207 - conv2d_63_loss: 0.0435 - conv2d_95_loss: 0.0394 - conv2d_127_loss: 0.0377 - val_loss: 0.1505 - val_conv2d_63_loss: 0.0499 - val_conv2d_95_loss: 0.0570 - val_conv2d_127_loss: 0.0436\n",
      "Counter: 0, Global: 0.6879298090934753, MyBest: 0.6879298090934753\n",
      "\n",
      "Epoch 19/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1199 - conv2d_63_loss: 0.0434 - conv2d_95_loss: 0.0392 - conv2d_127_loss: 0.0374(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.6894881  0.51385659 0.5449363  0.67480147 0.67796856 0.54755914\n",
      " 0.51382732 0.75043404 0.90895128 0.90921789 0.87559599 0.60596633\n",
      " 0.66235954 0.78584367 0.80167246 0.65299815 0.60582083] @epoch 18\n",
      "Epoch 019: val_acc improved from 0.688 to 0.689\n",
      "1151/1151 [==============================] - 326s 283ms/step - loss: 0.1199 - conv2d_63_loss: 0.0434 - conv2d_95_loss: 0.0392 - conv2d_127_loss: 0.0374 - val_loss: 0.1279 - val_conv2d_63_loss: 0.0448 - val_conv2d_95_loss: 0.0422 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 1, Global: 0.689488098025322, MyBest: 0.6879298090934753\n",
      "\n",
      "Epoch 20/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1190 - conv2d_63_loss: 0.0430 - conv2d_95_loss: 0.0389 - conv2d_127_loss: 0.0371(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.68729328 0.50856781 0.554829   0.67566788 0.6796999  0.56601244\n",
      " 0.52058268 0.75535303 0.90615833 0.90586591 0.87097239 0.58758658\n",
      " 0.65617979 0.781385   0.78606272 0.64555538 0.59621364] @epoch 19\n",
      "Epoch 020: val_acc did not improve from 0.689\n",
      "1151/1151 [==============================] - 326s 283ms/step - loss: 0.1190 - conv2d_63_loss: 0.0430 - conv2d_95_loss: 0.0389 - conv2d_127_loss: 0.0371 - val_loss: 0.1283 - val_conv2d_63_loss: 0.0450 - val_conv2d_95_loss: 0.0424 - val_conv2d_127_loss: 0.0410\n",
      "Counter: 0, Global: 0.689488098025322, MyBest: 0.689488098025322\n",
      "\n",
      "Epoch 21/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1183 - conv2d_63_loss: 0.0428 - conv2d_95_loss: 0.0387 - conv2d_127_loss: 0.0368(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.69578543 0.52824199 0.56706905 0.68144405 0.67926705 0.56634796\n",
      " 0.51530504 0.75289351 0.91453707 0.90893853 0.87805229 0.60794568\n",
      " 0.66671348 0.79169571 0.80418116 0.66058135 0.60935295] @epoch 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 021: val_acc improved from 0.689 to 0.696\n",
      "1151/1151 [==============================] - 328s 285ms/step - loss: 0.1183 - conv2d_63_loss: 0.0428 - conv2d_95_loss: 0.0387 - conv2d_127_loss: 0.0368 - val_loss: 0.1267 - val_conv2d_63_loss: 0.0443 - val_conv2d_95_loss: 0.0417 - val_conv2d_127_loss: 0.0407\n",
      "Counter: 1, Global: 0.69578542932868, MyBest: 0.689488098025322\n",
      "\n",
      "Epoch 22/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1178 - conv2d_63_loss: 0.0427 - conv2d_95_loss: 0.0385 - conv2d_127_loss: 0.0366(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.70214431 0.53120375 0.57344067 0.68649822 0.68864524 0.5757423\n",
      " 0.52543807 0.76027197 0.91565424 0.91592181 0.88715506 0.61317688\n",
      " 0.66783708 0.80228508 0.80432057 0.66535598 0.62136197] @epoch 21\n",
      "Epoch 022: val_acc improved from 0.696 to 0.702\n",
      "1151/1151 [==============================] - 327s 284ms/step - loss: 0.1178 - conv2d_63_loss: 0.0427 - conv2d_95_loss: 0.0385 - conv2d_127_loss: 0.0366 - val_loss: 0.1259 - val_conv2d_63_loss: 0.0442 - val_conv2d_95_loss: 0.0414 - val_conv2d_127_loss: 0.0403\n",
      "Counter: 0, Global: 0.702144306153059, MyBest: 0.69578542932868\n",
      "\n",
      "Epoch 23/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1168 - conv2d_63_loss: 0.0425 - conv2d_95_loss: 0.0381 - conv2d_127_loss: 0.0362(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.69112681 0.52485722 0.54929578 0.67725635 0.67623717 0.56701899\n",
      " 0.51044965 0.73987269 0.91258204 0.91047484 0.88137555 0.5898487\n",
      " 0.66390449 0.79378569 0.79790938 0.65931749 0.60384291] @epoch 22\n",
      "Epoch 023: val_acc did not improve from 0.702\n",
      "1151/1151 [==============================] - 328s 285ms/step - loss: 0.1168 - conv2d_63_loss: 0.0425 - conv2d_95_loss: 0.0381 - conv2d_127_loss: 0.0362 - val_loss: 0.1284 - val_conv2d_63_loss: 0.0446 - val_conv2d_95_loss: 0.0422 - val_conv2d_127_loss: 0.0415\n",
      "Counter: 0, Global: 0.702144306153059, MyBest: 0.702144306153059\n",
      "\n",
      "Epoch 24/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1164 - conv2d_63_loss: 0.0424 - conv2d_95_loss: 0.0380 - conv2d_127_loss: 0.0360(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.70378709 0.53056908 0.56908113 0.69126356 0.69181937 0.5848012\n",
      " 0.52733797 0.76967591 0.91118556 0.91187149 0.88440979 0.60865265\n",
      " 0.67851126 0.790999   0.81059235 0.67097318 0.62884998] @epoch 23\n",
      "Epoch 024: val_acc improved from 0.702 to 0.704\n",
      "1151/1151 [==============================] - 326s 284ms/step - loss: 0.1164 - conv2d_63_loss: 0.0424 - conv2d_95_loss: 0.0380 - conv2d_127_loss: 0.0360 - val_loss: 0.1288 - val_conv2d_63_loss: 0.0445 - val_conv2d_95_loss: 0.0425 - val_conv2d_127_loss: 0.0418\n",
      "Counter: 1, Global: 0.7037870921194553, MyBest: 0.702144306153059\n",
      "\n",
      "Epoch 25/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1158 - conv2d_63_loss: 0.0423 - conv2d_95_loss: 0.0378 - conv2d_127_loss: 0.0358(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.70921337 0.53945422 0.57947683 0.70238268 0.70639157 0.58513671\n",
      " 0.5351488  0.77271414 0.9188661  0.91675979 0.88397628 0.62151843\n",
      " 0.67865169 0.79991639 0.80891985 0.67546695 0.62263352] @epoch 24\n",
      "Epoch 025: val_acc improved from 0.704 to 0.709\n",
      "1151/1151 [==============================] - 325s 282ms/step - loss: 0.1158 - conv2d_63_loss: 0.0423 - conv2d_95_loss: 0.0378 - conv2d_127_loss: 0.0358 - val_loss: 0.1255 - val_conv2d_63_loss: 0.0441 - val_conv2d_95_loss: 0.0412 - val_conv2d_127_loss: 0.0402\n",
      "Counter: 0, Global: 0.7092133723199368, MyBest: 0.7037870921194553\n",
      "\n",
      "Epoch 26/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1152 - conv2d_63_loss: 0.0421 - conv2d_95_loss: 0.0376 - conv2d_127_loss: 0.0355(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.70497023 0.53628093 0.57729709 0.68895304 0.69340646 0.57641333\n",
      " 0.53430444 0.76895255 0.91314059 0.9131285  0.88527668 0.62745655\n",
      " 0.67710674 0.791417   0.8154704  0.66633898 0.61458039] @epoch 25\n",
      "Epoch 026: val_acc did not improve from 0.709\n",
      "1151/1151 [==============================] - 326s 284ms/step - loss: 0.1152 - conv2d_63_loss: 0.0421 - conv2d_95_loss: 0.0376 - conv2d_127_loss: 0.0355 - val_loss: 0.1257 - val_conv2d_63_loss: 0.0441 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0403\n",
      "Counter: 0, Global: 0.7092133723199368, MyBest: 0.7092133723199368\n",
      "\n",
      "Epoch 27/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1145 - conv2d_63_loss: 0.0419 - conv2d_95_loss: 0.0373 - conv2d_127_loss: 0.0352(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.70115215 0.52633804 0.56354797 0.69025272 0.69066513 0.57674885\n",
      " 0.52881569 0.76244211 0.91146487 0.91019553 0.87877476 0.61713558\n",
      " 0.67865169 0.79378569 0.80236936 0.67139447 0.61585194] @epoch 26\n",
      "Epoch 027: val_acc did not improve from 0.709\n",
      "1151/1151 [==============================] - 325s 282ms/step - loss: 0.1145 - conv2d_63_loss: 0.0419 - conv2d_95_loss: 0.0373 - conv2d_127_loss: 0.0352 - val_loss: 0.1265 - val_conv2d_63_loss: 0.0443 - val_conv2d_95_loss: 0.0415 - val_conv2d_127_loss: 0.0406\n",
      "Counter: 1, Global: 0.7092133723199368, MyBest: 0.7092133723199368\n",
      "\n",
      "Epoch 28/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1138 - conv2d_63_loss: 0.0418 - conv2d_95_loss: 0.0371 - conv2d_127_loss: 0.0349(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.70494513 0.53945422 0.58249497 0.69083035 0.68561536 0.57674885\n",
      " 0.53535992 0.76142937 0.9162128  0.91243017 0.87747437 0.6178425\n",
      " 0.68483144 0.79894108 0.80432057 0.67504567 0.62009043] @epoch 27\n",
      "Epoch 028: val_acc did not improve from 0.709\n",
      "1151/1151 [==============================] - 328s 285ms/step - loss: 0.1138 - conv2d_63_loss: 0.0418 - conv2d_95_loss: 0.0371 - conv2d_127_loss: 0.0349 - val_loss: 0.1266 - val_conv2d_63_loss: 0.0444 - val_conv2d_95_loss: 0.0415 - val_conv2d_127_loss: 0.0407\n",
      "Counter: 2, Global: 0.7092133723199368, MyBest: 0.7092133723199368\n",
      "\n",
      "Epoch 29/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1132 - conv2d_63_loss: 0.0417 - conv2d_95_loss: 0.0369 - conv2d_127_loss: 0.0347(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.70765873 0.53797334 0.57847083 0.68909746 0.69816768 0.58966619\n",
      " 0.53430444 0.76953125 0.91369921 0.9134078  0.87747437 0.62660825\n",
      " 0.68384832 0.79935908 0.81212544 0.67560738 0.62319863] @epoch 28\n",
      "Epoch 029: val_acc did not improve from 0.709\n",
      "1151/1151 [==============================] - 326s 283ms/step - loss: 0.1132 - conv2d_63_loss: 0.0417 - conv2d_95_loss: 0.0369 - conv2d_127_loss: 0.0347 - val_loss: 0.1253 - val_conv2d_63_loss: 0.0439 - val_conv2d_95_loss: 0.0411 - val_conv2d_127_loss: 0.0402\n",
      "Counter: 3, Global: 0.7092133723199368, MyBest: 0.7092133723199368\n",
      "\n",
      "Epoch 30/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1128 - conv2d_63_loss: 0.0416 - conv2d_95_loss: 0.0367 - conv2d_127_loss: 0.0346(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.69977704 0.52845359 0.57377601 0.68202168 0.68070984 0.58396244\n",
      " 0.51551616 0.75101274 0.9164921  0.91256982 0.88224244 0.61558038\n",
      " 0.6758427  0.78904837 0.80264807 0.66872633 0.61782992] @epoch 29\n",
      "Epoch 030: val_acc did not improve from 0.709\n",
      "1151/1151 [==============================] - 327s 284ms/step - loss: 0.1128 - conv2d_63_loss: 0.0416 - conv2d_95_loss: 0.0367 - conv2d_127_loss: 0.0346 - val_loss: 0.1267 - val_conv2d_63_loss: 0.0446 - val_conv2d_95_loss: 0.0415 - val_conv2d_127_loss: 0.0406\n",
      "Counter: 4, Global: 0.7092133723199368, MyBest: 0.7092133723199368\n",
      "\n",
      "Epoch 31/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1172 - conv2d_63_loss: 0.0426 - conv2d_95_loss: 0.0383 - conv2d_127_loss: 0.0363(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.70413167 0.53860801 0.57712942 0.68866426 0.6949935  0.57440025\n",
      " 0.51973826 0.76345485 0.91272169 0.91396648 0.88339835 0.62250811\n",
      " 0.6797753  0.79726905 0.80585366 0.66788375 0.62574172] @epoch 30\n",
      "Epoch 031: val_acc did not improve from 0.709\n",
      "1151/1151 [==============================] - 324s 281ms/step - loss: 0.1172 - conv2d_63_loss: 0.0426 - conv2d_95_loss: 0.0383 - conv2d_127_loss: 0.0363 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0442 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter: 5, Global: 0.7092133723199368, MyBest: 0.7092133723199368\n",
      "\n",
      "Epoch 32/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1131 - conv2d_63_loss: 0.0417 - conv2d_95_loss: 0.0368 - conv2d_127_loss: 0.0346(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.70571885 0.53945422 0.5791415  0.68808663 0.69456065 0.58211708\n",
      " 0.53134894 0.76186341 0.91369921 0.91480446 0.88657707 0.62109429\n",
      " 0.67359549 0.79573637 0.80933797 0.6744839  0.62560046] @epoch 31\n",
      "Epoch 032: val_acc did not improve from 0.709\n",
      "1151/1151 [==============================] - 324s 281ms/step - loss: 0.1131 - conv2d_63_loss: 0.0417 - conv2d_95_loss: 0.0368 - conv2d_127_loss: 0.0346 - val_loss: 0.1255 - val_conv2d_63_loss: 0.0439 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0403\n",
      "Counter: 6, Global: 0.7092133723199368, MyBest: 0.7092133723199368\n",
      "\n",
      "Epoch 33/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1115 - conv2d_63_loss: 0.0413 - conv2d_95_loss: 0.0362 - conv2d_127_loss: 0.0340(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.7063874  0.53924263 0.57712942 0.69111913 0.68979943 0.58161384\n",
      " 0.54042643 0.76417822 0.91062701 0.9107542  0.881809   0.62887037\n",
      " 0.68132025 0.80005574 0.80487806 0.67322004 0.62715459] @epoch 32\n",
      "Epoch 033: val_acc did not improve from 0.709\n",
      "1151/1151 [==============================] - 327s 284ms/step - loss: 0.1115 - conv2d_63_loss: 0.0413 - conv2d_95_loss: 0.0362 - conv2d_127_loss: 0.0340 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0442 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0404\n",
      "Counter: 7, Global: 0.7092133723199368, MyBest: 0.7092133723199368\n",
      "\n",
      "Epoch 033: Updating Learning rate.. New value is 0.001340\n",
      "Epoch 34/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1076 - conv2d_63_loss: 0.0405 - conv2d_95_loss: 0.0349 - conv2d_127_loss: 0.0322(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.72369827 0.5631479  0.59641182 0.70469314 0.71273988 0.60996479\n",
      " 0.55668145 0.77546299 0.92012286 0.92067039 0.89206761 0.64852256\n",
      " 0.70196629 0.81440711 0.82898957 0.69147593 0.64184797] @epoch 33\n",
      "Epoch 034: val_acc improved from 0.709 to 0.724\n",
      "1151/1151 [==============================] - 327s 284ms/step - loss: 0.1076 - conv2d_63_loss: 0.0405 - conv2d_95_loss: 0.0349 - conv2d_127_loss: 0.0322 - val_loss: 0.1238 - val_conv2d_63_loss: 0.0435 - val_conv2d_95_loss: 0.0407 - val_conv2d_127_loss: 0.0397\n",
      "Counter: 0, Global: 0.723698265850544, MyBest: 0.7092133723199368\n",
      "\n",
      "Epoch 35/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1062 - conv2d_63_loss: 0.0402 - conv2d_95_loss: 0.0343 - conv2d_127_loss: 0.0316(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.72282617 0.55849373 0.59372902 0.71104693 0.71230704 0.60493207\n",
      " 0.55034834 0.78211808 0.92165899 0.91885477 0.89394593 0.64371556\n",
      " 0.69733149 0.81510383 0.82815331 0.68908858 0.64439106] @epoch 34\n",
      "Epoch 035: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 324s 282ms/step - loss: 0.1062 - conv2d_63_loss: 0.0402 - conv2d_95_loss: 0.0343 - conv2d_127_loss: 0.0316 - val_loss: 0.1241 - val_conv2d_63_loss: 0.0435 - val_conv2d_95_loss: 0.0407 - val_conv2d_127_loss: 0.0399\n",
      "Counter: 0, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 36/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1054 - conv2d_63_loss: 0.0401 - conv2d_95_loss: 0.0341 - conv2d_127_loss: 0.0312(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.72267668 0.55362809 0.59423208 0.71104693 0.70797867 0.6056031\n",
      " 0.55435932 0.77763313 0.92026252 0.9182961  0.89336801 0.64428109\n",
      " 0.70351124 0.81120247 0.82452959 0.69751441 0.64538008] @epoch 35\n",
      "Epoch 036: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 326s 283ms/step - loss: 0.1054 - conv2d_63_loss: 0.0401 - conv2d_95_loss: 0.0341 - conv2d_127_loss: 0.0312 - val_loss: 0.1244 - val_conv2d_63_loss: 0.0435 - val_conv2d_95_loss: 0.0408 - val_conv2d_127_loss: 0.0400\n",
      "Counter: 1, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 37/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1048 - conv2d_63_loss: 0.0400 - conv2d_95_loss: 0.0339 - conv2d_127_loss: 0.0309(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.72172057 0.55447429 0.59574109 0.70772564 0.70971    0.60359001\n",
      " 0.55161494 0.77416086 0.92221755 0.91983241 0.89163417 0.64512938\n",
      " 0.69831461 0.81412846 0.82606274 0.68979079 0.6434021 ] @epoch 36\n",
      "Epoch 037: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 326s 283ms/step - loss: 0.1048 - conv2d_63_loss: 0.0400 - conv2d_95_loss: 0.0339 - conv2d_127_loss: 0.0309 - val_loss: 0.1244 - val_conv2d_63_loss: 0.0435 - val_conv2d_95_loss: 0.0409 - val_conv2d_127_loss: 0.0400\n",
      "Counter: 2, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 38/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1044 - conv2d_63_loss: 0.0399 - conv2d_95_loss: 0.0337 - conv2d_127_loss: 0.0307(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.72060405 0.55426276 0.59121394 0.70916969 0.70523733 0.6009059\n",
      " 0.55203718 0.77676505 0.91900575 0.91801673 0.88859993 0.641312\n",
      " 0.70140451 0.81273514 0.82411152 0.68993121 0.64495623] @epoch 37\n",
      "Epoch 038: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 327s 284ms/step - loss: 0.1044 - conv2d_63_loss: 0.0399 - conv2d_95_loss: 0.0337 - conv2d_127_loss: 0.0307 - val_loss: 0.1245 - val_conv2d_63_loss: 0.0435 - val_conv2d_95_loss: 0.0409 - val_conv2d_127_loss: 0.0400\n",
      "Counter: 3, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 39/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1039 - conv2d_63_loss: 0.0399 - conv2d_95_loss: 0.0336 - conv2d_127_loss: 0.0305(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.7175694  0.5515126  0.58802819 0.69891697 0.70393884 0.59251803\n",
      " 0.54908168 0.77271414 0.91802824 0.91871506 0.89279008 0.63834298\n",
      " 0.69676965 0.81426781 0.82229966 0.6857183  0.63746822] @epoch 38\n",
      "Epoch 039: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 326s 283ms/step - loss: 0.1039 - conv2d_63_loss: 0.0399 - conv2d_95_loss: 0.0336 - conv2d_127_loss: 0.0305 - val_loss: 0.1249 - val_conv2d_63_loss: 0.0436 - val_conv2d_95_loss: 0.0410 - val_conv2d_127_loss: 0.0402\n",
      "Counter: 4, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 40/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1036 - conv2d_63_loss: 0.0398 - conv2d_95_loss: 0.0334 - conv2d_127_loss: 0.0303(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71821007 0.54982018 0.59138161 0.69776171 0.69961047 0.59855729\n",
      " 0.5499261  0.76967591 0.92165899 0.92039108 0.89380145 0.63678777\n",
      " 0.69648874 0.8134318  0.82494771 0.6893695  0.6377508 ] @epoch 39\n",
      "Epoch 040: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 326s 284ms/step - loss: 0.1036 - conv2d_63_loss: 0.0398 - conv2d_95_loss: 0.0334 - conv2d_127_loss: 0.0303 - val_loss: 0.1250 - val_conv2d_63_loss: 0.0436 - val_conv2d_95_loss: 0.0411 - val_conv2d_127_loss: 0.0403\n",
      "Counter: 5, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 41/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1031 - conv2d_63_loss: 0.0397 - conv2d_95_loss: 0.0333 - conv2d_127_loss: 0.0301(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71705972 0.55383962 0.59138161 0.69602889 0.70105326 0.59721524\n",
      " 0.54887056 0.7722801  0.91984361 0.91801673 0.89148968 0.63763607\n",
      " 0.697191   0.80827641 0.82202089 0.6867013  0.63111049] @epoch 40\n",
      "Epoch 041: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 325s 282ms/step - loss: 0.1031 - conv2d_63_loss: 0.0397 - conv2d_95_loss: 0.0333 - conv2d_127_loss: 0.0301 - val_loss: 0.1252 - val_conv2d_63_loss: 0.0436 - val_conv2d_95_loss: 0.0411 - val_conv2d_127_loss: 0.0405\n",
      "Counter: 6, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 42/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1028 - conv2d_63_loss: 0.0397 - conv2d_95_loss: 0.0332 - conv2d_127_loss: 0.0299(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validate accuracy:\n",
      " [0.71673269 0.55024326 0.58618379 0.6968953  0.69744623 0.5941956\n",
      " 0.55013722 0.77068865 0.91872644 0.92011172 0.8926456  0.64173621\n",
      " 0.69747192 0.80813712 0.81937283 0.68908858 0.63464254] @epoch 41\n",
      "Epoch 042: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 325s 283ms/step - loss: 0.1028 - conv2d_63_loss: 0.0397 - conv2d_95_loss: 0.0332 - conv2d_127_loss: 0.0299 - val_loss: 0.1252 - val_conv2d_63_loss: 0.0436 - val_conv2d_95_loss: 0.0411 - val_conv2d_127_loss: 0.0404\n",
      "Counter: 7, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 042: Updating Learning rate.. New value is 0.000268\n",
      "Epoch 43/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1016 - conv2d_63_loss: 0.0395 - conv2d_95_loss: 0.0327 - conv2d_127_loss: 0.0294(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71844339 0.54918551 0.59188461 0.69631767 0.70249605 0.59939605\n",
      " 0.54675955 0.77097803 0.919285   0.91871506 0.89351249 0.64272588\n",
      " 0.70126402 0.81217778 0.82257837 0.69077379 0.63704437] @epoch 42\n",
      "Epoch 043: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 326s 284ms/step - loss: 0.1016 - conv2d_63_loss: 0.0395 - conv2d_95_loss: 0.0327 - conv2d_127_loss: 0.0294 - val_loss: 0.1254 - val_conv2d_63_loss: 0.0436 - val_conv2d_95_loss: 0.0412 - val_conv2d_127_loss: 0.0406\n",
      "Counter: 0, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 44/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1013 - conv2d_63_loss: 0.0394 - conv2d_95_loss: 0.0326 - conv2d_127_loss: 0.0292(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71845753 0.55553204 0.59171695 0.69819492 0.69917762 0.59939605\n",
      " 0.54887056 0.77054399 0.91984361 0.91871506 0.89293456 0.64159477\n",
      " 0.69859552 0.80953044 0.82285714 0.69091421 0.63690311] @epoch 43\n",
      "Epoch 044: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 328s 285ms/step - loss: 0.1013 - conv2d_63_loss: 0.0394 - conv2d_95_loss: 0.0326 - conv2d_127_loss: 0.0292 - val_loss: 0.1253 - val_conv2d_63_loss: 0.0436 - val_conv2d_95_loss: 0.0412 - val_conv2d_127_loss: 0.0405\n",
      "Counter: 1, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 45/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1012 - conv2d_63_loss: 0.0394 - conv2d_95_loss: 0.0326 - conv2d_127_loss: 0.0292(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71879135 0.55087793 0.58920187 0.69978338 0.70004326 0.59906054\n",
      " 0.55161494 0.77416086 0.919285   0.91899443 0.89221209 0.64244312\n",
      " 0.69971907 0.81106311 0.824669   0.69119507 0.63633794] @epoch 44\n",
      "Epoch 045: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 326s 283ms/step - loss: 0.1012 - conv2d_63_loss: 0.0394 - conv2d_95_loss: 0.0326 - conv2d_127_loss: 0.0292 - val_loss: 0.1254 - val_conv2d_63_loss: 0.0436 - val_conv2d_95_loss: 0.0412 - val_conv2d_127_loss: 0.0406\n",
      "Counter: 2, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 46/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1010 - conv2d_63_loss: 0.0394 - conv2d_95_loss: 0.0326 - conv2d_127_loss: 0.0291(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71767341 0.5515126  0.58819586 0.69833934 0.69917762 0.59889281\n",
      " 0.5486595  0.77083331 0.91956431 0.91927373 0.89076722 0.63933265\n",
      " 0.6991573  0.81036645 0.82327527 0.68908858 0.63633794] @epoch 45\n",
      "Epoch 046: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 326s 283ms/step - loss: 0.1010 - conv2d_63_loss: 0.0394 - conv2d_95_loss: 0.0326 - conv2d_127_loss: 0.0291 - val_loss: 0.1256 - val_conv2d_63_loss: 0.0436 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0407\n",
      "Counter: 3, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 47/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1009 - conv2d_63_loss: 0.0394 - conv2d_95_loss: 0.0325 - conv2d_127_loss: 0.0290(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.7180342  0.55172414 0.58869886 0.69920576 0.70033187 0.59855729\n",
      " 0.54887056 0.77097803 0.91984361 0.91927373 0.89206761 0.64300865\n",
      " 0.69733149 0.80953044 0.82313591 0.68950993 0.63647926] @epoch 46\n",
      "Epoch 047: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 328s 285ms/step - loss: 0.1009 - conv2d_63_loss: 0.0394 - conv2d_95_loss: 0.0325 - conv2d_127_loss: 0.0290 - val_loss: 0.1255 - val_conv2d_63_loss: 0.0436 - val_conv2d_95_loss: 0.0412 - val_conv2d_127_loss: 0.0406\n",
      "Counter: 4, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 48/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1009 - conv2d_63_loss: 0.0394 - conv2d_95_loss: 0.0325 - conv2d_127_loss: 0.0290(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71799175 0.54876244 0.59087861 0.6968953  0.70047611 0.6009059\n",
      " 0.5492928  0.77184606 0.92012286 0.91787708 0.89336801 0.63933265\n",
      " 0.6991573  0.8100878  0.82160276 0.68922901 0.63803333] @epoch 47\n",
      "Epoch 048: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 325s 282ms/step - loss: 0.1009 - conv2d_63_loss: 0.0394 - conv2d_95_loss: 0.0325 - conv2d_127_loss: 0.0290 - val_loss: 0.1256 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0407\n",
      "Counter: 5, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 49/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1008 - conv2d_63_loss: 0.0393 - conv2d_95_loss: 0.0325 - conv2d_127_loss: 0.0290(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71668467 0.54685849 0.58635145 0.69458485 0.70004326 0.59788626\n",
      " 0.54781508 0.76996529 0.92026252 0.91745812 0.89293456 0.63919127\n",
      " 0.69985956 0.81050581 0.82076657 0.68712258 0.63534898] @epoch 48\n",
      "Epoch 049: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 326s 284ms/step - loss: 0.1008 - conv2d_63_loss: 0.0393 - conv2d_95_loss: 0.0325 - conv2d_127_loss: 0.0290 - val_loss: 0.1256 - val_conv2d_63_loss: 0.0436 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0407\n",
      "Counter: 6, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 50/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1006 - conv2d_63_loss: 0.0393 - conv2d_95_loss: 0.0324 - conv2d_127_loss: 0.0289(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71657764 0.5485509  0.5876928  0.69588447 0.69571489 0.59654421\n",
      " 0.54528183 0.76895255 0.92068148 0.91899443 0.89163417 0.64088786\n",
      " 0.69887638 0.8100878  0.82313591 0.68838644 0.63393617] @epoch 49\n",
      "Epoch 050: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 325s 282ms/step - loss: 0.1006 - conv2d_63_loss: 0.0393 - conv2d_95_loss: 0.0324 - conv2d_127_loss: 0.0289 - val_loss: 0.1256 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0407\n",
      "Counter: 7, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 050: Updating Learning rate.. New value is 0.000054\n",
      "Epoch 51/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1004 - conv2d_63_loss: 0.0393 - conv2d_95_loss: 0.0323 - conv2d_127_loss: 0.0288(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71740047 0.54918551 0.5885312  0.6968953  0.69831192 0.59755075\n",
      " 0.54908168 0.76953125 0.92096078 0.9182961  0.89279008 0.64102924\n",
      " 0.6991573  0.81078446 0.82257837 0.6903525  0.633371  ] @epoch 50\n",
      "Epoch 051: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 327s 284ms/step - loss: 0.1004 - conv2d_63_loss: 0.0393 - conv2d_95_loss: 0.0323 - conv2d_127_loss: 0.0288 - val_loss: 0.1257 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0407\n",
      "Counter: 0, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 52/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1003 - conv2d_63_loss: 0.0393 - conv2d_95_loss: 0.0323 - conv2d_127_loss: 0.0287(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71700108 0.55003172 0.58735746 0.6938628  0.69860047 0.59738296\n",
      " 0.54760396 0.76938659 0.92096078 0.91745812 0.89279008 0.64117062\n",
      " 0.69845504 0.8102271  0.82285714 0.68908858 0.63478386] @epoch 51\n",
      "Epoch 052: val_acc did not improve from 0.724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1151/1151 [==============================] - 325s 282ms/step - loss: 0.1003 - conv2d_63_loss: 0.0393 - conv2d_95_loss: 0.0323 - conv2d_127_loss: 0.0287 - val_loss: 0.1257 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 1, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 53/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1003 - conv2d_63_loss: 0.0393 - conv2d_95_loss: 0.0323 - conv2d_127_loss: 0.0287(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71674663 0.54960865 0.5876928  0.69559568 0.69701344 0.59687972\n",
      " 0.54654843 0.76909721 0.92165899 0.9182961  0.89250106 0.64003956\n",
      " 0.69733149 0.81036645 0.8229965  0.68880773 0.63351232] @epoch 52\n",
      "Epoch 053: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 329s 286ms/step - loss: 0.1003 - conv2d_63_loss: 0.0393 - conv2d_95_loss: 0.0323 - conv2d_127_loss: 0.0287 - val_loss: 0.1257 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 2, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 54/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1003 - conv2d_63_loss: 0.0393 - conv2d_95_loss: 0.0323 - conv2d_127_loss: 0.0287(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71713582 0.55024326 0.58786052 0.69574004 0.69730198 0.59822178\n",
      " 0.54760396 0.77126735 0.92054182 0.9170391  0.89221209 0.64060509\n",
      " 0.69929773 0.81036645 0.82327527 0.68979079 0.63280588] @epoch 53\n",
      "Epoch 054: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 325s 283ms/step - loss: 0.1003 - conv2d_63_loss: 0.0393 - conv2d_95_loss: 0.0323 - conv2d_127_loss: 0.0287 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 3, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 55/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1003 - conv2d_63_loss: 0.0393 - conv2d_95_loss: 0.0323 - conv2d_127_loss: 0.0287(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71681061 0.55024326 0.58651912 0.69545126 0.69802338 0.60040259\n",
      " 0.54507071 0.77083331 0.92040217 0.91759777 0.89192313 0.64060509\n",
      " 0.69789326 0.80980909 0.82355398 0.68599916 0.63464254] @epoch 54\n",
      "Epoch 055: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 326s 284ms/step - loss: 0.1003 - conv2d_63_loss: 0.0393 - conv2d_95_loss: 0.0323 - conv2d_127_loss: 0.0287 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 4, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 56/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1002 - conv2d_63_loss: 0.0393 - conv2d_95_loss: 0.0323 - conv2d_127_loss: 0.0287(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71677539 0.54685849 0.58802819 0.69646209 0.69816768 0.59855729\n",
      " 0.54570401 0.76895255 0.92110038 0.91759777 0.89250106 0.64159477\n",
      " 0.69901687 0.81120247 0.82146341 0.68726301 0.63393617] @epoch 55\n",
      "Epoch 056: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 326s 284ms/step - loss: 0.1002 - conv2d_63_loss: 0.0393 - conv2d_95_loss: 0.0323 - conv2d_127_loss: 0.0287 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 5, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 57/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1002 - conv2d_63_loss: 0.0393 - conv2d_95_loss: 0.0323 - conv2d_127_loss: 0.0287(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71668594 0.54643536 0.58651912 0.69444042 0.69715768 0.59771848\n",
      " 0.54633737 0.77199072 0.92054182 0.91745812 0.8926456  0.64088786\n",
      " 0.69803369 0.81092376 0.8229965  0.68824601 0.63464254] @epoch 56\n",
      "Epoch 057: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 326s 283ms/step - loss: 0.1002 - conv2d_63_loss: 0.0393 - conv2d_95_loss: 0.0323 - conv2d_127_loss: 0.0287 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 6, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 58/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1002 - conv2d_63_loss: 0.0393 - conv2d_95_loss: 0.0323 - conv2d_127_loss: 0.0287(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71649485 0.54812777 0.58534539 0.6938628  0.69860047 0.59889281\n",
      " 0.54570401 0.76967591 0.91998327 0.91662014 0.8926456  0.64032233\n",
      " 0.69775283 0.81092376 0.82341462 0.68740344 0.63464254] @epoch 57\n",
      "Epoch 058: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 327s 284ms/step - loss: 0.1002 - conv2d_63_loss: 0.0393 - conv2d_95_loss: 0.0323 - conv2d_127_loss: 0.0287 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 7, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 058: Updating Learning rate.. New value is 0.000011\n",
      "Epoch 59/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1002 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0323 - conv2d_127_loss: 0.0287(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71642235 0.55024326 0.58635145 0.69487363 0.69686913 0.59889281\n",
      " 0.54549295 0.77039933 0.92012286 0.91620111 0.89250106 0.63933265\n",
      " 0.69747192 0.8100878  0.82229966 0.68810558 0.63351232] @epoch 58\n",
      "Epoch 059: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 326s 283ms/step - loss: 0.1002 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0323 - conv2d_127_loss: 0.0287 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 0, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 60/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71635989 0.5485509  0.58433938 0.69574004 0.69658059 0.59872502\n",
      " 0.54654843 0.76924187 0.91998327 0.9170391  0.89279008 0.63989818\n",
      " 0.69845504 0.80966979 0.8229965  0.68712258 0.63407743] @epoch 59\n",
      "Epoch 060: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 324s 282ms/step - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 1, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 61/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0287(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71667156 0.54918551 0.58517772 0.69501805 0.69816768 0.59872502\n",
      " 0.54612625 0.76982063 0.92040217 0.91759777 0.89221209 0.64003956\n",
      " 0.6991573  0.81120247 0.82327527 0.6867013  0.63393617] @epoch 60\n",
      "Epoch 061: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 327s 284ms/step - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0287 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 2, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 62/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71644971 0.55003172 0.58551306 0.69444042 0.69874477 0.59889281\n",
      " 0.54570401 0.76953125 0.92040217 0.91662014 0.89250106 0.63933265\n",
      " 0.697191   0.80994844 0.82257837 0.68740344 0.63436002] @epoch 61\n",
      "Epoch 062: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 327s 284ms/step - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter: 3, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 63/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71656448 0.55024326 0.58584845 0.69588447 0.69845623 0.59906054\n",
      " 0.54739285 0.76967591 0.92026252 0.91717875 0.8913452  0.64032233\n",
      " 0.69747192 0.8102271  0.82285714 0.68599916 0.63280588] @epoch 62\n",
      "Epoch 063: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 326s 283ms/step - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 4, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 64/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71660992 0.54918551 0.58366865 0.69588447 0.69816768 0.59872502\n",
      " 0.54633737 0.76996529 0.92040217 0.91773742 0.89206761 0.63989818\n",
      " 0.69817418 0.81036645 0.82355398 0.68698215 0.63464254] @epoch 63\n",
      "Epoch 064: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 326s 283ms/step - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 5, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 65/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71660296 0.54939705 0.58433938 0.6938628  0.69802338 0.59755075\n",
      " 0.54697067 0.77054399 0.92040217 0.91787708 0.89192313 0.641312\n",
      " 0.69887638 0.8102271  0.82285714 0.68684173 0.63464254] @epoch 64\n",
      "Epoch 065: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 329s 286ms/step - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 6, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 66/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71646432 0.55003172 0.58568072 0.69472927 0.69658059 0.59906054\n",
      " 0.54485959 0.76996529 0.92012286 0.9182961  0.89120072 0.63933265\n",
      " 0.69887638 0.8106451  0.82355398 0.68712258 0.633371  ] @epoch 65\n",
      "Epoch 066: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 326s 283ms/step - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 7, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 066: Updating Learning rate.. New value is 0.000002\n",
      "Epoch 67/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71676235 0.55024326 0.58601612 0.69660652 0.69730198 0.59989935\n",
      " 0.54633737 0.76895255 0.92082113 0.91731846 0.89206761 0.64018095\n",
      " 0.69817418 0.8100878  0.82313591 0.68782473 0.63322973] @epoch 66\n",
      "Epoch 067: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 329s 286ms/step - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 0, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 68/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71650621 0.54876244 0.58702213 0.69501805 0.69701344 0.59671193\n",
      " 0.54591513 0.77054399 0.92040217 0.91815645 0.89192313 0.64046371\n",
      " 0.69901687 0.80980909 0.82383275 0.68656087 0.63294715] @epoch 67\n",
      "Epoch 068: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 326s 283ms/step - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 1, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 69/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.7165142  0.5477047  0.58601612 0.69444042 0.69802338 0.59922832\n",
      " 0.54612625 0.77010995 0.92040217 0.9170391  0.89235657 0.641312\n",
      " 0.69747192 0.8102271  0.8229965  0.6876843  0.63308847] @epoch 68\n",
      "Epoch 069: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 325s 282ms/step - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 2, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 70/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71619211 0.55003172 0.58350098 0.69415164 0.69686913 0.59704745\n",
      " 0.54612625 0.76953125 0.91970396 0.91759777 0.89120072 0.63947403\n",
      " 0.69747192 0.81092376 0.82425088 0.68838644 0.63280588] @epoch 69\n",
      "Epoch 070: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 325s 283ms/step - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 3, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 71/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.716542   0.54876244 0.58517772 0.69530684 0.69787908 0.59855729\n",
      " 0.54633737 0.76924187 0.92040217 0.91773742 0.89221209 0.64102924\n",
      " 0.69775283 0.81078446 0.82285714 0.68726301 0.633371  ] @epoch 70\n",
      "Epoch 071: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 325s 282ms/step - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 4, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 72/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71652158 0.54876244 0.58735746 0.69357401 0.69701344 0.59805399\n",
      " 0.54654843 0.76837385 0.92012286 0.91843575 0.89192313 0.63989818\n",
      " 0.69943821 0.8102271  0.82341462 0.68684173 0.63436002] @epoch 71\n",
      "Epoch 072: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 324s 281ms/step - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 5, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 73/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1000 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validate accuracy:\n",
      " [0.71662611 0.55045485 0.58685446 0.694296   0.69715768 0.59805399\n",
      " 0.54570401 0.76953125 0.92012286 0.91801673 0.89206761 0.64088786\n",
      " 0.69705057 0.81120247 0.82327527 0.68698215 0.63436002] @epoch 72\n",
      "Epoch 073: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 325s 283ms/step - loss: 0.1000 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0414 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 6, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 74/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71655862 0.54897398 0.58618379 0.69415164 0.69845623 0.59889281\n",
      " 0.54633737 0.76837385 0.92026252 0.91731846 0.89235657 0.64060509\n",
      " 0.69817418 0.80994844 0.8229965  0.68712258 0.63478386] @epoch 73\n",
      "Epoch 074: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 328s 285ms/step - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 7, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 074: Updating Learning rate.. New value is 0.000000\n",
      "Epoch 75/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.7167838  0.54897398 0.58551306 0.69602889 0.69802338 0.60006708\n",
      " 0.54528183 0.77068865 0.92026252 0.91717875 0.89192313 0.64117062\n",
      " 0.69747192 0.81106311 0.82397211 0.68642044 0.63450128] @epoch 74\n",
      "Epoch 075: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 325s 282ms/step - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 0, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 76/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71646047 0.54897398 0.58501005 0.69516248 0.69686913 0.59805399\n",
      " 0.54464853 0.76953125 0.92012286 0.91717875 0.89250106 0.64088786\n",
      " 0.69845504 0.81050581 0.82271779 0.68796515 0.63478386] @epoch 75\n",
      "Epoch 076: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 325s 282ms/step - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 1, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 77/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71640062 0.54918551 0.58635145 0.69458485 0.69802338 0.59838951\n",
      " 0.54591513 0.76909721 0.92068148 0.91773742 0.8913452  0.64102924\n",
      " 0.69634831 0.81036645 0.8229965  0.68613958 0.63421869] @epoch 76\n",
      "Epoch 077: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 326s 283ms/step - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 2, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 78/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71682011 0.54918551 0.58702213 0.69574004 0.69874477 0.59872502\n",
      " 0.54464853 0.76982063 0.92096078 0.91745812 0.89235657 0.64117062\n",
      " 0.697191   0.81092376 0.82369339 0.68740344 0.63407743] @epoch 77\n",
      "Epoch 078: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 325s 283ms/step - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 3, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 79/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71654063 0.5485509  0.58517772 0.69501805 0.69773483 0.59872502\n",
      " 0.54549295 0.77097803 0.92054182 0.91759777 0.89192313 0.63876712\n",
      " 0.69803369 0.8106451  0.82285714 0.68810558 0.63450128] @epoch 78\n",
      "Epoch 079: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 327s 284ms/step - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 4, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 80/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.7163864  0.54918551 0.58584845 0.69602889 0.69802338 0.59755075\n",
      " 0.54570401 0.76953125 0.92026252 0.91731846 0.89177865 0.64074647\n",
      " 0.69705057 0.8100878  0.82285714 0.68754387 0.63266462] @epoch 79\n",
      "Epoch 080: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 327s 284ms/step - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 5, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 81/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.7164099  0.54918551 0.58618379 0.69458485 0.69874477 0.59704745\n",
      " 0.54739285 0.76924187 0.92054182 0.91801673 0.89206761 0.63947403\n",
      " 0.69733149 0.81050581 0.82188153 0.68613958 0.63421869] @epoch 80\n",
      "Epoch 081: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 325s 283ms/step - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0414 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 6, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 82/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.7164082  0.54812777 0.58450705 0.69487363 0.69816768 0.59805399\n",
      " 0.54570401 0.77054399 0.92040217 0.91815645 0.89192313 0.64046371\n",
      " 0.69817418 0.8102271  0.82327527 0.6867013  0.63322973] @epoch 81\n",
      "Epoch 082: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 326s 283ms/step - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0414 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 7, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 082: Updating Learning rate.. New value is 0.000000\n",
      "Epoch 83/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71604688 0.54897398 0.58501005 0.69357401 0.69658059 0.59704745\n",
      " 0.54485959 0.76996529 0.91984361 0.91773742 0.89192313 0.63933265\n",
      " 0.69803369 0.80994844 0.82229966 0.6876843  0.63393617] @epoch 82\n",
      "Epoch 083: val_acc did not improve from 0.724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1151/1151 [==============================] - 327s 284ms/step - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0414 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 0, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 84/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71652748 0.54939705 0.58601612 0.69545126 0.69701344 0.59687972\n",
      " 0.54591513 0.76967591 0.92054182 0.91745812 0.89192313 0.64060509\n",
      " 0.69845504 0.81162047 0.82313591 0.68726301 0.63308847] @epoch 83\n",
      "Epoch 084: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 326s 283ms/step - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0414 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 1, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 85/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71626018 0.54897398 0.58735746 0.694296   0.69787908 0.59822178\n",
      " 0.54485959 0.76953125 0.91970396 0.91759777 0.89192313 0.63989818\n",
      " 0.69691008 0.8102271  0.82369339 0.68557787 0.63351232] @epoch 84\n",
      "Epoch 085: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 327s 284ms/step - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 2, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 86/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71664874 0.54939705 0.58601612 0.69458485 0.69787908 0.59855729\n",
      " 0.54528183 0.77083331 0.92082113 0.91801673 0.89235657 0.64088786\n",
      " 0.69859552 0.81036645 0.82313591 0.68642044 0.63322973] @epoch 85\n",
      "Epoch 086: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 325s 283ms/step - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 3, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 87/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.7168975  0.55045485 0.58534539 0.69545126 0.69802338 0.59939605\n",
      " 0.54591513 0.77097803 0.92110038 0.9182961  0.89177865 0.64046371\n",
      " 0.6991573  0.8102271  0.8229965  0.68712258 0.63365358] @epoch 86\n",
      "Epoch 087: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 328s 285ms/step - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 4, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 88/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71666268 0.54918551 0.58568072 0.6938628  0.69831192 0.59788626\n",
      " 0.54675955 0.77010995 0.92012286 0.91745812 0.89221209 0.63961542\n",
      " 0.69985956 0.81078446 0.82327527 0.68782473 0.63365358] @epoch 87\n",
      "Epoch 088: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 325s 282ms/step - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 5, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 89/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71676851 0.54939705 0.58534539 0.69588447 0.69759053 0.59721524\n",
      " 0.54781508 0.76996529 0.92026252 0.91843575 0.89192313 0.64074647\n",
      " 0.69747192 0.81078446 0.82341462 0.6876843  0.63436002] @epoch 88\n",
      "Epoch 089: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 326s 283ms/step - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 6, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 90/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71672844 0.54960865 0.58551306 0.69357401 0.69802338 0.59838951\n",
      " 0.54633737 0.77112269 0.92082113 0.91815645 0.89177865 0.64159477\n",
      " 0.69747192 0.81092376 0.82285714 0.68712258 0.63436002] @epoch 89\n",
      "Epoch 090: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 328s 285ms/step - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 7, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 090: Updating Learning rate.. New value is 0.000000\n",
      "Epoch 91/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.7166703  0.54918551 0.58702213 0.69487363 0.69773483 0.59889281\n",
      " 0.54549295 0.76996529 0.92068148 0.91773742 0.89221209 0.64088786\n",
      " 0.69817418 0.81050581 0.82257837 0.68642044 0.63436002] @epoch 90\n",
      "Epoch 091: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 325s 283ms/step - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 0, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 92/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.7166616  0.54982018 0.58568072 0.69516248 0.69874477 0.59822178\n",
      " 0.54485959 0.77097803 0.92096078 0.91773742 0.89206761 0.64046371\n",
      " 0.69817418 0.8100878  0.82341462 0.68698215 0.63322973] @epoch 91\n",
      "Epoch 092: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 326s 283ms/step - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 1, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 93/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71623455 0.54812777 0.58551306 0.69588447 0.69614774 0.59872502\n",
      " 0.54507071 0.76909721 0.91970396 0.91759777 0.89250106 0.64018095\n",
      " 0.69845504 0.80911243 0.82243901 0.6876843  0.63351232] @epoch 92\n",
      "Epoch 093: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 328s 285ms/step - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter: 2, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 94/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.7167599  0.55003172 0.58618379 0.69530684 0.69845623 0.59771848\n",
      " 0.54612625 0.76996529 0.92110038 0.9182961  0.89206761 0.64003956\n",
      " 0.69873595 0.81134176 0.82327527 0.6857183  0.63379484] @epoch 93\n",
      "Epoch 094: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 326s 283ms/step - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 3, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 95/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.7164296  0.54876244 0.58568072 0.69487363 0.69845623 0.59755075\n",
      " 0.54528183 0.77054399 0.91970396 0.91731846 0.89206761 0.64018095\n",
      " 0.69831461 0.81036645 0.82285714 0.68754387 0.633371  ] @epoch 94\n",
      "Epoch 095: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 326s 283ms/step - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 4, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 96/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71672133 0.54960865 0.58584845 0.69472927 0.69802338 0.59755075\n",
      " 0.54528183 0.77054399 0.91984361 0.91857541 0.89235657 0.64159477\n",
      " 0.69705057 0.8106451  0.82327527 0.68698215 0.63563156] @epoch 95\n",
      "Epoch 096: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 328s 285ms/step - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 5, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 97/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.7169782  0.55003172 0.58618379 0.69631767 0.69961047 0.59755075\n",
      " 0.54718179 0.76967591 0.92040217 0.91815645 0.89235657 0.64145339\n",
      " 0.69817418 0.81078446 0.82355398 0.68599916 0.63421869] @epoch 96\n",
      "Epoch 097: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 326s 284ms/step - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 6, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 98/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1000 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71674998 0.55130106 0.58534539 0.69415164 0.69831192 0.59939605\n",
      " 0.54612625 0.76924187 0.92068148 0.91759777 0.89250106 0.64088786\n",
      " 0.697191   0.81050581 0.82313591 0.68698215 0.63464254] @epoch 97\n",
      "Epoch 098: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 328s 285ms/step - loss: 0.1000 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 7, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 098: Updating Learning rate.. New value is 0.000000\n",
      "Epoch 99/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71654986 0.5485509  0.58685446 0.6938628  0.69802338 0.59771848\n",
      " 0.54570401 0.76982063 0.92054182 0.91773742 0.8926456  0.64003956\n",
      " 0.69775283 0.8100878  0.82341462 0.68782473 0.63421869] @epoch 98\n",
      "Epoch 099: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 327s 284ms/step - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 0, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 100/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71661269 0.5477047  0.58702213 0.69545126 0.69787908 0.59822178\n",
      " 0.54654843 0.77054399 0.92026252 0.91731846 0.89177865 0.64102924\n",
      " 0.69761235 0.80953044 0.82271779 0.68824601 0.63393617] @epoch 99\n",
      "Epoch 100: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 325s 283ms/step - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 1, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 101/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71713734 0.54982018 0.58618379 0.69545126 0.69802338 0.59838951\n",
      " 0.54718179 0.77039933 0.92054182 0.91787708 0.89221209 0.64102924\n",
      " 0.69887638 0.81106311 0.82327527 0.68894815 0.63492513] @epoch 100\n",
      "Epoch 101: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 327s 284ms/step - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 2, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 102/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71646611 0.54876244 0.58501005 0.69559568 0.69744623 0.59838951\n",
      " 0.54654843 0.77010995 0.92026252 0.91745812 0.8926456  0.63919127\n",
      " 0.697191   0.8106451  0.82229966 0.68782473 0.63407743] @epoch 101\n",
      "Epoch 102: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 326s 283ms/step - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 3, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 103/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n",
      "\n",
      "validate accuracy:\n",
      " [0.71625187 0.54876244 0.58685446 0.69328523 0.69686913 0.59704745\n",
      " 0.54654843 0.76924187 0.92054182 0.91717875 0.8913452  0.64018095\n",
      " 0.69733149 0.81050581 0.8229965  0.68726301 0.63407743] @epoch 102\n",
      "Epoch 103: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 327s 284ms/step - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 4, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 104/201\n",
      "1151/1151 [==============================] - ETA: 0s - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286(3, 2407, 64, 64, 16)\n",
      "(7221, 64, 64, 16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validate accuracy:\n",
      " [0.71654922 0.54918551 0.58568072 0.69602889 0.69643629 0.59939605\n",
      " 0.54549295 0.77083331 0.92012286 0.9170391  0.89192313 0.64032233\n",
      " 0.69662923 0.80980909 0.82327527 0.68712258 0.63549024] @epoch 103\n",
      "Epoch 104: val_acc did not improve from 0.724\n",
      "1151/1151 [==============================] - 325s 282ms/step - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286 - val_loss: 0.1258 - val_conv2d_63_loss: 0.0437 - val_conv2d_95_loss: 0.0413 - val_conv2d_127_loss: 0.0408\n",
      "Counter: 5, Global: 0.723698265850544, MyBest: 0.723698265850544\n",
      "\n",
      "Epoch 105/201\n",
      " 956/1151 [=======================>......] - ETA: 43s - loss: 0.1001 - conv2d_63_loss: 0.0392 - conv2d_95_loss: 0.0322 - conv2d_127_loss: 0.0286"
     ]
    }
   ],
   "source": [
    "\n",
    "net.compile(optimizer=optimizer, loss=weighted_mse_loss, metrics=[])\n",
    "#checkpointer = ModelCheckpoint(filepath=f'../cunet{nUNet}_{m}{n}_best.h5', verbose=1, monitor='val_loss', mode='auto', save_best_only=True)\n",
    "history = net.fit(train_images,[train_hms,train_hms,train_hms],validation_data=(eval_images,eval_hms2),epochs=201, batch_size=16,shuffle=True,verbose=1, callbacks=[evalcallback,updateLR])#,use_multiprocessing=True,workers=20)#[checkpointer,updateLR])\n",
    "#np.savez_compressed(\"../history\",history)\n",
    "net.save_weights(f'../cunet{nUNet}_{m}{n}_last_sigmoidAdamQuasiDef3sx12_restartsig8_4_6416_2S.h5', overwrite=True)\n",
    "np.save('../history_sigmoidAdamQuasiDef3sx12_restartsig8_4_6416_2S.npy',history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "net.load_weights(\"../cunet2_6416_last_sigmoidAdamQuasiDef3sx12.h5\")\n",
    "output = net.predict(train_images)\n",
    "output = np.transpose(output,(0,3,1,2))\n",
    "print(accuracy(output,np.transpose(train_hms,(0,3,1,2))))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ho aumentato solo patience   7221\n",
    "#Provato con dropout ma andato male"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
