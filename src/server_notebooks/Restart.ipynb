{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setGPU: Setting GPU to: 0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import setGPU\n",
    "import gc\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "160\n",
      "240\n",
      "320\n",
      "96\n",
      "192\n",
      "288\n",
      "384\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 128, 128, 64) 9408        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 128, 128, 64) 256         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 128, 128, 64) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 64, 64, 64)   0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 64, 64)   256         max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 64, 64)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 64)   4096        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 64, 64, 64)   256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 64, 64, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 64, 64, 16)   9216        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 64, 64, 80)   0           max_pooling2d[0][0]              \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 64, 64, 80)   320         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 64, 64, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 64, 64)   5120        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 64)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 64)   256         max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 64)   4096        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 64)   256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 16)   9216        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 80)   0           max_pooling2d_1[0][0]            \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 80)   320         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 80)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 64)   5120        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 64)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 64)   256         max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 64)   4096        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 64)   256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 64)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 16)   9216        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 16, 16, 80)   0           max_pooling2d_2[0][0]            \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 80)   320         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 80)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 64)   5120        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 64)     0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 8, 8, 64)     256         max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 8, 8, 64)     0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 8, 8, 64)     4096        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 8, 8, 64)     256         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 8, 8, 64)     0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 8, 8, 16)     9216        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 8, 8, 80)     0           max_pooling2d_3[0][0]            \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 8, 8, 80)     320         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 8, 8, 80)     0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 8, 8, 64)     5120        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 4, 4, 64)     0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 4, 4, 64)     256         max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 4, 4, 64)     0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 4, 4, 64)     4096        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 4, 4, 64)     256         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 4, 4, 64)     0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 8, 8, 80)     320         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 4, 4, 16)     9216        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 8, 8, 80)     0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 4, 4, 80)     0           max_pooling2d_4[0][0]            \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 8, 8, 64)     5120        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 8, 8, 80)     0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 8, 8, 144)    0           conv2d_16[0][0]                  \n",
      "                                                                 up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 8, 8, 144)    576         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 8, 8, 144)    0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 8, 8, 64)     9216        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 8, 8, 64)     256         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 8, 8, 64)     0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 80)   320         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 8, 8, 16)     9216        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 80)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 8, 8, 160)    0           concatenate_5[0][0]              \n",
      "                                                                 conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 64)   5120        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 16, 16, 160)  0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 16, 16, 224)  0           conv2d_12[0][0]                  \n",
      "                                                                 up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 16, 224)  896         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 224)  0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 16, 16, 64)   14336       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 16, 64)   256         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 64)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 80)   320         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 16, 16, 16)   9216        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 80)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 16, 16, 240)  0           concatenate_7[0][0]              \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 64)   5120        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 32, 32, 240)  0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 32, 32, 304)  0           conv2d_8[0][0]                   \n",
      "                                                                 up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 32, 32, 304)  1216        concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 32, 32, 304)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 32, 32, 64)   19456       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 32, 32, 64)   256         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 32, 32, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 64, 64, 80)   320         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 32, 32, 16)   9216        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 64, 64, 80)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 32, 32, 320)  0           concatenate_9[0][0]              \n",
      "                                                                 conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 64)   5120        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 64, 64, 320)  0           concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 64, 64, 384)  0           conv2d_4[0][0]                   \n",
      "                                                                 up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 64, 64, 384)  1536        concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 64, 64, 384)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 64, 64, 64)   24576       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 64, 64, 64)   256         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 64, 64, 64)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 64, 64, 16)   9216        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 64, 64, 400)  0           concatenate_11[0][0]             \n",
      "                                                                 conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 64, 64, 464)  0           max_pooling2d[0][0]              \n",
      "                                                                 concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 64, 64, 464)  1856        concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 64, 64, 464)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 64, 64, 64)   29696       activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 64, 64, 80)   0           conv2d_31[0][0]                  \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 64, 64, 80)   320         concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 64, 64, 80)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 64, 64, 64)   5120        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 64, 64, 64)   256         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 64, 64, 64)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 64, 64, 16)   9216        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 64, 64, 96)   0           concatenate_14[0][0]             \n",
      "                                                                 conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 64, 64, 96)   384         concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 64, 64, 96)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 64, 64, 64)   6144        activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 32, 32, 64)   0           conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 32, 32, 80)   0           max_pooling2d_5[0][0]            \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 32, 32, 80)   320         concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 32, 32, 80)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 32, 32, 64)   5120        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 32, 32, 64)   256         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 32, 32, 64)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 32, 32, 16)   9216        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 32, 32, 96)   0           concatenate_16[0][0]             \n",
      "                                                                 conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 32, 32, 96)   384         concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 32, 32, 96)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 32, 32, 64)   6144        activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 16, 16, 64)   0           conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 16, 16, 80)   0           max_pooling2d_6[0][0]            \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 16, 16, 80)   320         concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 16, 16, 80)   0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 16, 16, 64)   5120        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 16, 16, 64)   256         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 16, 16, 64)   0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 16, 16, 16)   9216        activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 16, 16, 96)   0           concatenate_18[0][0]             \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 16, 16, 96)   384         concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 16, 16, 96)   0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 16, 16, 64)   6144        activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 8, 8, 64)     0           conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 8, 8, 80)     0           max_pooling2d_7[0][0]            \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 8, 8, 80)     320         concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 8, 8, 80)     0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 8, 8, 64)     5120        activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 8, 8, 64)     256         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 8, 8, 64)     0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 8, 8, 16)     9216        activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 8, 8, 96)     0           concatenate_20[0][0]             \n",
      "                                                                 conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 8, 8, 96)     384         concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 8, 8, 96)     0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 8, 8, 64)     6144        activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 4, 4, 64)     0           conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 4, 4, 80)     0           max_pooling2d_8[0][0]            \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 4, 4, 80)     320         concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 4, 4, 80)     0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 4, 4, 64)     5120        activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 4, 4, 64)     256         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 4, 4, 64)     0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 8, 8, 96)     384         concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 4, 4, 16)     9216        activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 8, 8, 96)     0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 4, 4, 96)     0           concatenate_22[0][0]             \n",
      "                                                                 conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 8, 8, 64)     6144        activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 8, 8, 96)     0           concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 8, 8, 176)    0           conv2d_47[0][0]                  \n",
      "                                                                 up_sampling2d_4[0][0]            \n",
      "                                                                 conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 8, 8, 176)    704         concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 8, 8, 176)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 8, 8, 64)     11264       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 8, 8, 64)     256         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 8, 8, 64)     0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 16, 16, 96)   384         concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 8, 8, 16)     9216        activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 16, 16, 96)   0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 8, 8, 192)    0           concatenate_24[0][0]             \n",
      "                                                                 conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 16, 16, 64)   6144        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 16, 16, 192)  0           concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 16, 16, 272)  0           conv2d_43[0][0]                  \n",
      "                                                                 up_sampling2d_5[0][0]            \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 16, 16, 272)  1088        concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 16, 16, 272)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 16, 16, 64)   17408       activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 16, 16, 64)   256         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 16, 16, 64)   0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 32, 32, 96)   384         concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 16, 16, 16)   9216        activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 32, 32, 96)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 16, 16, 288)  0           concatenate_26[0][0]             \n",
      "                                                                 conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 32, 32, 64)   6144        activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2D)  (None, 32, 32, 288)  0           concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 32, 32, 368)  0           conv2d_39[0][0]                  \n",
      "                                                                 up_sampling2d_6[0][0]            \n",
      "                                                                 conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 32, 32, 368)  1472        concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 32, 32, 368)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 32, 32, 64)   23552       activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 32, 32, 64)   256         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 32, 32, 64)   0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 64, 64, 96)   384         concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 32, 32, 16)   9216        activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 64, 64, 96)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 32, 32, 384)  0           concatenate_28[0][0]             \n",
      "                                                                 conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 64, 64, 64)   6144        activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2D)  (None, 64, 64, 384)  0           concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 64, 64, 464)  0           conv2d_35[0][0]                  \n",
      "                                                                 up_sampling2d_7[0][0]            \n",
      "                                                                 conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 64, 64, 464)  1856        concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 64, 64, 464)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 64, 64, 64)   29696       activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 64, 64, 64)   256         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 64, 64, 64)   0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 64, 64, 16)   9216        activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 64, 64, 480)  0           concatenate_30[0][0]             \n",
      "                                                                 conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 64, 64, 480)  1920        concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 64, 64, 480)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 64, 64, 16)   7680        activation_62[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 524,864\n",
      "Trainable params: 511,616\n",
      "Non-trainable params: 13,248\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Definizione Modello\n",
    "def getUnit1(layerPrec, filters, kernel_size = (1, 1), activation='relu', kernel_initializer='he_normal'):\n",
    "  l = BatchNormalization()(layerPrec)\n",
    "  l = Activation('relu')(l)\n",
    "  l = Conv2D(filters, kernel_size, kernel_initializer=kernel_initializer, padding='same',use_bias=False)(l)\n",
    "  return l\n",
    "\n",
    "def getUnit2(layerPrec, filters, kernel_size = (3, 3), activation='relu', kernel_initializer='he_normal'):\n",
    "  l = BatchNormalization()(layerPrec)\n",
    "  l = Activation('relu')(l)\n",
    "  l = Conv2D(filters, kernel_size, kernel_initializer=kernel_initializer, padding='same',use_bias=False)(l)\n",
    "  return l\n",
    "\n",
    "def getDownBlock(layerPrec,m,n,indexBlock):\n",
    "  l = getUnit1(layerPrec,4*n)\n",
    "  l = getUnit2(l,n)\n",
    "  nets[\"layers\"][f\"down{indexBlock}\"].append(l)\n",
    "\n",
    "  concat = Concatenate()([layerPrec,l])\n",
    "  l = getUnit1(concat,m)\n",
    "  maxPooling = MaxPool2D(padding='same')(l)\n",
    "  return maxPooling, getUnit1(concat,m)\n",
    "\n",
    "def getUpBlock(layerPrec,skipConn,m,n,indexBlock,upLayers=[]):\n",
    "  l = getUnit1(layerPrec,m)\n",
    "  l = UpSampling2D()(layerPrec)\n",
    "  concat = Concatenate()([skipConn,l]+upLayers)\n",
    "  l = getUnit1(concat,4*n)\n",
    "  l = getUnit2(l,n)\n",
    "  nets[\"layers\"][f\"up{indexBlock}\"].append(l)\n",
    "  concat = Concatenate()([concat,l])\n",
    "  return concat\n",
    "\n",
    "def getUNet(input,m,n,indexUNet,nUNet, nBlocks):\n",
    "  layerPrec = input\n",
    "  listSkipConn = []\n",
    "\n",
    "  if indexUNet != 0:\n",
    "    layerPrec = nets[f\"unet{indexUNet-1}\"]\n",
    "    #layerPrec = Concatenate()([input,layerPrec]) #l'abbiamo fatto giù con l'if dopo l'up\n",
    "    layerPrec = getUnit1(layerPrec,m)\n",
    "\n",
    "  # down\n",
    "  for i in range(nBlocks):\n",
    "    if nets[\"layers\"][f\"down{i}\"]:\n",
    "        layerPrec = Concatenate()([layerPrec]+nets[\"layers\"][f\"down{i}\"])\n",
    "    layerPrec, skipConn = getDownBlock(layerPrec,m,n,i)\n",
    "    listSkipConn.append(skipConn)\n",
    "\n",
    "  # bottle neck\n",
    "  if nets[\"layers\"][f\"bn\"]:\n",
    "      layerPrec = Concatenate()([layerPrec]+nets[\"layers\"][f\"bn\"])\n",
    "\n",
    "  l = getUnit1(layerPrec,4*n)\n",
    "  l = getUnit2(l,n)\n",
    "  nets[\"layers\"][\"bn\"].append(l)\n",
    "  concat = Concatenate()([layerPrec,l])\n",
    "\n",
    "  # up\n",
    "  layerPrec = concat\n",
    "  for i in range(nBlocks):\n",
    "    layerPrec = getUpBlock(layerPrec,listSkipConn[-(i+1)],m,n,i,upLayers=nets[\"layers\"][f\"up{i}\"])\n",
    "\n",
    "\n",
    "  if indexUNet != nUNet - 1:\n",
    "    l = Concatenate()([input,layerPrec])\n",
    "  else:\n",
    "    l = getUnit1(layerPrec,16,activation=\"linear\") #era sigmoid\n",
    "\n",
    "  return l\n",
    "\n",
    "def trasformationInput(x, filters):\n",
    "  #x = BatchNormalization()(x)\n",
    "  #x = Activation('relu')(x)\n",
    "  #x = Conv2D(filters, kernel_size=(7,7), strides=(2,2), kernel_initializer=\"he_normal\", padding='same',use_bias=False)(x)\n",
    "  #maxPooling = MaxPool2D(padding='same')(x)\n",
    "  #x = Conv2D(filters*2, kernel_size=(5,5), strides=(1,1), kernel_initializer=\"he_normal\", padding='same',use_bias=False)(x)\n",
    "  #x = BatchNormalization()(x)\n",
    "  #x = Activation('relu')(x)\n",
    "  x = Conv2D(filters, kernel_size=(7,7), strides=(1,1), kernel_initializer=\"he_normal\", padding='same',use_bias=False)(x) #era 3x3\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = MaxPool2D(padding='same')(x)\n",
    "\n",
    "  return x#maxPooling\n",
    "\n",
    "def getCUNet(shape,m,n,nUNet,nBlocks):\n",
    "  for i in range(nUNet):\n",
    "    nets[f\"unet{i}\"] = None\n",
    "\n",
    "  for j in range(nBlocks):\n",
    "    nets[\"layers\"][f\"down{j}\"] = []\n",
    "    nets[\"layers\"][f\"up{j}\"] = []\n",
    "    \n",
    "  input = Input(shape=shape)\n",
    "  \n",
    "  t_input = trasformationInput(input,m) # per le heatmap da 64x64\n",
    "\n",
    "  for i in range(nUNet):\n",
    "    nets[f\"unet{i}\"] = getUNet(t_input,m,n,i,nUNet,nBlocks)\n",
    "\n",
    "  output = nets[f\"unet{nUNet-1}\"]\n",
    "  return Model(inputs=input, outputs=output)\n",
    "\n",
    "nets = {}\n",
    "nets[\"layers\"] = {}\n",
    "nets[\"layers\"][\"bn\"] = []\n",
    "shape = (128,128,3)\n",
    "m = 64\n",
    "n = 16\n",
    "nUNet = 2\n",
    "nBlocks = 4\n",
    "#mirrored_strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\n",
    "#with mirrored_strategy.scope():\n",
    "net = getCUNet(shape,m,n,nUNet,nBlocks)\n",
    "\n",
    "layers = net.layers\n",
    "#print(layers[57].input)\n",
    "for i in range(len(layers)):\n",
    "    if isinstance(layers[i], tf.python.keras.layers.convolutional.Conv2D):\n",
    "        if isinstance(layers[i-1].input,list):\n",
    "            in_chan = 0\n",
    "            for k in layers[i-1].input:\n",
    "                in_chan = in_chan + k.shape[-1]\n",
    "            print(in_chan)\n",
    "        else:\n",
    "            in_chan = layers[i-1].input.shape[-1]\n",
    "        n1 = layers[i].kernel_size[0] * layers[i].kernel_size[1] * in_chan\n",
    "        stdv = 1/math.sqrt(n1)\n",
    "        layers[i].kernel_initializer = tf.keras.initializers.RandomUniform(minval=-stdv, maxval=stdv)\n",
    "\n",
    "net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_preds(heatmaps):\n",
    "    \"\"\"Get keypoint predictions from score maps.\n",
    "    Note:\n",
    "        batch_size: N\n",
    "        num_keypoints: K\n",
    "        heatmap height: H\n",
    "        heatmap width: W\n",
    "    Args:\n",
    "        heatmaps (np.ndarray[N, K, H, W]): model predicted heatmaps.\n",
    "    Returns:\n",
    "        tuple: A tuple containing aggregated results.\n",
    "        - preds (np.ndarray[N, K, 2]): Predicted keypoint location.  \n",
    "        - maxvals (np.ndarray[N, K, 1]): Scores (confidence) of the keypoints. non lo restituiamo\n",
    "    \"\"\"\n",
    "    #assert isinstance(heatmaps, np.ndarray), ('heatmaps should be numpy.ndarray')\n",
    "    #assert heatmaps.ndim == 4, 'batch_images should be 4-ndim'\n",
    "\n",
    "    N, K, _, W = heatmaps.shape\n",
    "    heatmaps_reshaped = heatmaps.reshape((N, K, -1))\n",
    "    idx = np.argmax(heatmaps_reshaped, 2).reshape((N, K, 1))\n",
    "    maxvals = np.amax(heatmaps_reshaped, 2).reshape((N, K, 1))\n",
    "\n",
    "    preds = np.tile(idx, (1, 1, 2)).astype(np.float32)\n",
    "    preds[:, :, 0] = preds[:, :, 0] % W\n",
    "    preds[:, :, 1] = preds[:, :, 1] // W\n",
    "\n",
    "    preds = np.where(np.tile(maxvals, (1, 1, 2)) > 0.0, preds, -1)\n",
    "    return preds#, maxvals\n",
    "\n",
    "def calc_dists(preds, target, normalize, use_zero=False):\n",
    "    preds = preds.astype(np.float32)\n",
    "    target = target.astype(np.float32)\n",
    "    normalize = normalize.astype(np.float32)\n",
    "    dists = np.zeros((preds.shape[1], preds.shape[0]))\n",
    "    if use_zero:\n",
    "        boundary = 0\n",
    "    else:\n",
    "        boundary = 1\n",
    "    for n in range(preds.shape[0]):\n",
    "        for c in range(preds.shape[1]):\n",
    "            if target[n,c,0] > boundary and target[n, c, 1] > boundary:\n",
    "                dists[c, n] = np.linalg.norm((preds[n,c,:]- target[n,c,:])/normalize[n]) # axis ricavato da solo\n",
    "            else:\n",
    "                dists[c, n] = -1\n",
    "    return dists\n",
    "\n",
    "def dist_acc(dists, thr=0.5):\n",
    "\n",
    "  #Return percentage below threshold while ignoring values with a -1\n",
    "\n",
    "  if (dists!=-1).sum() > 0:\n",
    "\n",
    "    return ((dists<=thr) == (dists!=-1)).sum().astype(np.float32) / (dists!=-1).sum().astype(np.float32)\n",
    "\n",
    "  else:\n",
    "\n",
    "    return -1\n",
    "\n",
    "def accuracy(output, target, thr=0.5):\n",
    "  ''' Calculate accuracy according to PCK, but uses ground truth heatmap rather than x,y locations\n",
    "        First value to be returned is average accuracy across 'idxs', followed by individual accuracies\n",
    "    '''\n",
    "  #output = output.numpy()\n",
    "  #print(output.__class__)\n",
    "  #target = target.numpy()\n",
    "\n",
    "  idkp = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "  preds = get_max_preds(output)\n",
    "  gts = get_max_preds(target)\n",
    "  norm = np.ones(preds.shape[0])*output.shape[3]/10\n",
    "\n",
    "  dists = calc_dists(preds, gts, norm)\n",
    "\n",
    "  acc = np.zeros(len(idkp)+1)\n",
    "  avg_acc = 0\n",
    "  cnt = 0\n",
    "\n",
    "  for i in range(len(idkp)):\n",
    "    acc[i+1] = dist_acc(dists[idkp[i]])\n",
    "    if acc[i+1] >= 0: \n",
    "      avg_acc = avg_acc + acc[i+1]\n",
    "      cnt += 1\n",
    "            \n",
    "  if cnt != 0:  \n",
    "    acc[0] = avg_acc / cnt\n",
    "\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.misc\n",
    "import cv2\n",
    "\n",
    "# =============================================================================\n",
    "# General image processing functions\n",
    "# =============================================================================\n",
    "\n",
    "def get_transform(center, scale, res, rot=0):\n",
    "    # Generate transformation matrix\n",
    "    h = 200 * scale\n",
    "    t = np.zeros((3, 3))\n",
    "    t[0, 0] = float(res[1]) / h\n",
    "    t[1, 1] = float(res[0]) / h\n",
    "    t[0, 2] = res[1] * (-float(center[0]) / h + .5)\n",
    "    t[1, 2] = res[0] * (-float(center[1]) / h + .5)\n",
    "    t[2, 2] = 1\n",
    "    if not rot == 0:\n",
    "        rot = -rot # To match direction of rotation from cropping\n",
    "        rot_mat = np.zeros((3,3))\n",
    "        rot_rad = rot * np.pi / 180\n",
    "        sn,cs = np.sin(rot_rad), np.cos(rot_rad)\n",
    "        rot_mat[0,:2] = [cs, -sn]\n",
    "        rot_mat[1,:2] = [sn, cs]\n",
    "        rot_mat[2,2] = 1\n",
    "        # Need to rotate around center\n",
    "        t_mat = np.eye(3)\n",
    "        t_mat[0,2] = -res[1]/2\n",
    "        t_mat[1,2] = -res[0]/2\n",
    "        t_inv = t_mat.copy()\n",
    "        t_inv[:2,2] *= -1\n",
    "        t = np.dot(t_inv,np.dot(rot_mat,np.dot(t_mat,t)))\n",
    "    return t\n",
    "\n",
    "def transform(pt, center, scale, res, invert=0, rot=0):\n",
    "    # Transform pixel location to different reference\n",
    "    t = get_transform(center, scale, res, rot=rot)\n",
    "    if invert:\n",
    "        t = np.linalg.inv(t)\n",
    "    new_pt = np.array([pt[0], pt[1], 1.]).T\n",
    "    new_pt = np.dot(t, new_pt)\n",
    "    return new_pt[:2].astype(int)\n",
    "\n",
    "def crop(img, center, scale, res, rot=0):\n",
    "    # Upper left point\n",
    "    ul = np.array(transform([0, 0], center, scale, res, invert=1))\n",
    "    # Bottom right point\n",
    "    br = np.array(transform(res, center, scale, res, invert=1))\n",
    "\n",
    "    new_shape = [br[1] - ul[1], br[0] - ul[0]]\n",
    "    if len(img.shape) > 2:\n",
    "        new_shape += [img.shape[2]]\n",
    "    new_img = np.zeros(new_shape)\n",
    "\n",
    "    # Range to fill new array\n",
    "    new_x = max(0, -ul[0]), min(br[0], len(img[0])) - ul[0]\n",
    "    new_y = max(0, -ul[1]), min(br[1], len(img)) - ul[1]\n",
    "    # Range to sample from original image\n",
    "    old_x = max(0, ul[0]), min(len(img[0]), br[0])\n",
    "    old_y = max(0, ul[1]), min(len(img), br[1])\n",
    "    new_img[new_y[0]:new_y[1], new_x[0]:new_x[1]] = img[old_y[0]:old_y[1], old_x[0]:old_x[1]]\n",
    "\n",
    "    return cv2.resize(new_img, res)\n",
    "\n",
    "def inv_mat(mat):\n",
    "    ans = np.linalg.pinv(np.array(mat).tolist() + [[0,0,1]])\n",
    "    return ans[:2]\n",
    "\n",
    "def kpt_affine(kpt, mat):\n",
    "    kpt = np.array(kpt)\n",
    "    shape = kpt.shape\n",
    "    kpt = kpt.reshape(-1, 2)\n",
    "    return np.dot( np.concatenate((kpt, kpt[:, 0:1]*0+1), axis = 1), mat.T ).reshape(shape)\n",
    "\n",
    "\n",
    "def resize(im, res):\n",
    "    return np.array([cv2.resize(im[i],res) for i in range(im.shape[0])])\n",
    "\n",
    "def generateHeatmap(keypoints,output_res,num_parts):\n",
    "    #Init\n",
    "    sigma = output_res/64\n",
    "    size = 6*sigma+3\n",
    "    x = np.arange(0, size, 1, float) #crea un array composto da nove 1.0 vettore 1-D (9,)\n",
    "    y = x[:, np.newaxis] #Vettore 2-D (9,1)\n",
    "    x0, y0 = 3*sigma + 1, 3*sigma + 1 #vedi giù a tutto\n",
    "    g = np.exp(- ((x - x0) ** 2 + (y - y0) ** 2) / (2 * sigma ** 2))\n",
    "    #Generation\n",
    "    hms = np.zeros(shape = (num_parts, output_res, output_res), dtype = np.float32) #crea vettore (16,64,64), cioè 16 heatmaps nere\n",
    "    for p in keypoints:\n",
    "        for idx, pt in enumerate(p): #ottiene id + [x,y] di ogni keypoint\n",
    "            if pt[0] > 0: \n",
    "                x, y = int(pt[0]), int(pt[1])\n",
    "                if x<0 or y<0 or x>=output_res or y>=output_res: #se succede questo, rimane heatmap idx-esima  tutta a 0\n",
    "                    continue\n",
    "                ul = int(x - 3*sigma - 1), int(y - 3*sigma - 1)\n",
    "                br = int(x + 3*sigma + 2), int(y + 3*sigma + 2)\n",
    "\n",
    "                c,d = max(0, -ul[0]), min(br[0], output_res) - ul[0]\n",
    "                a,b = max(0, -ul[1]), min(br[1], output_res) - ul[1]\n",
    "\n",
    "                cc,dd = max(0, ul[0]), min(br[0], output_res)\n",
    "                aa,bb = max(0, ul[1]), min(br[1], output_res)\n",
    "                hms[idx, aa:bb,cc:dd] = np.maximum(hms[idx, aa:bb,cc:dd], g[a:b,c:d])\n",
    "    return hms\n",
    "def getImgHms(img,c,s,keypoints,inp_res=(256,256),out_res=(64,64)):\n",
    "    cropped = crop(img,c,s,inp_res)\n",
    "    orig_keypoints = []\n",
    "    for i in keypoints:\n",
    "        orig_keypoints.append(np.array([i[\"x\"],i[\"y\"]]))\n",
    "    orig_keypoints = np.array(orig_keypoints).reshape((1,16,2))\n",
    "    kptmp = np.copy(orig_keypoints)\n",
    "    for i in range(orig_keypoints.shape[1]):\n",
    "        if orig_keypoints[0,i,0] > 0:\n",
    "            orig_keypoints[0,i,:2] = transform(orig_keypoints[0,i,:2], c, s, inp_res)\n",
    "    keypoints = np.copy(orig_keypoints)\n",
    "    h, w = cropped.shape[0:2]\n",
    "    center = np.array((w/2,h/2))\n",
    "    scale = max(h,w)/200\n",
    "    aug_rot = (np.random.random()*2-1)*30\n",
    "    aug_scale = np.random.random() * (1.25-0.75)+0.75\n",
    "    scale *= aug_scale\n",
    "\n",
    "    mat_mask = get_transform(center, scale, out_res, aug_rot)[:2]\n",
    "    mat = get_transform(center, scale, inp_res, aug_rot)[:2]\n",
    "    inp = cv2.warpAffine(cropped, mat, inp_res).astype(np.float32)/255\n",
    "\n",
    "    keypoints[:,:,0:2] = kpt_affine(keypoints[:,:,0:2], mat_mask) \n",
    "    \n",
    "    #print('\\n')\n",
    "\n",
    "\n",
    "    #Flip 50% probability\n",
    "    if np.random.randint(2) == 0:\n",
    "        inp = inp[:, ::-1]\n",
    "        keypoints = keypoints[:, flipped_parts['mpii']]\n",
    "        keypoints[:, :, 0] = 64 - keypoints[:, :, 0]\n",
    "        orig_keypoints = orig_keypoints[:, flipped_parts['mpii']]\n",
    "        orig_keypoints[:, :, 0] = 256 - orig_keypoints[:, :, 0]\n",
    "\n",
    "    ## set keypoints to 0 when were not visible initially (so heatmap all 0s)\n",
    "        for i in range(np.shape(orig_keypoints)[1]):\n",
    "            if kptmp[0,i,0] == 0 and kptmp[0,i,1] == 0:\n",
    "                keypoints[0,i,0] = 0\n",
    "                keypoints[0,i,1] = 0\n",
    "                orig_keypoints[0,i,0] = 0\n",
    "                orig_keypoints[0,i,1] = 0\n",
    "\n",
    "    heatmaps = generateHeatmap(keypoints,out_res[0],16)\n",
    "    return inp,heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.RMSprop(\n",
    "    learning_rate=2.5e-4, rho=0.99, momentum=0.0, epsilon=1e-08\n",
    ")\n",
    "#optimizer = tf.keras.optimizers.Adam(learning_rate=6.7e-3)\n",
    "\n",
    "\n",
    "def heatmapLoss(y_true,y_pred):\n",
    "    l = tf.math.square((y_pred - y_true))\n",
    "    l = tf.reduce_mean(l,axis=3)\n",
    "    l = tf.reduce_mean(l,axis=2)\n",
    "    l = tf.reduce_mean(l,axis=1)\n",
    "    return l\n",
    "\n",
    "def euclidean_loss(y_true, y_pred):\n",
    "    return K.sqrt(K.sum(K.square(y_true - y_pred)))\n",
    "\n",
    "def dice(y_true,y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + 1) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1 - dice(y_true, y_pred)\n",
    "\n",
    "def weighted_mse_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    apply weights on heatmap mse loss to only pick valid keypoint heatmap\n",
    "    since y_true would be gt_heatmap with shape\n",
    "    (batch_size, heatmap_size[0], heatmap_size[1], num_keypoints)\n",
    "    we sum up the heatmap for each keypoints and check. Sum for invalid\n",
    "    keypoint would be 0, so we can get a keypoint weights tensor with shape\n",
    "    (batch_size, 1, 1, num_keypoints)\n",
    "    and multiply to loss\n",
    "    \"\"\"\n",
    "    heatmap_sum = K.sum(K.sum(y_true, axis=1, keepdims=True), axis=2, keepdims=True)\n",
    "\n",
    "    # keypoint_weights shape: (batch_size, 1, 1, num_keypoints), with\n",
    "    # valid_keypoint = 1.0, invalid_keypoint = 0.0\n",
    "    keypoint_weights = 1.0 - K.cast(K.equal(heatmap_sum, 0.0), 'float32')\n",
    "\n",
    "    return K.sqrt(K.mean(K.square((y_true - y_pred) * keypoint_weights)))\n",
    "\n",
    "def smooth_l1_loss(y_true, y_pred):\n",
    "    diff = K.abs(y_true - y_pred)\n",
    "    less_than_one = K.cast(K.less(diff, 1.0), 'float32')\n",
    "    loss = (less_than_one * 0.5 * diff**2) + (1 - less_than_one) * (diff - 0.5)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "parts = {'mpii':['rank', 'rkne', 'rhip',\n",
    "                 'lhip', 'lkne', 'lank',\n",
    "                 'pelv', 'thrx', 'neck', 'head',\n",
    "                 'rwri', 'relb', 'rsho',\n",
    "                 'lsho', 'lelb', 'lwri']}\n",
    "\n",
    "flipped_parts = {'mpii':[5, 4, 3, 2, 1, 0, 6, 7, 8, 9, 15, 14, 13, 12, 11, 10]}\n",
    "\n",
    "part_pairs = {'mpii':[[0, 5], [1, 4], [2, 3], [6], [7], [8], [9], [10, 15], [11, 14], [12, 13]]}\n",
    "\n",
    "pair_names = {'mpii':['ankle', 'knee', 'hip', 'pelvis', 'thorax', 'neck', 'head', 'wrist', 'elbow', 'shoulder']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import imageio\n",
    "\n",
    "class Dataset(tf.keras.utils.Sequence):\n",
    "    #Costruttore\n",
    "    def __init__(self,json_path,batch_size,input_shape=(256,256,3),output_shape=(64,64,16),train=True,dataset_name=\"MPII\"):\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "        self.batch_size = batch_size\n",
    "        f = open(json_path)\n",
    "        self.dataset = json.load(f)\n",
    "        if dataset_name == \"MPII\":\n",
    "            self.dataset = self.dataset[\"dataset\"][\"MPII\"][\"people\"]\n",
    "        if train:\n",
    "            self.dataset = self.dataset[:-7221]\n",
    "        self.batch_images = np.zeros(shape=((self.batch_size,)+(self.input_shape)), dtype=np.float32)\n",
    "        self.batch_heatmaps = np.zeros(shape=((self.batch_size,)+(self.output_shape)), dtype=np.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset) // self.batch_size\n",
    "    \n",
    "    def __getitem__(self,i):\n",
    "        for n, annotation in enumerate(self.dataset[i*self.batch_size:(i+1)*self.batch_size]):\n",
    "            #sample_index = i*self.batch_size + n\n",
    "            image, gt_heatmap = self.extract_imgs_hms(annotation)\n",
    "            gt_heatmap = np.transpose(gt_heatmap,(1,2,0))\n",
    "            self.batch_images[n,:,:,:] = image\n",
    "            self.batch_heatmaps[n, :, :, :] = gt_heatmap#gt_heatmap.reshape((self.output_shape))\n",
    "            \n",
    "        return self.batch_images, self.batch_heatmaps\n",
    "#getImgHms(img,c,s,keypoints,inp_res=(256,256),out_res=(64,64)):\n",
    "    \n",
    "    def extract_imgs_hms(self,annotation):\n",
    "        inp_res = self.input_shape[0:2]\n",
    "        out_res = self.output_shape[0:2]\n",
    "        img = imageio.imread(f\"../images_mpii/{annotation['filepath']}\")\n",
    "        c = [annotation[\"objpos\"][\"x\"],annotation[\"objpos\"][\"y\"]]\n",
    "        s = annotation[\"scale\"]\n",
    "        keypoints = annotation[\"keypoints\"]\n",
    "        cropped = crop(img,c,s,inp_res)\n",
    "        \n",
    "        orig_keypoints = []\n",
    "        for i in keypoints:\n",
    "            orig_keypoints.append(np.array([i[\"x\"],i[\"y\"]]))\n",
    "        orig_keypoints = np.array(orig_keypoints).reshape((1,16,2))\n",
    "        kptmp = np.copy(orig_keypoints)\n",
    "        for i in range(orig_keypoints.shape[1]):\n",
    "            if orig_keypoints[0,i,0] > 0:\n",
    "                orig_keypoints[0,i,:2] = transform(orig_keypoints[0,i,:2], c, s, inp_res)\n",
    "        keypoints = np.copy(orig_keypoints)\n",
    "        h, w = cropped.shape[0:2]\n",
    "        center = np.array((w/2,h/2))\n",
    "        scale = max(h,w)/200\n",
    "        aug_rot = (np.random.random()*2-1)*30\n",
    "        aug_scale = np.random.random() * (1.25-0.75)+0.75\n",
    "        scale *= aug_scale\n",
    "\n",
    "        mat_mask = get_transform(center, scale, out_res, aug_rot)[:2]\n",
    "        mat = get_transform(center, scale, inp_res, aug_rot)[:2]\n",
    "        inp = cv2.warpAffine(cropped, mat, inp_res).astype(np.float32)/255\n",
    "\n",
    "        keypoints[:,:,0:2] = kpt_affine(keypoints[:,:,0:2], mat_mask) \n",
    "\n",
    "        #print('\\n')\n",
    "\n",
    "\n",
    "        #Flip 50% probability\n",
    "        if np.random.randint(2) == 0:\n",
    "            inp = inp[:, ::-1]\n",
    "            keypoints = keypoints[:, flipped_parts['mpii']]\n",
    "            keypoints[:, :, 0] = 64 - keypoints[:, :, 0]\n",
    "            orig_keypoints = orig_keypoints[:, flipped_parts['mpii']]\n",
    "            orig_keypoints[:, :, 0] = 256 - orig_keypoints[:, :, 0]\n",
    "\n",
    "        ## set keypoints to 0 when were not visible initially (so heatmap all 0s)\n",
    "            for i in range(np.shape(orig_keypoints)[1]):\n",
    "                if kptmp[0,i,0] == 0 and kptmp[0,i,1] == 0:\n",
    "                    keypoints[0,i,0] = 0\n",
    "                    keypoints[0,i,1] = 0\n",
    "                    orig_keypoints[0,i,0] = 0\n",
    "                    orig_keypoints[0,i,1] = 0\n",
    "\n",
    "        heatmaps = generateHeatmap(keypoints,out_res[0],16)\n",
    "        return inp,heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import imageio\n",
    "\n",
    "class Dataset2(tf.keras.utils.Sequence):\n",
    "    #Costruttore\n",
    "    def __init__(self,json_path,batch_size,input_shape=(256,256,3),output_shape=(64,64,16),train=True,dataset_name=\"MPII\"):\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "        self.batch_size = batch_size\n",
    "        self.images = np.load(\"../imgs_mpii.npz\")['arr_0']\n",
    "        self.hms = np.load(\"../hms_mpii.npz\")['arr_0']\n",
    "        self.hms = self.hms.reshape((self.hms.shape[0],64,64,16))\n",
    "        if dataset_name == \"MPII\":\n",
    "            self.images = self.images[\"dataset\"][\"MPII\"][\"people\"]\n",
    "        if train:\n",
    "            self.images = self.images[:-8665]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset) // self.batch_size\n",
    "    \n",
    "    def __getitem__(self,i):\n",
    "        return self.images[i*self.batch_size:(i+1)*self.batch_size], self.hms[i*self.batch_size:(i+1)*self.batch_size]\n",
    "#getImgHms(img,c,s,keypoints,inp_res=(256,256),out_res=(64,64)):\n",
    "    \n",
    "    def extract_imgs_hms(self,annotation):\n",
    "        inp_res = self.input_shape[0:2]\n",
    "        out_res = self.output_shape[0:2]\n",
    "        img = imageio.imread(f\"../images_mpii/{annotation['filepath']}\")\n",
    "        c = [annotation[\"objpos\"][\"x\"],annotation[\"objpos\"][\"y\"]]\n",
    "        s = annotation[\"scale\"]\n",
    "        keypoints = annotation[\"keypoints\"]\n",
    "        cropped = crop(img,c,s,inp_res)\n",
    "        \n",
    "        orig_keypoints = []\n",
    "        for i in keypoints:\n",
    "            orig_keypoints.append(np.array([i[\"x\"],i[\"y\"]]))\n",
    "        orig_keypoints = np.array(orig_keypoints).reshape((1,16,2))\n",
    "        kptmp = np.copy(orig_keypoints)\n",
    "        for i in range(orig_keypoints.shape[1]):\n",
    "            if orig_keypoints[0,i,0] > 0:\n",
    "                orig_keypoints[0,i,:2] = transform(orig_keypoints[0,i,:2], c, s, inp_res)\n",
    "        keypoints = np.copy(orig_keypoints)\n",
    "        h, w = cropped.shape[0:2]\n",
    "        center = np.array((w/2,h/2))\n",
    "        scale = max(h,w)/200\n",
    "        aug_rot = (np.random.random()*2-1)*30\n",
    "        aug_scale = np.random.random() * (1.25-0.75)+0.75\n",
    "        scale *= aug_scale\n",
    "\n",
    "        mat_mask = get_transform(center, scale, out_res, aug_rot)[:2]\n",
    "        mat = get_transform(center, scale, inp_res, aug_rot)[:2]\n",
    "        inp = cv2.warpAffine(cropped, mat, inp_res).astype(np.float32)/255\n",
    "\n",
    "        keypoints[:,:,0:2] = kpt_affine(keypoints[:,:,0:2], mat_mask) \n",
    "\n",
    "        #print('\\n')\n",
    "\n",
    "\n",
    "        #Flip 50% probability\n",
    "        if np.random.randint(2) == 0:\n",
    "            inp = inp[:, ::-1]\n",
    "            keypoints = keypoints[:, flipped_parts['mpii']]\n",
    "            keypoints[:, :, 0] = 64 - keypoints[:, :, 0]\n",
    "            orig_keypoints = orig_keypoints[:, flipped_parts['mpii']]\n",
    "            orig_keypoints[:, :, 0] = 256 - orig_keypoints[:, :, 0]\n",
    "\n",
    "        ## set keypoints to 0 when were not visible initially (so heatmap all 0s)\n",
    "            for i in range(np.shape(orig_keypoints)[1]):\n",
    "                if kptmp[0,i,0] == 0 and kptmp[0,i,1] == 0:\n",
    "                    keypoints[0,i,0] = 0\n",
    "                    keypoints[0,i,1] = 0\n",
    "                    orig_keypoints[0,i,0] = 0\n",
    "                    orig_keypoints[0,i,1] = 0\n",
    "\n",
    "        heatmaps = generateHeatmap(keypoints,out_res[0],16)\n",
    "        return inp,heatmaps\n",
    "####################################################################àà\n",
    "\n",
    "\n",
    "def get_normalize(input_shape):\n",
    "    \"\"\"\n",
    "    rescale keypoint distance normalize coefficient\n",
    "    based on input shape, used for PCK evaluation\n",
    "    NOTE: 6.4 is standard normalize coefficient under\n",
    "          input shape (256,256)\n",
    "    # Arguments\n",
    "        input_shape: input image shape as (height, width)\n",
    "    # Returns\n",
    "        scale: normalize coefficient\n",
    "    \"\"\"\n",
    "    #assert input_shape[0] == input_shape[1], 'only support square input shape.'\n",
    "\n",
    "    # use averaged scale factor for non square input shape\n",
    "    scale = float((input_shape[0] + input_shape[1]) / 2) / 256.0\n",
    "\n",
    "    return 6.4*scale\n",
    "\n",
    "global_best_acc = 0.0\n",
    "\n",
    "class EvalCallBack(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, model_input_shape, fileName, imgs,hms):\n",
    "        self.normalize = get_normalize(model_input_shape)\n",
    "        self.model_input_shape = model_input_shape\n",
    "        self.best_acc = 0.0\n",
    "        self.fileName = fileName\n",
    "        self.eval_images = imgs#np.load(\"../imgs_val_mpii128.npz\")['arr_0']\n",
    "        self.eval_hms = hms#np.load(\"../hms_val_mpii128.npz\")['arr_0']\n",
    "        self.listAcc = []\n",
    "        #self.eval_hms = np.reshape(self.eval_hms,(self.eval_hms.shape[0],64,64,16))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        global global_best_acc\n",
    "        output = self.model.predict(self.eval_images)\n",
    "        #output = output.reshape( (output.shape[0],)+(16,64,64) )\n",
    "        output = np.transpose(output,(0,3,1,2))\n",
    "        val_acc = accuracy(output,self.eval_hms)\n",
    "        self.listAcc.append(val_acc[0])\n",
    "        print('\\nvalidate accuracy:\\n', val_acc, '@epoch', epoch)\n",
    "        f = open(self.fileName, \"a\")\n",
    "        if val_acc[0] > self.best_acc:\n",
    "            # Save best accuray value and model checkpoint\n",
    "            #checkpoint_dir = os.path.join(self.log_dir, 'ep{epoch:03d}-loss{loss:.3f}-val_acc{val_acc:.3f}.h5'.format(epoch=(epoch+1), loss=logs.get('loss'), val_acc=val_acc))\n",
    "            #self.model.save(f\"../modelsave/ep{epoch}_acc{val_acc[0]}.h5\")\n",
    "            self.model.save_weights(f\"../cunet{nUNet}_{m}{n}_best_sigmoidAdamQuasiDef3sx12_restart.h5\")\n",
    "            print('Epoch {epoch:03d}: val_acc improved from {best_acc:.3f} to {val_acc:.3f}'.format(epoch=epoch+1, best_acc=self.best_acc, val_acc=val_acc[0]))# checkpoint_dir=checkpoint_dir))\n",
    "            message = 'Epoch {epoch:03d}: val_acc improved from {best_acc:.3f} to {val_acc:.3f}. Train loss is {loss:.3f}\\n'.format(epoch=epoch+1, best_acc=self.best_acc, val_acc=val_acc[0],loss=logs.get('loss'))\n",
    "            self.best_acc = val_acc[0]\n",
    "            global_best_acc = val_acc[0]\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            message = 'Epoch {epoch:03d}: val_acc did not improve from {best_acc:.3f}. Train loss is {loss:.3f}\\n'.format(epoch=epoch+1, best_acc=self.best_acc,loss=logs.get('loss'))\n",
    "            print('Epoch {epoch:03d}: val_acc did not improve from {best_acc:.3f}'.format(epoch=epoch+1, best_acc=self.best_acc))\n",
    "        f.write(message)\n",
    "        f.close()\n",
    "        if epoch == 150:\n",
    "            np.savez_compressed(f'../cunet{nUNet}_{m}{n}_best_sigmoidAdamQuasiDef3sx12_restart_accs', self.listAcc)\n",
    "        gc.collect()\n",
    "        \n",
    "        \n",
    "class CustomLearningRateScheduler(tf.keras.callbacks.Callback):\n",
    "    \"\"\"Learning rate scheduler which sets the learning rate according to schedule.\n",
    "\n",
    "  Arguments:\n",
    "      schedule: a function that takes an epoch index\n",
    "          (integer, indexed from 0) and current learning rate\n",
    "          as inputs and returns a new learning rate as output (float).\n",
    "  \"\"\"\n",
    "\n",
    "    def __init__(self, patience,factor,fileName=None):\n",
    "        super(CustomLearningRateScheduler, self).__init__()\n",
    "        self.counter = 0\n",
    "        self.patience = patience\n",
    "        self.fileName = fileName\n",
    "        self.factor = factor\n",
    "        self.best_acc = 0.0\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        global global_best_acc\n",
    "        print(f\"Counter: {self.counter}, Global: {global_best_acc}, MyBest: {self.best_acc}\\n\")\n",
    "        if not hasattr(self.model.optimizer, \"lr\"):\n",
    "            raise ValueError('Optimizer must have a \"lr\" attribute.')\n",
    "        # Get the current learning rate from model's optimizer.\n",
    "        lr = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n",
    "        # Call schedule function to get the scheduled learning rate.\n",
    "        scheduled_lr = self.schedule(epoch, lr)\n",
    "        # Set the value back to the optimizer before this epoch starts\n",
    "        tf.keras.backend.set_value(self.model.optimizer.lr, scheduled_lr)\n",
    "    \n",
    "    def schedule(self,epoch,lr):\n",
    "        global global_best_acc\n",
    "        if self.counter == self.patience:\n",
    "            self.counter = 0 \n",
    "            print(\"Epoch %03d: Updating Learning rate.. New value is %f\" % (epoch, lr*self.factor))\n",
    "            message = \"Epoch %03d: Updating Learning rate.. New value is %f\" % (epoch, lr*self.factor)\n",
    "            f = open(self.fileName, \"a\")\n",
    "            f.write(message)\n",
    "            f.close()\n",
    "            return lr*self.factor\n",
    "        if self.best_acc == global_best_acc:\n",
    "            self.counter = self.counter + 1\n",
    "        elif self.best_acc < global_best_acc:\n",
    "            self.counter = 0\n",
    "            self.best_acc = global_best_acc\n",
    "        return lr\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finito 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ndataset = Dataset(\"datasets.json\",32)\\n\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle \n",
    "with open('../train_imgssx12.pickle', 'rb') as handle:\n",
    "    train_images = pickle.load(handle)\n",
    "with open('../train_hmssx12.pickle', 'rb') as handle:\n",
    "    train_hms = pickle.load(handle)\n",
    "\n",
    "eval_images = np.load(\"../imgs_val_mpii128sx12.npz\")['arr_0']\n",
    "eval_hms = np.load(\"../hms_val_mpii128sx12.npz\")['arr_0']\n",
    "\n",
    "#train_images = np.load(\"../imgs_train_mpii128.npz\")['arr_0']\n",
    "#train_hms = np.load(\"../hms_train_mpii128.npz\")['arr_0']\n",
    "train_hms = np.transpose(train_hms,(0,2,3,1))#np.reshape(train_hms,(train_hms.shape[0],64,64,16))\n",
    "eval_hms2 = np.transpose(eval_hms,(0,2,3,1))\n",
    "print(\"Finito 1\")\n",
    "\"\"\"\n",
    "dataset = Dataset(\"datasets.json\",32)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finito 2\n"
     ]
    }
   ],
   "source": [
    "evalcallback = EvalCallBack((128,128),\"../sigmoidLayersAdamSchedulingQuasiDef3sx12_restart.txt\",eval_images,eval_hms)\n",
    "updateLR = CustomLearningRateScheduler(7,0.2,fileName=\"../sigmoidLayersAdamSchedulingQuasiDef3sx12_restart.txt\")\n",
    "print(\"Finito 2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter: 0, Global: 0.0, MyBest: 0.0\n",
      "\n",
      "Epoch 1/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0938WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0082s vs `on_test_batch_end` time: 0.0351s). Check your callbacks.\n",
      "\n",
      "validate accuracy:\n",
      " [0.02509172 0.0050923  0.02959866 0.02377864 0.01728857 0.01040268\n",
      " 0.00063803 0.02948403 0.         0.04150943 0.02329282 0.03434144\n",
      " 0.00014029 0.06634146 0.02021188 0.06909142 0.0302559 ] @epoch 0\n",
      "Epoch 001: val_acc improved from 0.000 to 0.025\n",
      "576/576 [==============================] - 125s 217ms/step - loss: 0.0938 - val_loss: 0.0346\n",
      "Counter: 1, Global: 0.02509172242207569, MyBest: 0.0\n",
      "\n",
      "Epoch 2/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0407\n",
      "validate accuracy:\n",
      " [0.02849555 0.01867176 0.02107023 0.02377864 0.03256015 0.0159396\n",
      " 0.024245   0.02673797 0.05015367 0.0479385  0.02922454 0.01710006\n",
      " 0.02370932 0.04334495 0.03610259 0.02555821 0.01979358] @epoch 1\n",
      "Epoch 002: val_acc improved from 0.025 to 0.028\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0407 - val_loss: 0.0386\n",
      "Counter: 0, Global: 0.028495548060163856, MyBest: 0.02509172242207569\n",
      "\n",
      "Epoch 3/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0374\n",
      "validate accuracy:\n",
      " [0.03601925 0.01994483 0.0277592  0.03026373 0.0540268  0.02651007\n",
      " 0.03126329 0.04523775 0.04442582 0.04095038 0.04123264 0.02063313\n",
      " 0.03184624 0.0543554  0.06063563 0.02064317 0.02657995] @epoch 2\n",
      "Epoch 003: val_acc improved from 0.028 to 0.036\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0374 - val_loss: 0.0529\n",
      "Counter: 0, Global: 0.03601925144903362, MyBest: 0.028495548060163856\n",
      "\n",
      "Epoch 4/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0361\n",
      "validate accuracy:\n",
      " [0.06332057 0.02376406 0.04314381 0.06672432 0.09825674 0.04395973\n",
      " 0.04466185 0.07212025 0.1096675  0.1037037  0.05338542 0.03504805\n",
      " 0.03689675 0.0912892  0.10091999 0.04886954 0.04071822] @epoch 3\n",
      "Epoch 004: val_acc improved from 0.036 to 0.063\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0361 - val_loss: 0.0424\n",
      "Counter: 0, Global: 0.06332057004328817, MyBest: 0.03601925144903362\n",
      "\n",
      "Epoch 5/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0354\n",
      "validate accuracy:\n",
      " [0.0797085  0.04774029 0.04715719 0.06369794 0.11280795 0.01912752\n",
      " 0.04849    0.14134991 0.14822575 0.15974844 0.08796296 0.0496043\n",
      " 0.02342873 0.08515679 0.1133259  0.0855217  0.04199067] @epoch 4\n",
      "Epoch 005: val_acc improved from 0.063 to 0.080\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0354 - val_loss: 0.0363\n",
      "Counter: 0, Global: 0.07970850286073983, MyBest: 0.06332057004328817\n",
      "\n",
      "Epoch 6/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0349\n",
      "validate accuracy:\n",
      " [0.10277481 0.04498196 0.06304348 0.14483355 0.17792825 0.05922819\n",
      " 0.05529562 0.16302934 0.14892428 0.1724668  0.10416666 0.06995478\n",
      " 0.09497755 0.128223   0.08363535 0.06838927 0.06531882] @epoch 5\n",
      "Epoch 006: val_acc improved from 0.080 to 0.103\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0349 - val_loss: 0.0398\n",
      "Counter: 0, Global: 0.10277480655349791, MyBest: 0.07970850286073983\n",
      "\n",
      "Epoch 7/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0342\n",
      "validate accuracy:\n",
      " [0.13442837 0.01124549 0.10334449 0.19138205 0.21423426 0.09110738\n",
      " 0.09825606 0.21852869 0.19013691 0.19399022 0.12630208 0.11800452\n",
      " 0.12401795 0.16013937 0.14371341 0.09773908 0.068712  ] @epoch 6\n",
      "Epoch 007: val_acc improved from 0.103 to 0.134\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0342 - val_loss: 0.0343\n",
      "Counter: 0, Global: 0.13442837272305042, MyBest: 0.10277480655349791\n",
      "\n",
      "Epoch 8/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0337\n",
      "validate accuracy:\n",
      " [0.1296208  0.07744537 0.05267559 0.20262286 0.18714882 0.00838926\n",
      " 0.0355168  0.2166498  0.2372171  0.20307477 0.0979456  0.10514415\n",
      " 0.07337262 0.17574912 0.17828269 0.14281702 0.07988124] @epoch 7\n",
      "Epoch 008: val_acc did not improve from 0.134\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0337 - val_loss: 0.0344\n",
      "Counter: 0, Global: 0.13442837272305042, MyBest: 0.13442837272305042\n",
      "\n",
      "Epoch 9/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0333\n",
      "validate accuracy:\n",
      " [0.13461365 0.0700191  0.07374582 0.20507278 0.18441147 0.05788591\n",
      " 0.04232242 0.19771643 0.23316568 0.18392733 0.14322917 0.07687959\n",
      " 0.11335578 0.19986063 0.15556175 0.13607639 0.08058815] @epoch 8\n",
      "Epoch 009: val_acc improved from 0.134 to 0.135\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0333 - val_loss: 0.0299\n",
      "Counter: 1, Global: 0.13461364875547588, MyBest: 0.13442837272305042\n",
      "\n",
      "Epoch 10/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0329\n",
      "validate accuracy:\n",
      " [0.15788824 0.08487163 0.08963211 0.21732238 0.22143783 0.10369127\n",
      " 0.07337303 0.22185287 0.25775355 0.24584207 0.14800347 0.10528547\n",
      " 0.14267677 0.15916376 0.20462783 0.14492346 0.10575428] @epoch 9\n",
      "Epoch 010: val_acc improved from 0.135 to 0.158\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0329 - val_loss: 0.0356\n",
      "Counter: 0, Global: 0.15788823692128062, MyBest: 0.13461364875547588\n",
      "\n",
      "Epoch 11/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0328\n",
      "validate accuracy:\n",
      " [0.1775385  0.08402292 0.1187291  0.21933997 0.24002305 0.1102349\n",
      " 0.09038707 0.31016043 0.34409052 0.33501047 0.19560185 0.12153759\n",
      " 0.11125141 0.16585366 0.1977976  0.11711838 0.07945709] @epoch 10\n",
      "Epoch 011: val_acc improved from 0.158 to 0.178\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0328 - val_loss: 0.0345\n",
      "Counter: 0, Global: 0.17753849970176816, MyBest: 0.15788823692128062\n",
      "\n",
      "Epoch 12/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0324\n",
      "validate accuracy:\n",
      " [0.16781971 0.06068322 0.08327759 0.20680213 0.24348077 0.10520134\n",
      " 0.06975755 0.31969938 0.35275218 0.23675752 0.1171875  0.12040701\n",
      " 0.11756454 0.19428572 0.2103429  0.15756214 0.08935388] @epoch 11\n",
      "Epoch 012: val_acc did not improve from 0.178\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0324 - val_loss: 0.0462\n",
      "Counter: 0, Global: 0.17753849970176816, MyBest: 0.17753849970176816\n",
      "\n",
      "Epoch 13/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0323\n",
      "validate accuracy:\n",
      " [0.17863664 0.         0.15000001 0.26401499 0.23080248 0.00067114\n",
      " 0.11548277 0.00202341 0.44160381 0.442348   0.26591435 0.08069531\n",
      " 0.18869248 0.25923344 0.21982157 0.19688246 0.        ] @epoch 12\n",
      "Epoch 013: val_acc improved from 0.178 to 0.179\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0323 - val_loss: 0.0439\n",
      "Counter: 1, Global: 0.17863663892057957, MyBest: 0.17753849970176816\n",
      "\n",
      "Epoch 14/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0322\n",
      "validate accuracy:\n",
      " [0.19000914 0.0963293  0.10568562 0.24700965 0.24621813 0.06812081\n",
      " 0.00914504 0.2968637  0.42637607 0.29280224 0.1791088  0.0968061\n",
      " 0.13201459 0.26132405 0.25689992 0.19056313 0.13487911] @epoch 13\n",
      "Epoch 014: val_acc improved from 0.179 to 0.190\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0322 - val_loss: 0.0383\n",
      "Counter: 0, Global: 0.19000914233038202, MyBest: 0.17863663892057957\n",
      "\n",
      "Epoch 15/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0320\n",
      "validate accuracy:\n",
      " [0.23303133 0.12263951 0.16856188 0.25061247 0.2685492  0.13154362\n",
      " 0.12547852 0.3408007  0.48169881 0.51194966 0.28038195 0.16167326\n",
      " 0.19248036 0.20655052 0.22247003 0.14618734 0.11692351] @epoch 14\n",
      "Epoch 015: val_acc improved from 0.190 to 0.233\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0320 - val_loss: 0.0361\n",
      "Counter: 0, Global: 0.23303133342415094, MyBest: 0.19000914233038202\n",
      "\n",
      "Epoch 16/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0317\n",
      "validate accuracy:\n",
      " [0.24789548 0.12263951 0.15969899 0.25291827 0.21999712 0.15520135\n",
      " 0.16078265 0.3173869  0.4925957  0.55709296 0.27575231 0.14966083\n",
      " 0.22544894 0.28376308 0.24323948 0.174835   0.17531458] @epoch 15\n",
      "Epoch 016: val_acc improved from 0.233 to 0.248\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0317 - val_loss: 0.0341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter: 0, Global: 0.24789547827094793, MyBest: 0.23303133342415094\n",
      "\n",
      "Epoch 17/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0315\n",
      "validate accuracy:\n",
      " [0.2461836  0.10036071 0.14397994 0.24989192 0.25313357 0.1488255\n",
      " 0.13738835 0.27850845 0.56077117 0.50635916 0.34172454 0.11037309\n",
      " 0.16624579 0.34940767 0.27446333 0.17272855 0.14477591] @epoch 16\n",
      "Epoch 017: val_acc did not improve from 0.248\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0315 - val_loss: 0.0360\n",
      "Counter: 0, Global: 0.24789547827094793, MyBest: 0.24789547827094793\n",
      "\n",
      "Epoch 18/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0314\n",
      "validate accuracy:\n",
      " [0.21635484 0.05834925 0.09966555 0.24585675 0.22388704 0.13993289\n",
      " 0.14313059 0.30264488 0.53380835 0.4479385  0.2265625  0.13793103\n",
      " 0.12233446 0.25560975 0.24198495 0.14843421 0.13360667] @epoch 17\n",
      "Epoch 018: val_acc did not improve from 0.248\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0314 - val_loss: 0.0390\n",
      "Counter: 1, Global: 0.24789547827094793, MyBest: 0.24789547827094793\n",
      "\n",
      "Epoch 19/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0312\n",
      "validate accuracy:\n",
      " [0.28392111 0.15743688 0.16772576 0.24441563 0.30067715 0.1533557\n",
      " 0.11739685 0.37534326 0.59625596 0.6338225  0.37991899 0.2047767\n",
      " 0.20482604 0.33672473 0.31544465 0.20404437 0.1505726 ] @epoch 18\n",
      "Epoch 019: val_acc improved from 0.248 to 0.284\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0312 - val_loss: 0.0331\n",
      "Counter: 2, Global: 0.2839211109094322, MyBest: 0.24789547827094793\n",
      "\n",
      "Epoch 20/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0310\n",
      "validate accuracy:\n",
      " [0.30746071 0.18162529 0.16588628 0.2951434  0.2594727  0.18104027\n",
      " 0.15695448 0.38762826 0.61357921 0.63997203 0.44502315 0.20449406\n",
      " 0.25014028 0.37825784 0.32311124 0.24575201 0.19129083] @epoch 19\n",
      "Epoch 020: val_acc improved from 0.284 to 0.307\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0310 - val_loss: 0.0389\n",
      "Counter: 0, Global: 0.3074607076123357, MyBest: 0.2839211109094322\n",
      "\n",
      "Epoch 21/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0309\n",
      "validate accuracy:\n",
      " [0.25361704 0.14831318 0.18076923 0.24081279 0.25255728 0.14463088\n",
      " 0.1482348  0.32114467 0.54735959 0.55080366 0.2993345  0.15404183\n",
      " 0.19009539 0.28850174 0.28003904 0.1800309  0.13120316] @epoch 20\n",
      "Epoch 021: val_acc did not improve from 0.307\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0309 - val_loss: 0.0380\n",
      "Counter: 0, Global: 0.3074607076123357, MyBest: 0.3074607076123357\n",
      "\n",
      "Epoch 22/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0308\n",
      "validate accuracy:\n",
      " [0.31691861 0.18777849 0.18428093 0.32007495 0.28511742 0.17080536\n",
      " 0.14270523 0.36406994 0.64012295 0.67085952 0.5078125  0.18866591\n",
      " 0.26851851 0.34313589 0.34332311 0.24813931 0.20528771] @epoch 21\n",
      "Epoch 022: val_acc improved from 0.307 to 0.317\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0308 - val_loss: 0.0316\n",
      "Counter: 1, Global: 0.31691860780119896, MyBest: 0.3074607076123357\n",
      "\n",
      "Epoch 23/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0306\n",
      "validate accuracy:\n",
      " [0.29624262 0.17398685 0.11304348 0.31993082 0.25601497 0.1181208\n",
      " 0.15801786 0.36291373 0.61148363 0.57624042 0.4982639  0.15050876\n",
      " 0.25392818 0.34871081 0.38444382 0.20502739 0.20924643] @epoch 22\n",
      "Epoch 023: val_acc did not improve from 0.317\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0306 - val_loss: 0.0420\n",
      "Counter: 0, Global: 0.31691860780119896, MyBest: 0.31691860780119896\n",
      "\n",
      "Epoch 24/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0306\n",
      "validate accuracy:\n",
      " [0.31664921 0.17568427 0.19331104 0.28058797 0.29217693 0.12936242\n",
      " 0.16801362 0.38647205 0.62461579 0.67812717 0.49811921 0.22230074\n",
      " 0.24046016 0.3990244  0.37984389 0.24813931 0.15014845] @epoch 23\n",
      "Epoch 024: val_acc did not improve from 0.317\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0306 - val_loss: 0.0295\n",
      "Counter: 1, Global: 0.31691860780119896, MyBest: 0.31691860780119896\n",
      "\n",
      "Epoch 25/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0304\n",
      "validate accuracy:\n",
      " [0.33584966 0.18162529 0.2041806  0.33880964 0.33784756 0.17533557\n",
      " 0.18162484 0.38892904 0.67141658 0.69350106 0.54542822 0.19446015\n",
      " 0.27819866 0.41128919 0.33816561 0.20685297 0.22592959] @epoch 24\n",
      "Epoch 025: val_acc improved from 0.317 to 0.336\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0304 - val_loss: 0.0312\n",
      "Counter: 2, Global: 0.33584966044873, MyBest: 0.31691860780119896\n",
      "\n",
      "Epoch 26/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0303\n",
      "validate accuracy:\n",
      " [0.33194841 0.20454063 0.19916388 0.29442284 0.35095808 0.15520135\n",
      " 0.18438962 0.43243244 0.65535069 0.69042629 0.49146411 0.21368004\n",
      " 0.28254771 0.34717771 0.38555896 0.20909984 0.21476036] @epoch 25\n",
      "Epoch 026: val_acc did not improve from 0.336\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0303 - val_loss: 0.0375\n",
      "Counter: 0, Global: 0.33584966044873, MyBest: 0.33584966044873\n",
      "\n",
      "Epoch 27/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0301\n",
      "validate accuracy:\n",
      " [0.34878276 0.20072141 0.20802675 0.33708027 0.35095808 0.18708053\n",
      " 0.16397278 0.44197139 0.67365187 0.65576518 0.56061924 0.21452798\n",
      " 0.25505051 0.42522648 0.42723724 0.26288444 0.21575004] @epoch 26\n",
      "Epoch 027: val_acc improved from 0.336 to 0.349\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0301 - val_loss: 0.0288\n",
      "Counter: 1, Global: 0.3487827619537711, MyBest: 0.33584966044873\n",
      "\n",
      "Epoch 28/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0299\n",
      "validate accuracy:\n",
      " [0.3417408  0.22384892 0.18879598 0.33520681 0.31638092 0.17348993\n",
      " 0.16248405 0.44283855 0.6823135  0.69489866 0.55324072 0.20195025\n",
      " 0.28058362 0.35052264 0.42054641 0.22005336 0.22069843] @epoch 27\n",
      "Epoch 028: val_acc did not improve from 0.349\n",
      "576/576 [==============================] - 121s 211ms/step - loss: 0.0299 - val_loss: 0.0317\n",
      "Counter: 0, Global: 0.3487827619537711, MyBest: 0.3487827619537711\n",
      "\n",
      "Epoch 29/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0298\n",
      "validate accuracy:\n",
      " [0.33548642 0.17419903 0.16789298 0.30220494 0.32661    0.19798657\n",
      " 0.18949383 0.44442838 0.67742383 0.70356393 0.5619213  0.23417185\n",
      " 0.27244669 0.32752612 0.40367997 0.23578149 0.14845186] @epoch 28\n",
      "Epoch 029: val_acc did not improve from 0.349\n",
      "576/576 [==============================] - 120s 209ms/step - loss: 0.0298 - val_loss: 0.0298\n",
      "Counter: 1, Global: 0.3487827619537711, MyBest: 0.3487827619537711\n",
      "\n",
      "Epoch 30/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0297\n",
      "validate accuracy:\n",
      " [0.32312544 0.18374708 0.17290969 0.28952298 0.34605965 0.14932886\n",
      " 0.17205444 0.43604568 0.68496788 0.69447941 0.49985531 0.15093273\n",
      " 0.27034232 0.37895471 0.33718985 0.19210786 0.21150856] @epoch 29\n",
      "Epoch 030: val_acc did not improve from 0.349\n",
      "576/576 [==============================] - 121s 209ms/step - loss: 0.0297 - val_loss: 0.0363\n",
      "Counter: 2, Global: 0.3487827619537711, MyBest: 0.3487827619537711\n",
      "\n",
      "Epoch 31/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0296\n",
      "validate accuracy:\n",
      " [0.2515693  0.08190113 0.08026756 0.29917857 0.16352111 0.06996644\n",
      " 0.12313909 0.38921809 0.48700756 0.60838574 0.4994213  0.07221594\n",
      " 0.09694164 0.39637631 0.3597714  0.18087347 0.11692351] @epoch 30\n",
      "Epoch 031: val_acc did not improve from 0.349\n",
      "576/576 [==============================] - 121s 209ms/step - loss: 0.0296 - val_loss: 0.0533\n",
      "Counter: 3, Global: 0.3487827619537711, MyBest: 0.3487827619537711\n",
      "\n",
      "Epoch 32/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0296\n",
      "validate accuracy:\n",
      " [0.34147778 0.21069382 0.18612041 0.29471105 0.31724536 0.17768456\n",
      " 0.20629519 0.41306546 0.64626992 0.63759607 0.55902779 0.17453364\n",
      " 0.25378788 0.40292683 0.46138835 0.28717875 0.23511946] @epoch 31\n",
      "Epoch 032: val_acc did not improve from 0.349\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0296 - val_loss: 0.0307\n",
      "Counter: 4, Global: 0.3487827619537711, MyBest: 0.3487827619537711\n",
      "\n",
      "Epoch 33/151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - ETA: 0s - loss: 0.0295\n",
      "validate accuracy:\n",
      " [0.3683682  0.23785275 0.18545151 0.35581496 0.32531336 0.22030202\n",
      " 0.22905147 0.42694032 0.70033526 0.72704405 0.60286456 0.22102883\n",
      " 0.26921996 0.45881534 0.43169779 0.29644713 0.20571186] @epoch 32\n",
      "Epoch 033: val_acc improved from 0.349 to 0.368\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0295 - val_loss: 0.0290\n",
      "Counter: 5, Global: 0.3683681981638074, MyBest: 0.3487827619537711\n",
      "\n",
      "Epoch 34/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0294\n",
      "validate accuracy:\n",
      " [0.35460281 0.2372162  0.2041806  0.32310131 0.26523554 0.2033557\n",
      " 0.21820502 0.4244833  0.64347583 0.72900069 0.60908562 0.18626343\n",
      " 0.29026374 0.43484321 0.43574017 0.27889341 0.19030115] @epoch 33\n",
      "Epoch 034: val_acc did not improve from 0.368\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0294 - val_loss: 0.0294\n",
      "Counter: 0, Global: 0.3683681981638074, MyBest: 0.3683681981638074\n",
      "\n",
      "Epoch 35/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0293\n",
      "validate accuracy:\n",
      " [0.36085031 0.22193931 0.20367894 0.33463034 0.31955048 0.17466442\n",
      " 0.22798809 0.40453821 0.72632021 0.73165619 0.60980904 0.18626343\n",
      " 0.2704826  0.47665507 0.38653472 0.29841316 0.2004807 ] @epoch 34\n",
      "Epoch 035: val_acc did not improve from 0.368\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0293 - val_loss: 0.0355\n",
      "Counter: 1, Global: 0.3683681981638074, MyBest: 0.3683681981638074\n",
      "\n",
      "Epoch 36/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0293\n",
      "validate accuracy:\n",
      " [0.37160146 0.23827711 0.22006689 0.33016285 0.32920328 0.20855705\n",
      " 0.24202468 0.47651395 0.73609948 0.7085954  0.55555558 0.17736009\n",
      " 0.30401236 0.43247387 0.48494563 0.24884145 0.25293368] @epoch 35\n",
      "Epoch 036: val_acc improved from 0.368 to 0.372\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0293 - val_loss: 0.0313\n",
      "Counter: 2, Global: 0.3716014586389065, MyBest: 0.3683681981638074\n",
      "\n",
      "Epoch 37/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0292\n",
      "validate accuracy:\n",
      " [0.38115019 0.19159772 0.21856187 0.37094682 0.31710127 0.22097315\n",
      " 0.21799235 0.40424916 0.74504054 0.74758911 0.63614005 0.22809497\n",
      " 0.31916386 0.49574912 0.48815167 0.25740767 0.23964372] @epoch 36\n",
      "Epoch 037: val_acc improved from 0.372 to 0.381\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0292 - val_loss: 0.0307\n",
      "Counter: 0, Global: 0.38115018978714943, MyBest: 0.3716014586389065\n",
      "\n",
      "Epoch 38/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0290\n",
      "validate accuracy:\n",
      " [0.39486696 0.22660726 0.16889632 0.37109095 0.38985738 0.22214764\n",
      " 0.23309231 0.50166208 0.73470241 0.74675053 0.64467591 0.254381\n",
      " 0.30751964 0.49574912 0.49066073 0.28661704 0.24346104] @epoch 37\n",
      "Epoch 038: val_acc improved from 0.381 to 0.395\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0290 - val_loss: 0.0263\n",
      "Counter: 0, Global: 0.39486696012318134, MyBest: 0.38115018978714943\n",
      "\n",
      "Epoch 39/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0290\n",
      "validate accuracy:\n",
      " [0.39094554 0.18014003 0.19916388 0.38348466 0.39619651 0.20755033\n",
      " 0.22756274 0.39601099 0.74993014 0.76268345 0.61921299 0.26611081\n",
      " 0.30204827 0.51303136 0.51115137 0.30332819 0.23752297] @epoch 38\n",
      "Epoch 039: val_acc did not improve from 0.395\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0290 - val_loss: 0.0304\n",
      "Counter: 0, Global: 0.39486696012318134, MyBest: 0.39486696012318134\n",
      "\n",
      "Epoch 40/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0289\n",
      "validate accuracy:\n",
      " [0.37860015 0.26628473 0.2013378  0.30941057 0.40152717 0.23137584\n",
      " 0.25818801 0.51062292 0.62922603 0.69294202 0.6076389  0.26257774\n",
      " 0.32617846 0.39763066 0.50766659 0.26709732 0.18789764] @epoch 39\n",
      "Epoch 040: val_acc did not improve from 0.395\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0289 - val_loss: 0.0363\n",
      "Counter: 1, Global: 0.39486696012318134, MyBest: 0.39486696012318134\n",
      "\n",
      "Epoch 41/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0289\n",
      "validate accuracy:\n",
      " [0.37901325 0.24867389 0.19414715 0.31748089 0.39417952 0.17869127\n",
      " 0.23521906 0.4435612  0.72827607 0.74199861 0.53023726 0.22286603\n",
      " 0.31285074 0.51233447 0.47518817 0.28886393 0.23964372] @epoch 40\n",
      "Epoch 041: val_acc did not improve from 0.395\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0289 - val_loss: 0.0287\n",
      "Counter: 2, Global: 0.39486696012318134, MyBest: 0.39486696012318134\n",
      "\n",
      "Epoch 42/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0288\n",
      "validate accuracy:\n",
      " [0.3857068  0.26670909 0.15150502 0.32238075 0.3997983  0.20637584\n",
      " 0.16524883 0.51654863 0.70354849 0.76827395 0.57581019 0.27091578\n",
      " 0.33529741 0.45240417 0.518121   0.30332819 0.21504313] @epoch 41\n",
      "Epoch 042: val_acc did not improve from 0.395\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0288 - val_loss: 0.0395\n",
      "Counter: 3, Global: 0.39486696012318134, MyBest: 0.39486696012318134\n",
      "\n",
      "Epoch 43/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0287\n",
      "validate accuracy:\n",
      " [0.40914704 0.24379376 0.18260869 0.35105923 0.40152717 0.23959732\n",
      " 0.26329222 0.46061569 0.76962841 0.72466809 0.65625    0.26780668\n",
      " 0.31874299 0.52599305 0.53484803 0.33998033 0.2659409 ] @epoch 42\n",
      "Epoch 043: val_acc improved from 0.395 to 0.409\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0287 - val_loss: 0.0291\n",
      "Counter: 4, Global: 0.409147035330534, MyBest: 0.39486696012318134\n",
      "\n",
      "Epoch 44/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0287\n",
      "validate accuracy:\n",
      " [0.3979577  0.2516444  0.18628763 0.32194841 0.41002738 0.20738254\n",
      " 0.21246278 0.46350628 0.77367979 0.77526206 0.67505789 0.23346524\n",
      " 0.29826039 0.53574914 0.44521883 0.33871648 0.23865403] @epoch 43\n",
      "Epoch 044: val_acc did not improve from 0.409\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0287 - val_loss: 0.0326\n",
      "Counter: 0, Global: 0.409147035330534, MyBest: 0.409147035330534\n",
      "\n",
      "Epoch 45/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0286\n",
      "validate accuracy:\n",
      " [0.41734262 0.25270528 0.19765887 0.39746362 0.38755223 0.23573825\n",
      " 0.26371756 0.50859952 0.75817269 0.76561844 0.66840279 0.26837197\n",
      " 0.32982603 0.53728223 0.49790913 0.34040162 0.26806164] @epoch 44\n",
      "Epoch 045: val_acc improved from 0.409 to 0.417\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0286 - val_loss: 0.0334\n",
      "Counter: 1, Global: 0.41734261624515057, MyBest: 0.409147035330534\n",
      "\n",
      "Epoch 46/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0285\n",
      "validate accuracy:\n",
      " [0.41594606 0.26692128 0.23377927 0.4007782  0.40743408 0.21241611\n",
      " 0.27052319 0.5217517  0.78164291 0.78252971 0.68417245 0.22738835\n",
      " 0.33964646 0.48209059 0.50153333 0.28521276 0.25731656] @epoch 45\n",
      "Epoch 046: val_acc did not improve from 0.417\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0285 - val_loss: 0.0286\n",
      "Counter: 0, Global: 0.41734261624515057, MyBest: 0.41734261624515057\n",
      "\n",
      "Epoch 47/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0285\n",
      "validate accuracy:\n",
      " [0.42480079 0.26713347 0.24698997 0.38492578 0.4139173  0.20100671\n",
      " 0.26988515 0.52608758 0.77367979 0.78742141 0.69314235 0.26921991\n",
      " 0.34638047 0.5286411  0.53861165 0.32242662 0.22734343] @epoch 46\n",
      "Epoch 047: val_acc improved from 0.417 to 0.425\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0285 - val_loss: 0.0292\n",
      "Counter: 1, Global: 0.42480079364031553, MyBest: 0.41734261624515057\n",
      "\n",
      "Epoch 48/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0284\n",
      "validate accuracy:\n",
      " [0.41451778 0.25970718 0.18996656 0.41028967 0.41420543 0.23708054\n",
      " 0.27626541 0.46336177 0.74084938 0.78211039 0.62282985 0.28038439\n",
      " 0.33684063 0.4958885  0.4909395  0.35289988 0.27866533] @epoch 47\n",
      "Epoch 048: val_acc did not improve from 0.425\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0284 - val_loss: 0.0328\n",
      "Counter: 0, Global: 0.42480079364031553, MyBest: 0.42480079364031553\n",
      "\n",
      "Epoch 49/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0284\n",
      "validate accuracy:\n",
      " [0.41767203 0.25143221 0.21588629 0.40899265 0.34173751 0.21610738\n",
      " 0.26626968 0.46249458 0.78373849 0.78770089 0.69328701 0.25593555\n",
      " 0.28044331 0.55205578 0.53512686 0.35598934 0.27555493] @epoch 48\n",
      "Epoch 049: val_acc did not improve from 0.425\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0284 - val_loss: 0.0357\n",
      "Counter: 1, Global: 0.42480079364031553, MyBest: 0.42480079364031553\n",
      "\n",
      "Epoch 50/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0282\n",
      "validate accuracy:\n",
      " [0.42492699 0.27562061 0.24364549 0.36431763 0.37631464 0.24647652\n",
      " 0.24011059 0.53215784 0.77703267 0.7854647  0.69878471 0.23685698\n",
      " 0.31425366 0.55261326 0.54056317 0.34995085 0.26466846] @epoch 49\n",
      "Epoch 050: val_acc improved from 0.425 to 0.425\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0282 - val_loss: 0.0320\n",
      "Counter: 2, Global: 0.4249269859865308, MyBest: 0.42480079364031553\n",
      "\n",
      "Epoch 51/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0282\n",
      "validate accuracy:\n",
      " [0.41130442 0.23403352 0.25234115 0.41144258 0.42385823 0.19060403\n",
      " 0.20693322 0.46379533 0.76166528 0.72382951 0.67173034 0.28575465\n",
      " 0.30513468 0.56627178 0.55673265 0.31961802 0.20712569] @epoch 50\n",
      "Epoch 051: val_acc did not improve from 0.425\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0282 - val_loss: 0.0323\n",
      "Counter: 0, Global: 0.4249269859865308, MyBest: 0.4249269859865308\n",
      "\n",
      "Epoch 52/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0281\n",
      "validate accuracy:\n",
      " [0.42274113 0.27519625 0.24615385 0.42153049 0.354848   0.24110739\n",
      " 0.25457251 0.46076024 0.73484212 0.74157929 0.70109951 0.23742227\n",
      " 0.3664422  0.56627178 0.55199331 0.35823619 0.25180262] @epoch 51\n",
      "Epoch 052: val_acc did not improve from 0.425\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0281 - val_loss: 0.0321\n",
      "Counter: 1, Global: 0.4249269859865308, MyBest: 0.4249269859865308\n",
      "\n",
      "Epoch 53/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0280\n",
      "validate accuracy:\n",
      " [0.4295145  0.27880332 0.24046823 0.39357257 0.41996831 0.23288591\n",
      " 0.2756274  0.54545456 0.79295892 0.80377358 0.70384836 0.28702655\n",
      " 0.36419752 0.54243904 0.46097016 0.2839489  0.2462887 ] @epoch 52\n",
      "Epoch 053: val_acc improved from 0.425 to 0.430\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0280 - val_loss: 0.0277\n",
      "Counter: 2, Global: 0.4295145031064749, MyBest: 0.4249269859865308\n",
      "\n",
      "Epoch 54/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0280\n",
      "validate accuracy:\n",
      " [0.43897494 0.28474432 0.25183946 0.39587837 0.40901887 0.19597316\n",
      " 0.27201191 0.51394713 0.7992456  0.74171907 0.72077549 0.29098362\n",
      " 0.34539843 0.59818816 0.56774461 0.367645   0.26848578] @epoch 53\n",
      "Epoch 054: val_acc improved from 0.430 to 0.439\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0280 - val_loss: 0.0316\n",
      "Counter: 0, Global: 0.43897493556141853, MyBest: 0.4295145031064749\n",
      "\n",
      "Epoch 55/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0280\n",
      "validate accuracy:\n",
      " [0.38287345 0.23785275 0.23444816 0.30537543 0.32214379 0.22281879\n",
      " 0.19481072 0.49645904 0.6793797  0.67337525 0.67332178 0.22654042\n",
      " 0.33964646 0.50675958 0.43783104 0.32340965 0.25180262] @epoch 54\n",
      "Epoch 055: val_acc did not improve from 0.439\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0280 - val_loss: 0.0340\n",
      "Counter: 0, Global: 0.43897493556141853, MyBest: 0.43897493556141853\n",
      "\n",
      "Epoch 56/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0278\n",
      "validate accuracy:\n",
      " [0.4206171  0.25800976 0.2521739  0.4051016  0.41953608 0.23708054\n",
      " 0.27796683 0.55311459 0.72645992 0.80712789 0.64293981 0.25833803\n",
      " 0.37976992 0.47317073 0.45023698 0.3142817  0.27456525] @epoch 55\n",
      "Epoch 056: val_acc did not improve from 0.439\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0278 - val_loss: 0.0328\n",
      "Counter: 1, Global: 0.43897493556141853, MyBest: 0.43897493556141853\n",
      "\n",
      "Epoch 57/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0277\n",
      "validate accuracy:\n",
      " [0.43266131 0.24676427 0.22892977 0.41201901 0.43048552 0.24932885\n",
      " 0.2460655  0.49125597 0.79952502 0.80614954 0.72887731 0.26130581\n",
      " 0.37682378 0.51010454 0.50947869 0.33478445 0.29068288] @epoch 56\n",
      "Epoch 057: val_acc did not improve from 0.439\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0277 - val_loss: 0.0294\n",
      "Counter: 2, Global: 0.43897493556141853, MyBest: 0.43897493556141853\n",
      "\n",
      "Epoch 58/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0276\n",
      "validate accuracy:\n",
      " [0.37958568 0.1663484  0.22140469 0.41835999 0.43495172 0.12332214\n",
      " 0.13547426 0.39413211 0.78639287 0.77833682 0.62065971 0.29267949\n",
      " 0.19374299 0.54898953 0.51589072 0.22679399 0.21589142] @epoch 57\n",
      "Epoch 058: val_acc did not improve from 0.439\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0276 - val_loss: 0.0455\n",
      "Counter: 3, Global: 0.43897493556141853, MyBest: 0.43897493556141853\n",
      "\n",
      "Epoch 59/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0275\n",
      "validate accuracy:\n",
      " [0.4174279  0.15977085 0.14113712 0.39213142 0.44057053 0.23674497\n",
      " 0.28817526 0.56323171 0.81112045 0.67924529 0.54658562 0.30016959\n",
      " 0.29068461 0.61045295 0.60356843 0.36006179 0.25519583] @epoch 58\n",
      "Epoch 059: val_acc did not improve from 0.439\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0275 - val_loss: 0.0384\n",
      "Counter: 4, Global: 0.43897493556141853, MyBest: 0.43897493556141853\n",
      "\n",
      "Epoch 60/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0274\n",
      "validate accuracy:\n",
      " [0.4137129  0.26586038 0.22558528 0.25810635 0.42616338 0.21996644\n",
      " 0.24202468 0.53418124 0.78974575 0.76380152 0.58738428 0.26710007\n",
      " 0.37317622 0.51038325 0.55882353 0.34756353 0.24954051] @epoch 59\n",
      "Epoch 060: val_acc did not improve from 0.439\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0274 - val_loss: 0.0307\n",
      "Counter: 5, Global: 0.43897493556141853, MyBest: 0.43897493556141853\n",
      "\n",
      "Epoch 61/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0274\n",
      "validate accuracy:\n",
      " [0.43306685 0.19711436 0.15217391 0.40193111 0.44172311 0.26040268\n",
      " 0.21671629 0.55282557 0.78597373 0.81257862 0.72294563 0.27261165\n",
      " 0.24116161 0.60348433 0.59632003 0.38042411 0.29068288] @epoch 60\n",
      "Epoch 061: val_acc did not improve from 0.439\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0274 - val_loss: 0.0352\n",
      "Counter: 6, Global: 0.43897493556141853, MyBest: 0.43897493556141853\n",
      "\n",
      "Epoch 62/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0272\n",
      "validate accuracy:\n",
      " [0.36189751 0.17504774 0.24013378 0.36157948 0.42529896 0.20973155\n",
      " 0.18460229 0.49154502 0.61427772 0.65576518 0.6261574  0.1302996\n",
      " 0.20314254 0.46662021 0.43434626 0.32439265 0.24741976] @epoch 61\n",
      "Epoch 062: val_acc did not improve from 0.439\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0272 - val_loss: 0.0345\n",
      "Counter: 7, Global: 0.43897493556141853, MyBest: 0.43897493556141853\n",
      "\n",
      "Epoch 062: Updating Learning rate.. New value is 0.000050\n",
      "Epoch 63/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0243\n",
      "validate accuracy:\n",
      " [0.47831584 0.29365584 0.26354516 0.44675025 0.47053739 0.26291946\n",
      " 0.30263719 0.58202052 0.81531155 0.83102727 0.75622106 0.31246465\n",
      " 0.40137485 0.62411147 0.62391973 0.38421571 0.2823413 ] @epoch 62\n",
      "Epoch 063: val_acc improved from 0.439 to 0.478\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0243 - val_loss: 0.0251\n",
      "Counter: 0, Global: 0.4783158376812935, MyBest: 0.43897493556141853\n",
      "\n",
      "Epoch 64/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0243\n",
      "validate accuracy:\n",
      " [0.4712815  0.28813919 0.25819397 0.44689438 0.46261346 0.25318792\n",
      " 0.2858358  0.57898539 0.82313496 0.8352201  0.73958331 0.31712833\n",
      " 0.39323795 0.61310107 0.625453   0.35809577 0.26169941] @epoch 63\n",
      "Epoch 064: val_acc did not improve from 0.478\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0243 - val_loss: 0.0251\n",
      "Counter: 0, Global: 0.4783158376812935, MyBest: 0.4783158376812935\n",
      "\n",
      "Epoch 65/151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - ETA: 0s - loss: 0.0243\n",
      "validate accuracy:\n",
      " [0.48269539 0.29132187 0.26555184 0.45352358 0.46520674 0.26828858\n",
      " 0.30263719 0.58418846 0.82509083 0.83731657 0.75708914 0.30992085\n",
      " 0.39870933 0.63707316 0.62684697 0.40303329 0.29732788] @epoch 64\n",
      "Epoch 065: val_acc improved from 0.478 to 0.483\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0243 - val_loss: 0.0247\n",
      "Counter: 1, Global: 0.4826953914016485, MyBest: 0.4783158376812935\n",
      "\n",
      "Epoch 66/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0243\n",
      "validate accuracy:\n",
      " [0.48164926 0.29556546 0.26622075 0.45914397 0.44143495 0.26627517\n",
      " 0.31071883 0.5599075  0.82341439 0.82515723 0.76027197 0.31628039\n",
      " 0.4176487  0.63094079 0.62517422 0.40963349 0.29860032] @epoch 65\n",
      "Epoch 066: val_acc did not improve from 0.483\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0243 - val_loss: 0.0252\n",
      "Counter: 0, Global: 0.4826953914016485, MyBest: 0.4826953914016485\n",
      "\n",
      "Epoch 67/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0242\n",
      "validate accuracy:\n",
      " [0.47237264 0.25843412 0.27023411 0.45438823 0.46679154 0.23758389\n",
      " 0.25584859 0.57595026 0.8218776  0.83368272 0.75737846 0.29861504\n",
      " 0.40067339 0.6137979  0.61959857 0.40935263 0.28375512] @epoch 66\n",
      "Epoch 067: val_acc did not improve from 0.483\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0242 - val_loss: 0.0251\n",
      "Counter: 1, Global: 0.4826953914016485, MyBest: 0.4826953914016485\n",
      "\n",
      "Epoch 68/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0242\n",
      "validate accuracy:\n",
      " [0.48033117 0.3023552  0.23896322 0.45597348 0.45123181 0.26409397\n",
      " 0.29817098 0.58693451 0.82397318 0.83619845 0.75969326 0.31698701\n",
      " 0.41947252 0.62536585 0.62740451 0.37719423 0.30128658] @epoch 67\n",
      "Epoch 068: val_acc did not improve from 0.483\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0242 - val_loss: 0.0251\n",
      "Counter: 2, Global: 0.4826953914016485, MyBest: 0.4826953914016485\n",
      "\n",
      "Epoch 69/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0242\n",
      "validate accuracy:\n",
      " [0.48162518 0.2830469  0.26856187 0.45755872 0.46794409 0.25637585\n",
      " 0.30157381 0.57884085 0.81908357 0.83759606 0.76142937 0.32207462\n",
      " 0.41470259 0.60278744 0.625453   0.40471843 0.30425563] @epoch 68\n",
      "Epoch 069: val_acc did not improve from 0.483\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0242 - val_loss: 0.0248\n",
      "Counter: 3, Global: 0.4826953914016485, MyBest: 0.4826953914016485\n",
      "\n",
      "Epoch 70/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0242\n",
      "validate accuracy:\n",
      " [0.48567361 0.29004881 0.27274248 0.45827928 0.47082552 0.26325503\n",
      " 0.2998724  0.57985258 0.82425261 0.8378756  0.75983799 0.32094404\n",
      " 0.42410213 0.63874567 0.625453   0.41089734 0.29379329] @epoch 69\n",
      "Epoch 070: val_acc improved from 0.483 to 0.486\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0242 - val_loss: 0.0247\n",
      "Counter: 4, Global: 0.48567361012101173, MyBest: 0.4826953914016485\n",
      "\n",
      "Epoch 71/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0242\n",
      "validate accuracy:\n",
      " [0.48144137 0.26437512 0.27224082 0.45842341 0.46909666 0.26057047\n",
      " 0.29753298 0.58259863 0.82271582 0.83633822 0.76490164 0.31613907\n",
      " 0.42031425 0.6319164  0.62447727 0.38140711 0.30001414] @epoch 70\n",
      "Epoch 071: val_acc did not improve from 0.486\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0242 - val_loss: 0.0249\n",
      "Counter: 0, Global: 0.48567361012101173, MyBest: 0.48567361012101173\n",
      "\n",
      "Epoch 72/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0242\n",
      "validate accuracy:\n",
      " [0.48689523 0.28941226 0.27173913 0.46245858 0.46823224 0.25369129\n",
      " 0.30965546 0.59083682 0.82369375 0.83927321 0.77039933 0.31797627\n",
      " 0.424523   0.63874567 0.61778647 0.41103777 0.30086243] @epoch 71\n",
      "Epoch 072: val_acc improved from 0.486 to 0.487\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0242 - val_loss: 0.0248\n",
      "Counter: 1, Global: 0.48689522966742516, MyBest: 0.48567361012101173\n",
      "\n",
      "Epoch 73/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0242\n",
      "validate accuracy:\n",
      " [0.48499059 0.29811162 0.26187292 0.46317914 0.47745281 0.26023489\n",
      " 0.30710337 0.57450497 0.82802457 0.83969253 0.75564235 0.31981346\n",
      " 0.3991302  0.6394425  0.63033175 0.402612   0.3027004 ] @epoch 72\n",
      "Epoch 073: val_acc did not improve from 0.487\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0242 - val_loss: 0.0248\n",
      "Counter: 0, Global: 0.48689522966742516, MyBest: 0.48689522966742516\n",
      "\n",
      "Epoch 74/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0241\n",
      "validate accuracy:\n",
      " [0.4887098  0.30256736 0.26806021 0.46000865 0.47269845 0.2614094\n",
      " 0.30837941 0.58866888 0.82970101 0.84262753 0.77025461 0.30243075\n",
      " 0.42438272 0.6419512  0.62517422 0.41805926 0.30298316] @epoch 73\n",
      "Epoch 074: val_acc improved from 0.487 to 0.489\n",
      "576/576 [==============================] - 122s 211ms/step - loss: 0.0241 - val_loss: 0.0247\n",
      "Counter: 1, Global: 0.4887098018079996, MyBest: 0.48689522966742516\n",
      "\n",
      "Epoch 75/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0241\n",
      "validate accuracy:\n",
      " [0.48911366 0.29747507 0.27274248 0.45568526 0.48019019 0.26728189\n",
      " 0.306678   0.57970804 0.82537019 0.84053111 0.76909721 0.31585643\n",
      " 0.42241862 0.64236933 0.62587118 0.42297429 0.30156934] @epoch 74\n",
      "Epoch 075: val_acc improved from 0.489 to 0.489\n",
      "576/576 [==============================] - 121s 209ms/step - loss: 0.0241 - val_loss: 0.0246\n",
      "Counter: 0, Global: 0.48911366425454617, MyBest: 0.4887098018079996\n",
      "\n",
      "Epoch 76/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0241\n",
      "validate accuracy:\n",
      " [0.48771556 0.27328664 0.27307692 0.46317914 0.47846133 0.26124161\n",
      " 0.30582732 0.58202052 0.8277452  0.83759606 0.76634836 0.31797627\n",
      " 0.42578563 0.64348429 0.62977421 0.41862097 0.29902446] @epoch 75\n",
      "Epoch 076: val_acc did not improve from 0.489\n",
      "576/576 [==============================] - 121s 209ms/step - loss: 0.0241 - val_loss: 0.0247\n",
      "Counter: 0, Global: 0.48911366425454617, MyBest: 0.48911366425454617\n",
      "\n",
      "Epoch 77/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0241\n",
      "validate accuracy:\n",
      " [0.48753286 0.30171865 0.2729097  0.44271508 0.47946981 0.26208055\n",
      " 0.30242449 0.58881342 0.82746577 0.83857441 0.76895255 0.29918033\n",
      " 0.42873177 0.64153308 0.62461668 0.4159528  0.30538669] @epoch 76\n",
      "Epoch 077: val_acc did not improve from 0.489\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0241 - val_loss: 0.0246\n",
      "Counter: 1, Global: 0.48911366425454617, MyBest: 0.48911366425454617\n",
      "\n",
      "Epoch 78/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0241\n",
      "validate accuracy:\n",
      " [0.48415589 0.29280713 0.27474916 0.40538982 0.4830716  0.25989932\n",
      " 0.30561462 0.58317673 0.82537019 0.84067088 0.76663774 0.31613907\n",
      " 0.41835016 0.64905924 0.63353777 0.42367646 0.2683444 ] @epoch 77\n",
      "Epoch 078: val_acc did not improve from 0.489\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0241 - val_loss: 0.0249\n",
      "Counter: 2, Global: 0.48911366425454617, MyBest: 0.48911366425454617\n",
      "\n",
      "Epoch 79/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0241\n",
      "validate accuracy:\n",
      " [0.48519093 0.287927   0.25836119 0.46202624 0.48638526 0.25453019\n",
      " 0.28987664 0.59199303 0.82606876 0.83214533 0.77054399 0.31034482\n",
      " 0.41652638 0.64250869 0.62824088 0.42620417 0.27937227] @epoch 78\n",
      "Epoch 079: val_acc did not improve from 0.489\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0241 - val_loss: 0.0248\n",
      "Counter: 3, Global: 0.48911366425454617, MyBest: 0.48911366425454617\n",
      "\n",
      "Epoch 80/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0241\n",
      "validate accuracy:\n",
      " [0.48065583 0.27265012 0.26204014 0.42513332 0.48422417 0.26845637\n",
      " 0.30370057 0.59199303 0.82704663 0.83927321 0.76866317 0.3188242\n",
      " 0.36630189 0.63804877 0.63200444 0.40710574 0.28502756] @epoch 79\n",
      "Epoch 080: val_acc did not improve from 0.489\n",
      "576/576 [==============================] - 122s 213ms/step - loss: 0.0241 - val_loss: 0.0254\n",
      "Counter: 4, Global: 0.48911366425454617, MyBest: 0.48911366425454617\n",
      "\n",
      "Epoch 81/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0241\n",
      "validate accuracy:\n",
      " [0.48283594 0.30511352 0.27190635 0.43896815 0.4502233  0.20469798\n",
      " 0.29710761 0.58014166 0.82760549 0.83829492 0.77112269 0.30780101\n",
      " 0.42718855 0.64738679 0.6314469  0.42465946 0.30171072] @epoch 80\n",
      "Epoch 081: val_acc did not improve from 0.489\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0241 - val_loss: 0.0251\n",
      "Counter: 5, Global: 0.48911366425454617, MyBest: 0.48911366425454617\n",
      "\n",
      "Epoch 82/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0241\n",
      "validate accuracy:\n",
      " [0.49335009 0.30765966 0.27341136 0.46908778 0.48681745 0.26761746\n",
      " 0.30901745 0.59387195 0.82928193 0.84039134 0.77184606 0.32037875\n",
      " 0.42508417 0.64613241 0.63576806 0.41651455 0.30072105] @epoch 81\n",
      "Epoch 082: val_acc improved from 0.489 to 0.493\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0241 - val_loss: 0.0251\n",
      "Counter: 6, Global: 0.493350088596344, MyBest: 0.48911366425454617\n",
      "\n",
      "Epoch 83/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0240\n",
      "validate accuracy:\n",
      " [0.49075972 0.29662636 0.27307692 0.46289089 0.48451233 0.26862416\n",
      " 0.30859208 0.59329385 0.83081865 0.83801538 0.76490164 0.32532504\n",
      " 0.42536476 0.62759584 0.63047117 0.4159528  0.3060936 ] @epoch 82\n",
      "Epoch 083: val_acc did not improve from 0.493\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0240 - val_loss: 0.0248\n",
      "Counter: 0, Global: 0.493350088596344, MyBest: 0.493350088596344\n",
      "\n",
      "Epoch 84/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0240\n",
      "validate accuracy:\n",
      " [0.48894036 0.27052832 0.26705685 0.43003315 0.48595303 0.26426175\n",
      " 0.30582732 0.59575081 0.82858342 0.83689725 0.77416086 0.32052007\n",
      " 0.43069586 0.64627177 0.63674378 0.42494032 0.30482116] @epoch 83\n",
      "Epoch 084: val_acc did not improve from 0.493\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0240 - val_loss: 0.0248\n",
      "Counter: 1, Global: 0.493350088596344, MyBest: 0.493350088596344\n",
      "\n",
      "Epoch 85/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0240\n",
      "validate accuracy:\n",
      " [0.47563471 0.22872905 0.26070234 0.42340395 0.4810546  0.26862416\n",
      " 0.2962569  0.58881342 0.8277452  0.83801538 0.77025461 0.31585643\n",
      " 0.38874859 0.63205576 0.62182885 0.37017274 0.2978934 ] @epoch 84\n",
      "Epoch 085: val_acc did not improve from 0.493\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0240 - val_loss: 0.0252\n",
      "Counter: 2, Global: 0.493350088596344, MyBest: 0.493350088596344\n",
      "\n",
      "Epoch 86/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0240\n",
      "validate accuracy:\n",
      " [0.49088591 0.30320391 0.27625418 0.46836719 0.47817317 0.26375839\n",
      " 0.31135687 0.57464951 0.82760549 0.84304684 0.77430558 0.31924817\n",
      " 0.41919193 0.64473867 0.63548928 0.4233956  0.29138979] @epoch 85\n",
      "Epoch 086: val_acc did not improve from 0.493\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0240 - val_loss: 0.0247\n",
      "Counter: 3, Global: 0.493350088596344, MyBest: 0.493350088596344\n",
      "\n",
      "Epoch 87/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0240\n",
      "validate accuracy:\n",
      " [0.4920033  0.30447698 0.27525082 0.46447614 0.48335975 0.27013424\n",
      " 0.30859208 0.59329385 0.83012015 0.84067088 0.77488428 0.28208026\n",
      " 0.42803031 0.64808363 0.6381377  0.42592332 0.3045384 ] @epoch 86\n",
      "Epoch 087: val_acc did not improve from 0.493\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0240 - val_loss: 0.0248\n",
      "Counter: 4, Global: 0.493350088596344, MyBest: 0.493350088596344\n",
      "\n",
      "Epoch 88/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0240\n",
      "validate accuracy:\n",
      " [0.48552728 0.30532569 0.26956522 0.46462026 0.49013111 0.24244967\n",
      " 0.29838365 0.5925712  0.8277452  0.83871418 0.77271414 0.32080272\n",
      " 0.3971661  0.64222997 0.63660443 0.42171043 0.24770252] @epoch 87\n",
      "Epoch 088: val_acc did not improve from 0.493\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0240 - val_loss: 0.0250\n",
      "Counter: 5, Global: 0.493350088596344, MyBest: 0.493350088596344\n",
      "\n",
      "Epoch 89/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0240\n",
      "validate accuracy:\n",
      " [0.49452714 0.3072353  0.27257526 0.47225824 0.48595303 0.27500001\n",
      " 0.30816674 0.59011418 0.83249509 0.84290707 0.77141201 0.31712833\n",
      " 0.43111673 0.64557493 0.63339835 0.42142957 0.30566946] @epoch 88\n",
      "Epoch 089: val_acc improved from 0.493 to 0.495\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0240 - val_loss: 0.0246\n",
      "Counter: 6, Global: 0.49452714435756207, MyBest: 0.493350088596344\n",
      "\n",
      "Epoch 90/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0240\n",
      "validate accuracy:\n",
      " [0.49108128 0.30384043 0.27357858 0.46548495 0.47831723 0.25738254\n",
      " 0.30986813 0.59170401 0.82858342 0.84039134 0.77445024 0.29833239\n",
      " 0.42312008 0.64864111 0.63172567 0.42522117 0.30665913] @epoch 89\n",
      "Epoch 090: val_acc did not improve from 0.495\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0240 - val_loss: 0.0248\n",
      "Counter: 0, Global: 0.49452714435756207, MyBest: 0.49452714435756207\n",
      "\n",
      "Epoch 91/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0240\n",
      "validate accuracy:\n",
      " [0.48865093 0.30808401 0.27274248 0.45525292 0.48422417 0.27114093\n",
      " 0.31135687 0.59401649 0.82872313 0.83857441 0.76461226 0.31854156\n",
      " 0.42971382 0.64599305 0.62071371 0.40977392 0.26495123] @epoch 90\n",
      "Epoch 091: val_acc did not improve from 0.495\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0240 - val_loss: 0.0250\n",
      "Counter: 1, Global: 0.49452714435756207, MyBest: 0.49452714435756207\n",
      "\n",
      "Epoch 92/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0239\n",
      "validate accuracy:\n",
      " [0.49397752 0.30596223 0.2750836  0.46721429 0.48206311 0.27114093\n",
      " 0.31135687 0.59430552 0.82369375 0.83871418 0.77314812 0.32136801\n",
      " 0.43420315 0.63986063 0.63521045 0.42662546 0.30369008] @epoch 91\n",
      "Epoch 092: val_acc did not improve from 0.495\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0239 - val_loss: 0.0247\n",
      "Counter: 2, Global: 0.49452714435756207, MyBest: 0.49452714435756207\n",
      "\n",
      "Epoch 93/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0239\n",
      "validate accuracy:\n",
      " [0.48714109 0.30532569 0.25016722 0.43608588 0.45569801 0.26627517\n",
      " 0.30710337 0.58404392 0.82495111 0.8378756  0.77213544 0.31981346\n",
      " 0.42255893 0.64473867 0.63897407 0.42171043 0.30680051] @epoch 92\n",
      "Epoch 093: val_acc did not improve from 0.495\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0239 - val_loss: 0.0250\n",
      "Counter: 3, Global: 0.49452714435756207, MyBest: 0.49452714435756207\n",
      "\n",
      "Epoch 94/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0239\n",
      "validate accuracy:\n",
      " [0.49581804 0.30405262 0.27742475 0.47024068 0.48696154 0.26912752\n",
      " 0.3075287  0.59748518 0.83291423 0.83997202 0.77792245 0.31953081\n",
      " 0.43308082 0.64850175 0.63618624 0.42578289 0.30637637] @epoch 93\n",
      "Epoch 094: val_acc improved from 0.495 to 0.496\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0239 - val_loss: 0.0246\n",
      "Counter: 4, Global: 0.49581803753972054, MyBest: 0.49452714435756207\n",
      "\n",
      "Epoch 95/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0239\n",
      "validate accuracy:\n",
      " [0.49469821 0.30553788 0.27541807 0.469376   0.48091054 0.2649329\n",
      " 0.3102935  0.59112591 0.82523054 0.84039134 0.77647567 0.32221594\n",
      " 0.43308082 0.64989549 0.63771957 0.4281702  0.30439702] @epoch 94\n",
      "Epoch 095: val_acc did not improve from 0.496\n",
      "576/576 [==============================] - 122s 213ms/step - loss: 0.0239 - val_loss: 0.0246\n",
      "Counter: 0, Global: 0.49581803753972054, MyBest: 0.49581803753972054\n",
      "\n",
      "Epoch 96/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0239\n",
      "validate accuracy:\n",
      " [0.49657246 0.30914491 0.27458194 0.46144977 0.49229217 0.27818793\n",
      " 0.31433433 0.59893048 0.8290025  0.83605868 0.77690971 0.31938949\n",
      " 0.43658811 0.64668989 0.63409537 0.42985535 0.30764881] @epoch 95\n",
      "Epoch 096: val_acc improved from 0.496 to 0.497\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0239 - val_loss: 0.0247\n",
      "Counter: 1, Global: 0.49657246470451355, MyBest: 0.49581803753972054\n",
      "\n",
      "Epoch 97/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0239\n",
      "validate accuracy:\n",
      " [0.49125317 0.31126672 0.27541807 0.42974493 0.46549487 0.27298659\n",
      " 0.30859208 0.5951727  0.82523054 0.84011179 0.77575231 0.31670436\n",
      " 0.43027496 0.64710802 0.63855588 0.42550203 0.30213487] @epoch 96\n",
      "Epoch 097: val_acc did not improve from 0.497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0239 - val_loss: 0.0249\n",
      "Counter: 0, Global: 0.49657246470451355, MyBest: 0.49657246470451355\n",
      "\n",
      "Epoch 98/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0239\n",
      "validate accuracy:\n",
      " [0.49578859 0.3010821  0.2729097  0.46534082 0.48753783 0.27785236\n",
      " 0.2928541  0.60124296 0.83235538 0.84150946 0.77907985 0.32391182\n",
      " 0.43406284 0.64641112 0.6399498  0.42943406 0.30708328] @epoch 97\n",
      "Epoch 098: val_acc did not improve from 0.497\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0239 - val_loss: 0.0249\n",
      "Counter: 1, Global: 0.49657246470451355, MyBest: 0.49657246470451355\n",
      "\n",
      "Epoch 99/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0239\n",
      "validate accuracy:\n",
      " [0.49486943 0.30744749 0.27023411 0.47096124 0.48681745 0.27449664\n",
      " 0.29732028 0.59560633 0.8277452  0.8371768  0.77965856 0.32023743\n",
      " 0.43181819 0.64571428 0.63925284 0.42690635 0.30651775] @epoch 98\n",
      "Epoch 099: val_acc did not improve from 0.497\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0239 - val_loss: 0.0245\n",
      "Counter: 2, Global: 0.49657246470451355, MyBest: 0.49657246470451355\n",
      "\n",
      "Epoch 100/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0239\n",
      "validate accuracy:\n",
      " [0.48960767 0.30575004 0.26471573 0.46058509 0.44748595 0.25654364\n",
      " 0.30774137 0.58086431 0.83137751 0.83731657 0.7800926  0.32136801\n",
      " 0.43167788 0.64041811 0.63730139 0.422553   0.30793157] @epoch 99\n",
      "Epoch 100: val_acc did not improve from 0.497\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0239 - val_loss: 0.0248\n",
      "Counter: 3, Global: 0.49657246470451355, MyBest: 0.49657246470451355\n",
      "\n",
      "Epoch 101/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0239\n",
      "validate accuracy:\n",
      " [0.49110967 0.30808401 0.27391306 0.47009656 0.48062238 0.27046978\n",
      " 0.30944279 0.56496602 0.82145852 0.83745635 0.77734375 0.31684569\n",
      " 0.43041527 0.64696866 0.61555618 0.4291532  0.30496255] @epoch 100\n",
      "Epoch 101: val_acc did not improve from 0.497\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0239 - val_loss: 0.0250\n",
      "Counter: 4, Global: 0.49657246470451355, MyBest: 0.49657246470451355\n",
      "\n",
      "Epoch 102/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0239\n",
      "validate accuracy:\n",
      " [0.48989202 0.29471675 0.27474916 0.43550944 0.48638526 0.27114093\n",
      " 0.29561889 0.59343839 0.82537019 0.8378756  0.77763313 0.31741098\n",
      " 0.40782827 0.64947736 0.63744074 0.43125966 0.30241764] @epoch 101\n",
      "Epoch 102: val_acc did not improve from 0.497\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0239 - val_loss: 0.0250\n",
      "Counter: 5, Global: 0.49657246470451355, MyBest: 0.49657246470451355\n",
      "\n",
      "Epoch 103/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0238\n",
      "validate accuracy:\n",
      " [0.48423566 0.28389561 0.25852844 0.46966422 0.48580897 0.26409397\n",
      " 0.31178221 0.58679003 0.82928193 0.82767296 0.77242476 0.25211984\n",
      " 0.43364197 0.64557493 0.63409537 0.4309788  0.26141664] @epoch 102\n",
      "Epoch 103: val_acc did not improve from 0.497\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0238 - val_loss: 0.0255\n",
      "Counter: 6, Global: 0.49657246470451355, MyBest: 0.49657246470451355\n",
      "\n",
      "Epoch 104/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0238\n",
      "validate accuracy:\n",
      " [0.47990614 0.23318481 0.28060201 0.44631791 0.48134273 0.21677852\n",
      " 0.23202892 0.59069228 0.83053929 0.83969253 0.77879053 0.30327868\n",
      " 0.42592594 0.64390242 0.64399219 0.4291532  0.30227625] @epoch 103\n",
      "Epoch 104: val_acc did not improve from 0.497\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0238 - val_loss: 0.0259\n",
      "Counter: 7, Global: 0.49657246470451355, MyBest: 0.49657246470451355\n",
      "\n",
      "Epoch 104: Updating Learning rate.. New value is 0.000010\n",
      "Epoch 105/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0237\n",
      "validate accuracy:\n",
      " [0.49891978 0.31126672 0.28143811 0.47067299 0.48998705 0.27869126\n",
      " 0.31242025 0.59777427 0.83053929 0.84332633 0.77994794 0.3175523\n",
      " 0.43518519 0.65170729 0.64343464 0.43041709 0.30835572] @epoch 104\n",
      "Epoch 105: val_acc improved from 0.497 to 0.499\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0237 - val_loss: 0.0245\n",
      "Counter: 0, Global: 0.498919777572155, MyBest: 0.49657246470451355\n",
      "\n",
      "Epoch 106/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0237\n",
      "validate accuracy:\n",
      " [0.49839175 0.30956927 0.28143811 0.47571695 0.48926666 0.27701342\n",
      " 0.30923012 0.596618   0.83081865 0.84290707 0.7806713  0.31458452\n",
      " 0.43602693 0.6501742  0.64343464 0.42971492 0.30708328] @epoch 105\n",
      "Epoch 106: val_acc did not improve from 0.499\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0237 - val_loss: 0.0245\n",
      "Counter: 0, Global: 0.498919777572155, MyBest: 0.498919777572155\n",
      "\n",
      "Epoch 107/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0237\n",
      "validate accuracy:\n",
      " [0.49868797 0.30935711 0.28076923 0.47413173 0.4921481  0.27550337\n",
      " 0.31305829 0.5971961  0.83067894 0.84220827 0.78110534 0.31401923\n",
      " 0.43350169 0.65184671 0.6423195  0.43224266 0.30892125] @epoch 106\n",
      "Epoch 107: val_acc did not improve from 0.499\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0237 - val_loss: 0.0244\n",
      "Counter: 1, Global: 0.498919777572155, MyBest: 0.498919777572155\n",
      "\n",
      "Epoch 108/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0236\n",
      "validate accuracy:\n",
      " [0.49730112 0.30850837 0.27892977 0.47355527 0.48552081 0.277349\n",
      " 0.30880475 0.59618443 0.82942164 0.84122992 0.78023726 0.31246465\n",
      " 0.43532547 0.65045297 0.64134371 0.4319618  0.30552807] @epoch 107\n",
      "Epoch 108: val_acc did not improve from 0.499\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0236 - val_loss: 0.0245\n",
      "Counter: 2, Global: 0.498919777572155, MyBest: 0.498919777572155\n",
      "\n",
      "Epoch 109/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0236\n",
      "validate accuracy:\n",
      " [0.49722339 0.30044559 0.27742475 0.47441995 0.4891226  0.27315435\n",
      " 0.31263292 0.59791875 0.83095837 0.84234798 0.77994794 0.31232333\n",
      " 0.43630752 0.65114981 0.64036798 0.4339278  0.30312455] @epoch 108\n",
      "Epoch 109: val_acc did not improve from 0.499\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0236 - val_loss: 0.0245\n",
      "Counter: 3, Global: 0.498919777572155, MyBest: 0.498919777572155\n",
      "\n",
      "Epoch 110/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0236\n",
      "validate accuracy:\n",
      " [0.49884998 0.31253979 0.28177258 0.47341114 0.48926666 0.27751678\n",
      " 0.31199491 0.5986414  0.83067894 0.84220827 0.78197336 0.31416056\n",
      " 0.43658811 0.65045297 0.64022863 0.43350652 0.30665913] @epoch 109\n",
      "Epoch 110: val_acc did not improve from 0.499\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0236 - val_loss: 0.0245\n",
      "Counter: 4, Global: 0.498919777572155, MyBest: 0.498919777572155\n",
      "\n",
      "Epoch 111/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0236\n",
      "validate accuracy:\n",
      " [0.49760011 0.31190324 0.28060201 0.4716818  0.4856649  0.27802014\n",
      " 0.30944279 0.596618   0.82970101 0.84290707 0.77965856 0.31331262\n",
      " 0.43518519 0.64850175 0.64162254 0.43238309 0.30439702] @epoch 110\n",
      "Epoch 111: val_acc did not improve from 0.499\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0236 - val_loss: 0.0245\n",
      "Counter: 5, Global: 0.498919777572155, MyBest: 0.498919777572155\n",
      "\n",
      "Epoch 112/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0236\n",
      "validate accuracy:\n",
      " [0.49840202 0.31105453 0.27976587 0.47384349 0.4891226  0.27701342\n",
      " 0.31284559 0.59806329 0.83067894 0.8427673  0.78081596 0.31274733\n",
      " 0.43434343 0.65365851 0.64134371 0.43055752 0.30581084] @epoch 111\n",
      "Epoch 112: val_acc did not improve from 0.499\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0236 - val_loss: 0.0245\n",
      "Counter: 6, Global: 0.498919777572155, MyBest: 0.498919777572155\n",
      "\n",
      "Epoch 113/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0236\n",
      "validate accuracy:\n",
      " [0.49690832 0.30277956 0.27658862 0.46620551 0.49157181 0.27684563\n",
      " 0.31050617 0.59734064 0.83151716 0.8434661  0.78153938 0.31331262\n",
      " 0.42859146 0.65156794 0.64190131 0.42957449 0.30722466] @epoch 112\n",
      "Epoch 113: val_acc did not improve from 0.499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0236 - val_loss: 0.0246\n",
      "Counter: 7, Global: 0.498919777572155, MyBest: 0.498919777572155\n",
      "\n",
      "Epoch 113: Updating Learning rate.. New value is 0.000002\n",
      "Epoch 114/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0236\n",
      "validate accuracy:\n",
      " [0.49887143 0.31232759 0.28260869 0.47283471 0.49113959 0.27634227\n",
      " 0.31135687 0.59734064 0.83081865 0.84206849 0.7818287  0.31585643\n",
      " 0.43672839 0.64933801 0.64259827 0.4329448  0.30581084] @epoch 113\n",
      "Epoch 114: val_acc did not improve from 0.499\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0236 - val_loss: 0.0245\n",
      "Counter: 0, Global: 0.498919777572155, MyBest: 0.498919777572155\n",
      "\n",
      "Epoch 115/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0236\n",
      "validate accuracy:\n",
      " [0.49798784 0.30935711 0.28110367 0.4718259  0.48825818 0.27651006\n",
      " 0.31135687 0.59705162 0.83025986 0.84290707 0.78125    0.31288865\n",
      " 0.43504488 0.65073168 0.64106494 0.43224266 0.30595222] @epoch 114\n",
      "Epoch 115: val_acc did not improve from 0.499\n",
      "576/576 [==============================] - 122s 213ms/step - loss: 0.0236 - val_loss: 0.0245\n",
      "Counter: 1, Global: 0.498919777572155, MyBest: 0.498919777572155\n",
      "\n",
      "Epoch 116/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0236\n",
      "validate accuracy:\n",
      " [0.49772946 0.31084237 0.27943143 0.4729788  0.49013111 0.27667785\n",
      " 0.3102935  0.59531724 0.83053929 0.84220827 0.78168404 0.31274733\n",
      " 0.43308082 0.65003484 0.64134371 0.43168095 0.30467978] @epoch 115\n",
      "Epoch 116: val_acc did not improve from 0.499\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0236 - val_loss: 0.0245\n",
      "Counter: 2, Global: 0.498919777572155, MyBest: 0.498919777572155\n",
      "\n",
      "Epoch 117/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0236\n",
      "validate accuracy:\n",
      " [0.49797546 0.31147888 0.28294313 0.47211415 0.48941076 0.27550337\n",
      " 0.30965546 0.59488368 0.83165687 0.84122992 0.78125    0.31204069\n",
      " 0.43546578 0.65142858 0.64120436 0.4329448  0.30439702] @epoch 116\n",
      "Epoch 117: val_acc did not improve from 0.499\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0236 - val_loss: 0.0245\n",
      "Counter: 3, Global: 0.498919777572155, MyBest: 0.498919777572155\n",
      "\n",
      "Epoch 118/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0236\n",
      "validate accuracy:\n",
      " [0.49861285 0.31147888 0.28076923 0.4729788  0.49041924 0.27634227\n",
      " 0.3111442  0.59950858 0.83123779 0.84318656 0.78197336 0.31331262\n",
      " 0.43448374 0.65156794 0.64064676 0.4329448  0.30581084] @epoch 117\n",
      "Epoch 118: val_acc did not improve from 0.499\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0236 - val_loss: 0.0245\n",
      "Counter: 4, Global: 0.498919777572155, MyBest: 0.498919777572155\n",
      "\n",
      "Epoch 119/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0236\n",
      "validate accuracy:\n",
      " [0.4988167  0.31084237 0.28160536 0.47326705 0.49056333 0.27684563\n",
      " 0.31178221 0.59791875 0.83165687 0.84318656 0.78211808 0.31359527\n",
      " 0.43532547 0.65198606 0.64190131 0.4329448  0.30552807] @epoch 118\n",
      "Epoch 119: val_acc did not improve from 0.499\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0236 - val_loss: 0.0245\n",
      "Counter: 5, Global: 0.498919777572155, MyBest: 0.498919777572155\n",
      "\n",
      "Epoch 120/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0236\n",
      "validate accuracy:\n",
      " [0.49884863 0.31211543 0.28160536 0.47283471 0.49142775 0.27634227\n",
      " 0.3102935  0.59618443 0.83151716 0.84150946 0.78139466 0.31387791\n",
      " 0.43588665 0.65128922 0.64218009 0.43575341 0.30736604] @epoch 119\n",
      "Epoch 120: val_acc did not improve from 0.499\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0236 - val_loss: 0.0244\n",
      "Counter: 6, Global: 0.498919777572155, MyBest: 0.498919777572155\n",
      "\n",
      "Epoch 121/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0236\n",
      "validate accuracy:\n",
      " [0.49827415 0.31232759 0.28143811 0.47269058 0.4891226  0.27617449\n",
      " 0.31071883 0.59820783 0.83012015 0.84109014 0.78327549 0.31204069\n",
      " 0.43546578 0.65059233 0.64036798 0.43322566 0.30552807] @epoch 120\n",
      "Epoch 121: val_acc did not improve from 0.499\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0236 - val_loss: 0.0245\n",
      "Counter: 7, Global: 0.498919777572155, MyBest: 0.498919777572155\n",
      "\n",
      "Epoch 121: Updating Learning rate.. New value is 0.000000\n",
      "Epoch 122/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0236\n",
      "validate accuracy:\n",
      " [0.49867609 0.31105453 0.28160536 0.47269058 0.49243626 0.27500001\n",
      " 0.31220758 0.59878594 0.83039957 0.84248775 0.78269678 0.3114754\n",
      " 0.43574634 0.65073168 0.6417619  0.43406826 0.30566946] @epoch 121\n",
      "Epoch 122: val_acc did not improve from 0.499\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0236 - val_loss: 0.0245\n",
      "Counter: 0, Global: 0.498919777572155, MyBest: 0.498919777572155\n",
      "\n",
      "Epoch 123/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0236\n",
      "validate accuracy:\n",
      " [0.49852425 0.31105453 0.28110367 0.47355527 0.49171588 0.27583891\n",
      " 0.31156954 0.59878594 0.83095837 0.84178895 0.7818287  0.31175804\n",
      " 0.43546578 0.65142858 0.64120436 0.4329448  0.30538669] @epoch 122\n",
      "Epoch 123: val_acc did not improve from 0.499\n",
      "576/576 [==============================] - 122s 213ms/step - loss: 0.0236 - val_loss: 0.0245\n",
      "Counter: 1, Global: 0.498919777572155, MyBest: 0.498919777572155\n",
      "\n",
      "Epoch 124/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0236\n",
      "validate accuracy:\n",
      " [0.49850339 0.31063017 0.28127089 0.47369939 0.49027517 0.27500001\n",
      " 0.31199491 0.59965312 0.83025986 0.84178895 0.78327549 0.31218201\n",
      " 0.43490461 0.65101045 0.64078617 0.43266395 0.30665913] @epoch 123\n",
      "Epoch 124: val_acc did not improve from 0.499\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0236 - val_loss: 0.0245\n",
      "Counter: 2, Global: 0.498919777572155, MyBest: 0.498919777572155\n",
      "\n",
      "Epoch 125/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0236\n",
      "validate accuracy:\n",
      " [0.49892441 0.31147888 0.28127089 0.47283471 0.49344474 0.2760067\n",
      " 0.31199491 0.59748518 0.83179659 0.84262753 0.78313076 0.31288865\n",
      " 0.43602693 0.65101045 0.64190131 0.43364695 0.30524531] @epoch 124\n",
      "Epoch 125: val_acc improved from 0.499 to 0.499\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0236 - val_loss: 0.0245\n",
      "Counter: 3, Global: 0.49892440624535084, MyBest: 0.498919777572155\n",
      "\n",
      "Epoch 126/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0236\n",
      "validate accuracy:\n",
      " [0.49839726 0.31105453 0.28043479 0.47312292 0.49171588 0.27516779\n",
      " 0.31071883 0.5986414  0.83053929 0.84136969 0.78226274 0.3131713\n",
      " 0.43518519 0.65031362 0.64148313 0.43364695 0.30552807] @epoch 125\n",
      "Epoch 126: val_acc did not improve from 0.499\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0236 - val_loss: 0.0245\n",
      "Counter: 0, Global: 0.49892440624535084, MyBest: 0.49892440624535084\n",
      "\n",
      "Epoch 127/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0236\n",
      "validate accuracy:\n",
      " [0.49898942 0.31190324 0.28127089 0.47427583 0.49200404 0.277349\n",
      " 0.31199491 0.59762973 0.83109808 0.84234798 0.78211808 0.31232333\n",
      " 0.43630752 0.65198606 0.64120436 0.43448955 0.30552807] @epoch 126\n",
      "Epoch 127: val_acc improved from 0.499 to 0.499\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0236 - val_loss: 0.0245\n",
      "Counter: 1, Global: 0.4989894162863493, MyBest: 0.49892440624535084\n",
      "\n",
      "Epoch 128/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0236\n",
      "validate accuracy:\n",
      " [0.49821149 0.31063017 0.28026757 0.47283471 0.4907074  0.27701342\n",
      " 0.31050617 0.59734064 0.83053929 0.84234798 0.7818287  0.31288865\n",
      " 0.43420315 0.64905924 0.64204073 0.43350652 0.30566946] @epoch 127\n",
      "Epoch 128: val_acc did not improve from 0.499\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0236 - val_loss: 0.0245\n",
      "Counter: 0, Global: 0.4989894162863493, MyBest: 0.4989894162863493\n",
      "\n",
      "Epoch 129/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0236\n",
      "validate accuracy:\n",
      " [0.49870946 0.31190324 0.27926421 0.47441995 0.49171588 0.27583891\n",
      " 0.31156954 0.59849691 0.83123779 0.84290707 0.78197336 0.31331262\n",
      " 0.4347643  0.65128922 0.64120436 0.43420869 0.30524531] @epoch 128\n",
      "Epoch 129: val_acc did not improve from 0.499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0236 - val_loss: 0.0245\n",
      "Counter: 1, Global: 0.4989894162863493, MyBest: 0.4989894162863493\n",
      "\n",
      "Epoch 130/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0236\n",
      "validate accuracy:\n",
      " [0.49883796 0.31105453 0.28294313 0.47326705 0.49200404 0.27785236\n",
      " 0.31178221 0.59777427 0.83067894 0.84206849 0.78153938 0.31260601\n",
      " 0.4347643  0.65073168 0.6423195  0.4339278  0.3060936 ] @epoch 129\n",
      "Epoch 130: val_acc did not improve from 0.499\n",
      "576/576 [==============================] - 122s 213ms/step - loss: 0.0236 - val_loss: 0.0245\n",
      "Counter: 2, Global: 0.4989894162863493, MyBest: 0.4989894162863493\n",
      "\n",
      "Epoch 131/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0236\n",
      "validate accuracy:\n",
      " [0.49850674 0.31020582 0.28110367 0.47341114 0.48926666 0.27718121\n",
      " 0.3111442  0.59849691 0.83095837 0.84290707 0.7818287  0.31232333\n",
      " 0.43532547 0.6508711  0.64148313 0.43336609 0.30623499] @epoch 130\n",
      "Epoch 131: val_acc did not improve from 0.499\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0236 - val_loss: 0.0245\n",
      "Counter: 3, Global: 0.4989894162863493, MyBest: 0.4989894162863493\n",
      "\n",
      "Epoch 132/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0236\n",
      "validate accuracy:\n",
      " [0.49857437 0.31105453 0.28160536 0.47240236 0.49099553 0.27684563\n",
      " 0.3111442  0.59806329 0.83109808 0.84262753 0.78385419 0.31218201\n",
      " 0.43574634 0.64947736 0.64148313 0.43350652 0.30510393] @epoch 131\n",
      "Epoch 132: val_acc did not improve from 0.499\n",
      "576/576 [==============================] - 122s 213ms/step - loss: 0.0236 - val_loss: 0.0245\n",
      "Counter: 4, Global: 0.4989894162863493, MyBest: 0.4989894162863493\n",
      "\n",
      "Epoch 133/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0236\n",
      "validate accuracy:\n",
      " [0.498525   0.31105453 0.28160536 0.4729788  0.49157181 0.27583891\n",
      " 0.3111442  0.59762973 0.83081865 0.84122992 0.78139466 0.31246465\n",
      " 0.43532547 0.65212542 0.64162254 0.43420869 0.30538669] @epoch 132\n",
      "Epoch 133: val_acc did not improve from 0.499\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0236 - val_loss: 0.0245\n",
      "Counter: 5, Global: 0.4989894162863493, MyBest: 0.4989894162863493\n",
      "\n",
      "Epoch 134/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0236\n",
      "validate accuracy:\n",
      " [0.49819408 0.31147888 0.28127089 0.47153768 0.48883447 0.27768457\n",
      " 0.31071883 0.59835237 0.83095837 0.84248775 0.7818287  0.3114754\n",
      " 0.43434343 0.65003484 0.64190131 0.43182138 0.30637637] @epoch 133\n",
      "Epoch 134: val_acc did not improve from 0.499\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0236 - val_loss: 0.0245\n",
      "Counter: 6, Global: 0.4989894162863493, MyBest: 0.4989894162863493\n",
      "\n",
      "Epoch 135/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0236\n",
      "validate accuracy:\n",
      " [0.49867841 0.31126672 0.28277591 0.47197002 0.49099553 0.27516779\n",
      " 0.3109315  0.59734064 0.8319363  0.84262753 0.78269678 0.31288865\n",
      " 0.43602693 0.65045297 0.6423195  0.43364695 0.30581084] @epoch 134\n",
      "Epoch 135: val_acc did not improve from 0.499\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0236 - val_loss: 0.0245\n",
      "Counter: 7, Global: 0.4989894162863493, MyBest: 0.4989894162863493\n",
      "\n",
      "Epoch 135: Updating Learning rate.. New value is 0.000000\n",
      "Epoch 136/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0236\n",
      "validate accuracy:\n",
      " [0.49874475 0.31169108 0.2832776  0.47369939 0.49056333 0.27550337\n",
      " 0.3111442  0.59690708 0.8319363  0.84178895 0.7818287  0.31246465\n",
      " 0.43658811 0.65114981 0.64036798 0.43477041 0.30623499] @epoch 135\n",
      "Epoch 136: val_acc did not improve from 0.499\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0236 - val_loss: 0.0245\n",
      "Counter: 0, Global: 0.4989894162863493, MyBest: 0.4989894162863493\n",
      "\n",
      "Epoch 137/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0236\n",
      "validate accuracy:\n",
      " [0.49876721 0.31126672 0.28093645 0.47398761 0.49013111 0.27651006\n",
      " 0.31178221 0.59994221 0.83067894 0.84234798 0.78153938 0.31260601\n",
      " 0.43546578 0.6508711  0.64106494 0.43505126 0.3060936 ] @epoch 136\n",
      "Epoch 137: val_acc did not improve from 0.499\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0236 - val_loss: 0.0245\n",
      "Counter: 1, Global: 0.4989894162863493, MyBest: 0.4989894162863493\n",
      "\n",
      "Epoch 138/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0236\n",
      "validate accuracy:\n",
      " [0.4984758  0.31232759 0.28177258 0.47341114 0.49041924 0.27667785\n",
      " 0.31071883 0.59835237 0.83053929 0.84262753 0.78197336 0.31218201\n",
      " 0.43406284 0.65073168 0.64148313 0.43266395 0.30566946] @epoch 137\n",
      "Epoch 138: val_acc did not improve from 0.499\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0236 - val_loss: 0.0245\n",
      "Counter: 2, Global: 0.4989894162863493, MyBest: 0.4989894162863493\n",
      "\n",
      "Epoch 139/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0236\n",
      "validate accuracy:\n",
      " [0.49868838 0.31126672 0.28026757 0.47384349 0.49229217 0.2760067\n",
      " 0.31156954 0.59762973 0.83137751 0.84164917 0.7818287  0.31274733\n",
      " 0.43546578 0.65212542 0.64078617 0.43462998 0.30552807] @epoch 138\n",
      "Epoch 139: val_acc did not improve from 0.499\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0236 - val_loss: 0.0245\n",
      "Counter: 3, Global: 0.4989894162863493, MyBest: 0.4989894162863493\n",
      "\n",
      "Epoch 140/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0236\n",
      "validate accuracy:\n",
      " [0.49906214 0.31211543 0.28093645 0.47413173 0.49330068 0.27583891\n",
      " 0.31305829 0.59835237 0.83012015 0.84234798 0.78168404 0.31373659\n",
      " 0.43504488 0.65212542 0.64245886 0.43336609 0.30637637] @epoch 139\n",
      "Epoch 140: val_acc improved from 0.499 to 0.499\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0236 - val_loss: 0.0244\n",
      "Counter: 4, Global: 0.4990621395409107, MyBest: 0.4989894162863493\n",
      "\n",
      "Epoch 141/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0236\n",
      "validate accuracy:\n",
      " [0.49866563 0.31105453 0.2832776  0.47240236 0.49113959 0.27651006\n",
      " 0.3109315  0.59762973 0.83123779 0.84178895 0.78081596 0.31302997\n",
      " 0.43574634 0.65073168 0.64106494 0.43462998 0.30665913] @epoch 140\n",
      "Epoch 141: val_acc did not improve from 0.499\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0236 - val_loss: 0.0245\n",
      "Counter: 0, Global: 0.4990621395409107, MyBest: 0.4990621395409107\n",
      "\n",
      "Epoch 142/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0236\n",
      "validate accuracy:\n",
      " [0.49853647 0.31041798 0.28093645 0.47254649 0.49099553 0.27667785\n",
      " 0.31008083 0.5986414  0.83095837 0.84248775 0.7818287  0.31401923\n",
      " 0.4347643  0.6508711  0.64134371 0.43505126 0.30496255] @epoch 141\n",
      "Epoch 142: val_acc did not improve from 0.499\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0236 - val_loss: 0.0245\n",
      "Counter: 1, Global: 0.4990621395409107, MyBest: 0.4990621395409107\n",
      "\n",
      "Epoch 143/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0236\n",
      "validate accuracy:\n",
      " [0.49849506 0.31232759 0.28076923 0.47341114 0.49013111 0.27550337\n",
      " 0.3111442  0.59748518 0.83165687 0.84178895 0.78168404 0.31218201\n",
      " 0.43658811 0.65101045 0.64148313 0.4329448  0.30581084] @epoch 142\n",
      "Epoch 143: val_acc did not improve from 0.499\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0236 - val_loss: 0.0245\n",
      "Counter: 2, Global: 0.4990621395409107, MyBest: 0.4990621395409107\n",
      "\n",
      "Epoch 144/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0236\n",
      "validate accuracy:\n",
      " [0.49865936 0.31169108 0.28361204 0.47254649 0.49171588 0.27500001\n",
      " 0.3109315  0.59762973 0.83081865 0.84136969 0.78110534 0.3131713\n",
      " 0.43602693 0.65114981 0.64190131 0.4339278  0.30595222] @epoch 143\n",
      "Epoch 144: val_acc did not improve from 0.499\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0236 - val_loss: 0.0245\n",
      "Counter: 3, Global: 0.4990621395409107, MyBest: 0.4990621395409107\n",
      "\n",
      "Epoch 145/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0236\n",
      "validate accuracy:\n",
      " [0.49836551 0.31169108 0.28093645 0.4718259  0.49056333 0.27533558\n",
      " 0.3102935  0.5971961  0.83012015 0.84150946 0.78197336 0.31288865\n",
      " 0.43602693 0.65101045 0.64273769 0.43378738 0.30595222] @epoch 144\n",
      "Epoch 145: val_acc did not improve from 0.499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0236 - val_loss: 0.0245\n",
      "Counter: 4, Global: 0.4990621395409107, MyBest: 0.4990621395409107\n",
      "\n",
      "Epoch 146/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0236\n",
      "validate accuracy:\n",
      " [0.4984534  0.31105453 0.28026757 0.47225824 0.48941076 0.27583891\n",
      " 0.31071883 0.59762973 0.83025986 0.84318656 0.78125    0.31302997\n",
      " 0.4364478  0.65240419 0.64218009 0.43350652 0.30581084] @epoch 145\n",
      "Epoch 146: val_acc did not improve from 0.499\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0236 - val_loss: 0.0245\n",
      "Counter: 5, Global: 0.4990621395409107, MyBest: 0.4990621395409107\n",
      "\n",
      "Epoch 147/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0236\n",
      "validate accuracy:\n",
      " [0.49819738 0.31105453 0.28043479 0.47153768 0.49185997 0.27550337\n",
      " 0.31050617 0.59849691 0.83025986 0.84095037 0.78081596 0.31189936\n",
      " 0.43574634 0.65114981 0.64120436 0.4339278  0.30581084] @epoch 146\n",
      "Epoch 147: val_acc did not improve from 0.499\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0236 - val_loss: 0.0245\n",
      "Counter: 6, Global: 0.4990621395409107, MyBest: 0.4990621395409107\n",
      "\n",
      "Epoch 148/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0236\n",
      "validate accuracy:\n",
      " [0.49884623 0.31105453 0.28143811 0.47441995 0.49171588 0.27567115\n",
      " 0.31156954 0.59921956 0.83053929 0.84262753 0.78255206 0.31359527\n",
      " 0.43462402 0.65184671 0.64092559 0.43364695 0.3060936 ] @epoch 147\n",
      "Epoch 148: val_acc did not improve from 0.499\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0236 - val_loss: 0.0245\n",
      "Counter: 7, Global: 0.4990621395409107, MyBest: 0.4990621395409107\n",
      "\n",
      "Epoch 148: Updating Learning rate.. New value is 0.000000\n",
      "Epoch 149/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0236\n",
      "validate accuracy:\n",
      " [0.49862846 0.31063017 0.28143811 0.47398761 0.49013111 0.27583891\n",
      " 0.31284559 0.59705162 0.83095837 0.84178895 0.78168404 0.31232333\n",
      " 0.43560606 0.65128922 0.6423195  0.4339278  0.30623499] @epoch 148\n",
      "Epoch 149: val_acc did not improve from 0.499\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0236 - val_loss: 0.0245\n",
      "Counter: 0, Global: 0.4990621395409107, MyBest: 0.4990621395409107\n",
      "\n",
      "Epoch 150/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0236\n",
      "validate accuracy:\n",
      " [0.49917801 0.31190324 0.28294313 0.47499639 0.49099553 0.27617449\n",
      " 0.31284559 0.5986414  0.83179659 0.84192872 0.78081596 0.31387791\n",
      " 0.43518519 0.65282232 0.64190131 0.43406826 0.30595222] @epoch 149\n",
      "Epoch 150: val_acc improved from 0.499 to 0.499\n",
      "576/576 [==============================] - 122s 213ms/step - loss: 0.0236 - val_loss: 0.0245\n",
      "Counter: 1, Global: 0.4991780146956444, MyBest: 0.4990621395409107\n",
      "\n",
      "Epoch 151/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0236\n",
      "validate accuracy:\n",
      " [0.49881775 0.30999362 0.28210703 0.4729788  0.4921481  0.27583891\n",
      " 0.31199491 0.5971961  0.83053929 0.84164917 0.78211808 0.31302997\n",
      " 0.4368687  0.65101045 0.6417619  0.43547255 0.30637637] @epoch 150\n",
      "Epoch 151: val_acc did not improve from 0.499\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0236 - val_loss: 0.0245\n"
     ]
    }
   ],
   "source": [
    "\n",
    "net.compile(optimizer=optimizer, loss=weighted_mse_loss, metrics=[])\n",
    "#checkpointer = ModelCheckpoint(filepath=f'../cunet{nUNet}_{m}{n}_best.h5', verbose=1, monitor='val_loss', mode='auto', save_best_only=True)\n",
    "history = net.fit(train_images,train_hms,validation_data=(eval_images,eval_hms2),epochs=151, batch_size=32,shuffle=True,verbose=1, callbacks=[evalcallback,updateLR])#,use_multiprocessing=True,workers=20)#[checkpointer,updateLR])\n",
    "#np.savez_compressed(\"../history\",history)\n",
    "net.save_weights(f'../cunet{nUNet}_{m}{n}_last_sigmoidAdamQuasiDef3sx12_restart.h5', overwrite=True)\n",
    "np.save('../history_sigmoidAdamQuasiDef3sx12_restart.npy',history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnet.load_weights(\"../cunet2_6416_last_sigmoidAdamQuasiDef3sx12.h5\")\\noutput = net.predict(train_images)\\noutput = np.transpose(output,(0,3,1,2))\\nprint(accuracy(output,np.transpose(train_hms,(0,3,1,2))))\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "net.load_weights(\"../cunet2_6416_last_sigmoidAdamQuasiDef3sx12.h5\")\n",
    "output = net.predict(train_images)\n",
    "output = np.transpose(output,(0,3,1,2))\n",
    "print(accuracy(output,np.transpose(train_hms,(0,3,1,2))))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ho aumentato solo patience \n",
    "#Provato con dropout ma andato male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
