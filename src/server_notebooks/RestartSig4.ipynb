{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setGPU: Setting GPU to: 0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import setGPU\n",
    "import gc\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "160\n",
      "240\n",
      "320\n",
      "96\n",
      "192\n",
      "288\n",
      "384\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 128, 128, 64) 9408        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 128, 128, 64) 256         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 128, 128, 64) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 64, 64, 64)   0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 64, 64)   256         max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 64, 64)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 64)   4096        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 64, 64, 64)   256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 64, 64, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 64, 64, 16)   9216        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 64, 64, 80)   0           max_pooling2d[0][0]              \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 64, 64, 80)   320         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 64, 64, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 64, 64)   5120        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 64)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 64)   256         max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 64)   4096        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 64)   256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 16)   9216        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 80)   0           max_pooling2d_1[0][0]            \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 80)   320         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 80)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 64)   5120        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 64)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 64)   256         max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 64)   4096        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 64)   256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 64)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 16)   9216        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 16, 16, 80)   0           max_pooling2d_2[0][0]            \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 80)   320         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 80)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 64)   5120        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 64)     0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 8, 8, 64)     256         max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 8, 8, 64)     0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 8, 8, 64)     4096        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 8, 8, 64)     256         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 8, 8, 64)     0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 8, 8, 16)     9216        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 8, 8, 80)     0           max_pooling2d_3[0][0]            \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 8, 8, 80)     320         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 8, 8, 80)     0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 8, 8, 64)     5120        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 4, 4, 64)     0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 4, 4, 64)     256         max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 4, 4, 64)     0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 4, 4, 64)     4096        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 4, 4, 64)     256         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 4, 4, 64)     0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 8, 8, 80)     320         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 4, 4, 16)     9216        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 8, 8, 80)     0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 4, 4, 80)     0           max_pooling2d_4[0][0]            \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 8, 8, 64)     5120        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 8, 8, 80)     0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 8, 8, 144)    0           conv2d_16[0][0]                  \n",
      "                                                                 up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 8, 8, 144)    576         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 8, 8, 144)    0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 8, 8, 64)     9216        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 8, 8, 64)     256         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 8, 8, 64)     0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 80)   320         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 8, 8, 16)     9216        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 80)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 8, 8, 160)    0           concatenate_5[0][0]              \n",
      "                                                                 conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 64)   5120        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 16, 16, 160)  0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 16, 16, 224)  0           conv2d_12[0][0]                  \n",
      "                                                                 up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 16, 224)  896         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 224)  0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 16, 16, 64)   14336       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 16, 64)   256         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 64)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 80)   320         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 16, 16, 16)   9216        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 80)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 16, 16, 240)  0           concatenate_7[0][0]              \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 64)   5120        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 32, 32, 240)  0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 32, 32, 304)  0           conv2d_8[0][0]                   \n",
      "                                                                 up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 32, 32, 304)  1216        concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 32, 32, 304)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 32, 32, 64)   19456       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 32, 32, 64)   256         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 32, 32, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 64, 64, 80)   320         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 32, 32, 16)   9216        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 64, 64, 80)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 32, 32, 320)  0           concatenate_9[0][0]              \n",
      "                                                                 conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 64)   5120        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 64, 64, 320)  0           concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 64, 64, 384)  0           conv2d_4[0][0]                   \n",
      "                                                                 up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 64, 64, 384)  1536        concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 64, 64, 384)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 64, 64, 64)   24576       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 64, 64, 64)   256         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 64, 64, 64)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 64, 64, 16)   9216        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 64, 64, 400)  0           concatenate_11[0][0]             \n",
      "                                                                 conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 64, 64, 464)  0           max_pooling2d[0][0]              \n",
      "                                                                 concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 64, 64, 464)  1856        concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 64, 64, 464)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 64, 64, 64)   29696       activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 64, 64, 80)   0           conv2d_31[0][0]                  \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 64, 64, 80)   320         concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 64, 64, 80)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 64, 64, 64)   5120        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 64, 64, 64)   256         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 64, 64, 64)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 64, 64, 16)   9216        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 64, 64, 96)   0           concatenate_14[0][0]             \n",
      "                                                                 conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 64, 64, 96)   384         concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 64, 64, 96)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 64, 64, 64)   6144        activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 32, 32, 64)   0           conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 32, 32, 80)   0           max_pooling2d_5[0][0]            \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 32, 32, 80)   320         concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 32, 32, 80)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 32, 32, 64)   5120        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 32, 32, 64)   256         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 32, 32, 64)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 32, 32, 16)   9216        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 32, 32, 96)   0           concatenate_16[0][0]             \n",
      "                                                                 conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 32, 32, 96)   384         concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 32, 32, 96)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 32, 32, 64)   6144        activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 16, 16, 64)   0           conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 16, 16, 80)   0           max_pooling2d_6[0][0]            \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 16, 16, 80)   320         concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 16, 16, 80)   0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 16, 16, 64)   5120        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 16, 16, 64)   256         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 16, 16, 64)   0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 16, 16, 16)   9216        activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 16, 16, 96)   0           concatenate_18[0][0]             \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 16, 16, 96)   384         concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 16, 16, 96)   0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 16, 16, 64)   6144        activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 8, 8, 64)     0           conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 8, 8, 80)     0           max_pooling2d_7[0][0]            \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 8, 8, 80)     320         concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 8, 8, 80)     0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 8, 8, 64)     5120        activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 8, 8, 64)     256         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 8, 8, 64)     0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 8, 8, 16)     9216        activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 8, 8, 96)     0           concatenate_20[0][0]             \n",
      "                                                                 conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 8, 8, 96)     384         concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 8, 8, 96)     0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 8, 8, 64)     6144        activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 4, 4, 64)     0           conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 4, 4, 80)     0           max_pooling2d_8[0][0]            \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 4, 4, 80)     320         concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 4, 4, 80)     0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 4, 4, 64)     5120        activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 4, 4, 64)     256         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 4, 4, 64)     0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 8, 8, 96)     384         concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 4, 4, 16)     9216        activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 8, 8, 96)     0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 4, 4, 96)     0           concatenate_22[0][0]             \n",
      "                                                                 conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 8, 8, 64)     6144        activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 8, 8, 96)     0           concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 8, 8, 176)    0           conv2d_47[0][0]                  \n",
      "                                                                 up_sampling2d_4[0][0]            \n",
      "                                                                 conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 8, 8, 176)    704         concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 8, 8, 176)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 8, 8, 64)     11264       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 8, 8, 64)     256         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 8, 8, 64)     0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 16, 16, 96)   384         concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 8, 8, 16)     9216        activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 16, 16, 96)   0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 8, 8, 192)    0           concatenate_24[0][0]             \n",
      "                                                                 conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 16, 16, 64)   6144        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 16, 16, 192)  0           concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 16, 16, 272)  0           conv2d_43[0][0]                  \n",
      "                                                                 up_sampling2d_5[0][0]            \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 16, 16, 272)  1088        concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 16, 16, 272)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 16, 16, 64)   17408       activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 16, 16, 64)   256         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 16, 16, 64)   0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 32, 32, 96)   384         concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 16, 16, 16)   9216        activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 32, 32, 96)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 16, 16, 288)  0           concatenate_26[0][0]             \n",
      "                                                                 conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 32, 32, 64)   6144        activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2D)  (None, 32, 32, 288)  0           concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 32, 32, 368)  0           conv2d_39[0][0]                  \n",
      "                                                                 up_sampling2d_6[0][0]            \n",
      "                                                                 conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 32, 32, 368)  1472        concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 32, 32, 368)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 32, 32, 64)   23552       activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 32, 32, 64)   256         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 32, 32, 64)   0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 64, 64, 96)   384         concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 32, 32, 16)   9216        activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 64, 64, 96)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 32, 32, 384)  0           concatenate_28[0][0]             \n",
      "                                                                 conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 64, 64, 64)   6144        activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2D)  (None, 64, 64, 384)  0           concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 64, 64, 464)  0           conv2d_35[0][0]                  \n",
      "                                                                 up_sampling2d_7[0][0]            \n",
      "                                                                 conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 64, 64, 464)  1856        concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 64, 64, 464)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 64, 64, 64)   29696       activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 64, 64, 64)   256         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 64, 64, 64)   0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 64, 64, 16)   9216        activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 64, 64, 480)  0           concatenate_30[0][0]             \n",
      "                                                                 conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 64, 64, 480)  1920        concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 64, 64, 480)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 64, 64, 16)   7680        activation_62[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 524,864\n",
      "Trainable params: 511,616\n",
      "Non-trainable params: 13,248\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Definizione Modello\n",
    "def getUnit1(layerPrec, filters, kernel_size = (1, 1), activation='relu', kernel_initializer='he_normal'):\n",
    "  l = BatchNormalization()(layerPrec)\n",
    "  l = Activation('relu')(l)\n",
    "  l = Conv2D(filters, kernel_size, kernel_initializer=kernel_initializer, padding='same',use_bias=False)(l)\n",
    "  return l\n",
    "\n",
    "def getUnit2(layerPrec, filters, kernel_size = (3, 3), activation='relu', kernel_initializer='he_normal'):\n",
    "  l = BatchNormalization()(layerPrec)\n",
    "  l = Activation('relu')(l)\n",
    "  l = Conv2D(filters, kernel_size, kernel_initializer=kernel_initializer, padding='same',use_bias=False)(l)\n",
    "  return l\n",
    "\n",
    "def getDownBlock(layerPrec,m,n,indexBlock):\n",
    "  l = getUnit1(layerPrec,4*n)\n",
    "  l = getUnit2(l,n)\n",
    "  nets[\"layers\"][f\"down{indexBlock}\"].append(l)\n",
    "\n",
    "  concat = Concatenate()([layerPrec,l])\n",
    "  l = getUnit1(concat,m)\n",
    "  maxPooling = MaxPool2D(padding='same')(l)\n",
    "  return maxPooling, getUnit1(concat,m)\n",
    "\n",
    "def getUpBlock(layerPrec,skipConn,m,n,indexBlock,upLayers=[]):\n",
    "  l = getUnit1(layerPrec,m)\n",
    "  l = UpSampling2D()(layerPrec)\n",
    "  concat = Concatenate()([skipConn,l]+upLayers)\n",
    "  l = getUnit1(concat,4*n)\n",
    "  l = getUnit2(l,n)\n",
    "  nets[\"layers\"][f\"up{indexBlock}\"].append(l)\n",
    "  concat = Concatenate()([concat,l])\n",
    "  return concat\n",
    "\n",
    "def getUNet(input,m,n,indexUNet,nUNet, nBlocks):\n",
    "  layerPrec = input\n",
    "  listSkipConn = []\n",
    "\n",
    "  if indexUNet != 0:\n",
    "    layerPrec = nets[f\"unet{indexUNet-1}\"]\n",
    "    #layerPrec = Concatenate()([input,layerPrec]) #l'abbiamo fatto giù con l'if dopo l'up\n",
    "    layerPrec = getUnit1(layerPrec,m)\n",
    "\n",
    "  # down\n",
    "  for i in range(nBlocks):\n",
    "    if nets[\"layers\"][f\"down{i}\"]:\n",
    "        layerPrec = Concatenate()([layerPrec]+nets[\"layers\"][f\"down{i}\"])\n",
    "    layerPrec, skipConn = getDownBlock(layerPrec,m,n,i)\n",
    "    listSkipConn.append(skipConn)\n",
    "\n",
    "  # bottle neck\n",
    "  if nets[\"layers\"][f\"bn\"]:\n",
    "      layerPrec = Concatenate()([layerPrec]+nets[\"layers\"][f\"bn\"])\n",
    "\n",
    "  l = getUnit1(layerPrec,4*n)\n",
    "  l = getUnit2(l,n)\n",
    "  nets[\"layers\"][\"bn\"].append(l)\n",
    "  concat = Concatenate()([layerPrec,l])\n",
    "\n",
    "  # up\n",
    "  layerPrec = concat\n",
    "  for i in range(nBlocks):\n",
    "    layerPrec = getUpBlock(layerPrec,listSkipConn[-(i+1)],m,n,i,upLayers=nets[\"layers\"][f\"up{i}\"])\n",
    "\n",
    "\n",
    "  if indexUNet != nUNet - 1:\n",
    "    l = Concatenate()([input,layerPrec])\n",
    "  else:\n",
    "    l = getUnit1(layerPrec,16,activation=\"sigmoid\") #era linear\n",
    "\n",
    "  return l\n",
    "\n",
    "def trasformationInput(x, filters):\n",
    "  #x = BatchNormalization()(x)\n",
    "  #x = Activation('relu')(x)\n",
    "  #x = Conv2D(filters, kernel_size=(7,7), strides=(2,2), kernel_initializer=\"he_normal\", padding='same',use_bias=False)(x)\n",
    "  #maxPooling = MaxPool2D(padding='same')(x)\n",
    "  \n",
    "  #x = Conv2D(filters*2, kernel_size=(5,5), strides=(1,1), kernel_initializer=\"he_normal\", padding='same',use_bias=False)(x)\n",
    "  #x = BatchNormalization()(x)\n",
    "  #x = Activation('relu')(x)\n",
    "  x = Conv2D(filters, kernel_size=(7,7), strides=(1,1), kernel_initializer=\"he_normal\", padding='same',use_bias=False)(x) #era 3x3\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = MaxPool2D(padding='same')(x)\n",
    "\n",
    "  return x#maxPooling\n",
    "\n",
    "def getCUNet(shape,m,n,nUNet,nBlocks):\n",
    "  for i in range(nUNet):\n",
    "    nets[f\"unet{i}\"] = None\n",
    "\n",
    "  for j in range(nBlocks):\n",
    "    nets[\"layers\"][f\"down{j}\"] = []\n",
    "    nets[\"layers\"][f\"up{j}\"] = []\n",
    "    \n",
    "  input = Input(shape=shape)\n",
    "  \n",
    "  t_input = trasformationInput(input,m) # per le heatmap da 64x64\n",
    "\n",
    "  for i in range(nUNet):\n",
    "    nets[f\"unet{i}\"] = getUNet(t_input,m,n,i,nUNet,nBlocks)\n",
    "\n",
    "  output = nets[f\"unet{nUNet-1}\"]\n",
    "  return Model(inputs=input, outputs=output)\n",
    "\n",
    "nets = {}\n",
    "nets[\"layers\"] = {}\n",
    "nets[\"layers\"][\"bn\"] = []\n",
    "shape = (128,128,3)\n",
    "m = 64\n",
    "n = 16\n",
    "nUNet = 2\n",
    "nBlocks = 4\n",
    "#mirrored_strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\n",
    "#with mirrored_strategy.scope():\n",
    "net = getCUNet(shape,m,n,nUNet,nBlocks)\n",
    "\n",
    "layers = net.layers\n",
    "#print(layers[57].input)\n",
    "for i in range(len(layers)):\n",
    "    if isinstance(layers[i], tf.python.keras.layers.convolutional.Conv2D):\n",
    "        if isinstance(layers[i-1].input,list):\n",
    "            in_chan = 0\n",
    "            for k in layers[i-1].input:\n",
    "                in_chan = in_chan + k.shape[-1]\n",
    "            print(in_chan)\n",
    "        else:\n",
    "            in_chan = layers[i-1].input.shape[-1]\n",
    "            \n",
    "        n1 = layers[i].kernel_size[0] * layers[i].kernel_size[1] * in_chan\n",
    "        stdv = 1/math.sqrt(n1)\n",
    "        layers[i].kernel_initializer = tf.keras.initializers.RandomUniform(minval=-stdv, maxval=stdv)\n",
    "\n",
    "net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_preds(heatmaps):\n",
    "    \"\"\"Get keypoint predictions from score maps.\n",
    "    Note:\n",
    "        batch_size: N\n",
    "        num_keypoints: K\n",
    "        heatmap height: H\n",
    "        heatmap width: W\n",
    "    Args:\n",
    "        heatmaps (np.ndarray[N, K, H, W]): model predicted heatmaps.\n",
    "    Returns:\n",
    "        tuple: A tuple containing aggregated results.\n",
    "        - preds (np.ndarray[N, K, 2]): Predicted keypoint location.  \n",
    "        - maxvals (np.ndarray[N, K, 1]): Scores (confidence) of the keypoints. non lo restituiamo\n",
    "    \"\"\"\n",
    "    #assert isinstance(heatmaps, np.ndarray), ('heatmaps should be numpy.ndarray')\n",
    "    #assert heatmaps.ndim == 4, 'batch_images should be 4-ndim'\n",
    "\n",
    "    N, K, _, W = heatmaps.shape\n",
    "    heatmaps_reshaped = heatmaps.reshape((N, K, -1))\n",
    "    idx = np.argmax(heatmaps_reshaped, 2).reshape((N, K, 1))\n",
    "    maxvals = np.amax(heatmaps_reshaped, 2).reshape((N, K, 1))\n",
    "\n",
    "    preds = np.tile(idx, (1, 1, 2)).astype(np.float32)\n",
    "    preds[:, :, 0] = preds[:, :, 0] % W\n",
    "    preds[:, :, 1] = preds[:, :, 1] // W\n",
    "\n",
    "    preds = np.where(np.tile(maxvals, (1, 1, 2)) > 0.0, preds, -1)\n",
    "    return preds#, maxvals\n",
    "\n",
    "def calc_dists(preds, target, normalize, use_zero=False):\n",
    "    preds = preds.astype(np.float32)\n",
    "    target = target.astype(np.float32)\n",
    "    normalize = normalize.astype(np.float32)\n",
    "    dists = np.zeros((preds.shape[1], preds.shape[0]))\n",
    "    if use_zero:\n",
    "        boundary = 0\n",
    "    else:\n",
    "        boundary = 1\n",
    "    for n in range(preds.shape[0]):\n",
    "        for c in range(preds.shape[1]):\n",
    "            if target[n,c,0] > boundary and target[n, c, 1] > boundary:\n",
    "                dists[c, n] = np.linalg.norm((preds[n,c,:]- target[n,c,:])/normalize[n]) # axis ricavato da solo\n",
    "            else:\n",
    "                dists[c, n] = -1\n",
    "    return dists\n",
    "\n",
    "def dist_acc(dists, thr=0.5):\n",
    "\n",
    "  #Return percentage below threshold while ignoring values with a -1\n",
    "\n",
    "  if (dists!=-1).sum() > 0:\n",
    "\n",
    "    return ((dists<=thr) == (dists!=-1)).sum().astype(np.float32) / (dists!=-1).sum().astype(np.float32)\n",
    "\n",
    "  else:\n",
    "\n",
    "    return -1\n",
    "\n",
    "def accuracy(output, target, thr=0.5):\n",
    "  ''' Calculate accuracy according to PCK, but uses ground truth heatmap rather than x,y locations\n",
    "        First value to be returned is average accuracy across 'idxs', followed by individual accuracies\n",
    "    '''\n",
    "  #output = output.numpy()\n",
    "  #print(output.__class__)\n",
    "  #target = target.numpy()\n",
    "\n",
    "  idkp = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "  preds = get_max_preds(output)\n",
    "  gts = get_max_preds(target)\n",
    "  norm = np.ones(preds.shape[0])*output.shape[3]/10\n",
    "\n",
    "  dists = calc_dists(preds, gts, norm)\n",
    "\n",
    "  acc = np.zeros(len(idkp)+1)\n",
    "  avg_acc = 0\n",
    "  cnt = 0\n",
    "\n",
    "  for i in range(len(idkp)):\n",
    "    acc[i+1] = dist_acc(dists[idkp[i]])\n",
    "    if acc[i+1] >= 0: \n",
    "      avg_acc = avg_acc + acc[i+1]\n",
    "      cnt += 1\n",
    "            \n",
    "  if cnt != 0:  \n",
    "    acc[0] = avg_acc / cnt\n",
    "\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.misc\n",
    "import cv2\n",
    "\n",
    "# =============================================================================\n",
    "# General image processing functions\n",
    "# =============================================================================\n",
    "\n",
    "def get_transform(center, scale, res, rot=0):\n",
    "    # Generate transformation matrix\n",
    "    h = 200 * scale\n",
    "    t = np.zeros((3, 3))\n",
    "    t[0, 0] = float(res[1]) / h\n",
    "    t[1, 1] = float(res[0]) / h\n",
    "    t[0, 2] = res[1] * (-float(center[0]) / h + .5)\n",
    "    t[1, 2] = res[0] * (-float(center[1]) / h + .5)\n",
    "    t[2, 2] = 1\n",
    "    if not rot == 0:\n",
    "        rot = -rot # To match direction of rotation from cropping\n",
    "        rot_mat = np.zeros((3,3))\n",
    "        rot_rad = rot * np.pi / 180\n",
    "        sn,cs = np.sin(rot_rad), np.cos(rot_rad)\n",
    "        rot_mat[0,:2] = [cs, -sn]\n",
    "        rot_mat[1,:2] = [sn, cs]\n",
    "        rot_mat[2,2] = 1\n",
    "        # Need to rotate around center\n",
    "        t_mat = np.eye(3)\n",
    "        t_mat[0,2] = -res[1]/2\n",
    "        t_mat[1,2] = -res[0]/2\n",
    "        t_inv = t_mat.copy()\n",
    "        t_inv[:2,2] *= -1\n",
    "        t = np.dot(t_inv,np.dot(rot_mat,np.dot(t_mat,t)))\n",
    "    return t\n",
    "\n",
    "def transform(pt, center, scale, res, invert=0, rot=0):\n",
    "    # Transform pixel location to different reference\n",
    "    t = get_transform(center, scale, res, rot=rot)\n",
    "    if invert:\n",
    "        t = np.linalg.inv(t)\n",
    "    new_pt = np.array([pt[0], pt[1], 1.]).T\n",
    "    new_pt = np.dot(t, new_pt)\n",
    "    return new_pt[:2].astype(int)\n",
    "\n",
    "def crop(img, center, scale, res, rot=0):\n",
    "    # Upper left point\n",
    "    ul = np.array(transform([0, 0], center, scale, res, invert=1))\n",
    "    # Bottom right point\n",
    "    br = np.array(transform(res, center, scale, res, invert=1))\n",
    "\n",
    "    new_shape = [br[1] - ul[1], br[0] - ul[0]]\n",
    "    if len(img.shape) > 2:\n",
    "        new_shape += [img.shape[2]]\n",
    "    new_img = np.zeros(new_shape)\n",
    "\n",
    "    # Range to fill new array\n",
    "    new_x = max(0, -ul[0]), min(br[0], len(img[0])) - ul[0]\n",
    "    new_y = max(0, -ul[1]), min(br[1], len(img)) - ul[1]\n",
    "    # Range to sample from original image\n",
    "    old_x = max(0, ul[0]), min(len(img[0]), br[0])\n",
    "    old_y = max(0, ul[1]), min(len(img), br[1])\n",
    "    new_img[new_y[0]:new_y[1], new_x[0]:new_x[1]] = img[old_y[0]:old_y[1], old_x[0]:old_x[1]]\n",
    "\n",
    "    return cv2.resize(new_img, res)\n",
    "\n",
    "def inv_mat(mat):\n",
    "    ans = np.linalg.pinv(np.array(mat).tolist() + [[0,0,1]])\n",
    "    return ans[:2]\n",
    "\n",
    "def kpt_affine(kpt, mat):\n",
    "    kpt = np.array(kpt)\n",
    "    shape = kpt.shape\n",
    "    kpt = kpt.reshape(-1, 2)\n",
    "    return np.dot( np.concatenate((kpt, kpt[:, 0:1]*0+1), axis = 1), mat.T ).reshape(shape)\n",
    "\n",
    "\n",
    "def resize(im, res):\n",
    "    return np.array([cv2.resize(im[i],res) for i in range(im.shape[0])])\n",
    "\n",
    "def generateHeatmap(keypoints,output_res,num_parts):\n",
    "    #Init\n",
    "    sigma = output_res/64\n",
    "    size = 6*sigma+3\n",
    "    x = np.arange(0, size, 1, float) #crea un array composto da nove 1.0 vettore 1-D (9,)\n",
    "    y = x[:, np.newaxis] #Vettore 2-D (9,1)\n",
    "    x0, y0 = 3*sigma + 1, 3*sigma + 1 #vedi giù a tutto\n",
    "    g = np.exp(- ((x - x0) ** 2 + (y - y0) ** 2) / (2 * sigma ** 2))\n",
    "    #Generation\n",
    "    hms = np.zeros(shape = (num_parts, output_res, output_res), dtype = np.float32) #crea vettore (16,64,64), cioè 16 heatmaps nere\n",
    "    for p in keypoints:\n",
    "        for idx, pt in enumerate(p): #ottiene id + [x,y] di ogni keypoint\n",
    "            if pt[0] > 0: \n",
    "                x, y = int(pt[0]), int(pt[1])\n",
    "                if x<0 or y<0 or x>=output_res or y>=output_res: #se succede questo, rimane heatmap idx-esima  tutta a 0\n",
    "                    continue\n",
    "                ul = int(x - 3*sigma - 1), int(y - 3*sigma - 1)\n",
    "                br = int(x + 3*sigma + 2), int(y + 3*sigma + 2)\n",
    "\n",
    "                c,d = max(0, -ul[0]), min(br[0], output_res) - ul[0]\n",
    "                a,b = max(0, -ul[1]), min(br[1], output_res) - ul[1]\n",
    "\n",
    "                cc,dd = max(0, ul[0]), min(br[0], output_res)\n",
    "                aa,bb = max(0, ul[1]), min(br[1], output_res)\n",
    "                hms[idx, aa:bb,cc:dd] = np.maximum(hms[idx, aa:bb,cc:dd], g[a:b,c:d])\n",
    "    return hms\n",
    "def getImgHms(img,c,s,keypoints,inp_res=(256,256),out_res=(64,64)):\n",
    "    cropped = crop(img,c,s,inp_res)\n",
    "    orig_keypoints = []\n",
    "    for i in keypoints:\n",
    "        orig_keypoints.append(np.array([i[\"x\"],i[\"y\"]]))\n",
    "    orig_keypoints = np.array(orig_keypoints).reshape((1,16,2))\n",
    "    kptmp = np.copy(orig_keypoints)\n",
    "    for i in range(orig_keypoints.shape[1]):\n",
    "        if orig_keypoints[0,i,0] > 0:\n",
    "            orig_keypoints[0,i,:2] = transform(orig_keypoints[0,i,:2], c, s, inp_res)\n",
    "    keypoints = np.copy(orig_keypoints)\n",
    "    h, w = cropped.shape[0:2]\n",
    "    center = np.array((w/2,h/2))\n",
    "    scale = max(h,w)/200\n",
    "    aug_rot = (np.random.random()*2-1)*30\n",
    "    aug_scale = np.random.random() * (1.25-0.75)+0.75\n",
    "    scale *= aug_scale\n",
    "\n",
    "    mat_mask = get_transform(center, scale, out_res, aug_rot)[:2]\n",
    "    mat = get_transform(center, scale, inp_res, aug_rot)[:2]\n",
    "    inp = cv2.warpAffine(cropped, mat, inp_res).astype(np.float32)/255\n",
    "\n",
    "    keypoints[:,:,0:2] = kpt_affine(keypoints[:,:,0:2], mat_mask) \n",
    "    \n",
    "    #print('\\n')\n",
    "\n",
    "\n",
    "    #Flip 50% probability\n",
    "    if np.random.randint(2) == 0:\n",
    "        inp = inp[:, ::-1]\n",
    "        keypoints = keypoints[:, flipped_parts['mpii']]\n",
    "        keypoints[:, :, 0] = 64 - keypoints[:, :, 0]\n",
    "        orig_keypoints = orig_keypoints[:, flipped_parts['mpii']]\n",
    "        orig_keypoints[:, :, 0] = 256 - orig_keypoints[:, :, 0]\n",
    "\n",
    "    ## set keypoints to 0 when were not visible initially (so heatmap all 0s)\n",
    "        for i in range(np.shape(orig_keypoints)[1]):\n",
    "            if kptmp[0,i,0] == 0 and kptmp[0,i,1] == 0:\n",
    "                keypoints[0,i,0] = 0\n",
    "                keypoints[0,i,1] = 0\n",
    "                orig_keypoints[0,i,0] = 0\n",
    "                orig_keypoints[0,i,1] = 0\n",
    "\n",
    "    heatmaps = generateHeatmap(keypoints,out_res[0],16)\n",
    "    return inp,heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.RMSprop(\n",
    "    learning_rate=2.5e-3, rho=0.99, momentum=0.0, epsilon=1e-08\n",
    ")\n",
    "#optimizer = tf.keras.optimizers.Adam(learning_rate=6.7e-3)\n",
    "\n",
    "\n",
    "def heatmapLoss(y_true,y_pred):\n",
    "    l = tf.math.square((y_pred - y_true))\n",
    "    l = tf.reduce_mean(l,axis=3)\n",
    "    l = tf.reduce_mean(l,axis=2)\n",
    "    l = tf.reduce_mean(l,axis=1)\n",
    "    return l\n",
    "\n",
    "def euclidean_loss(y_true, y_pred):\n",
    "    return K.sqrt(K.sum(K.square(y_true - y_pred)))\n",
    "\n",
    "def dice(y_true,y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + 1) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1 - dice(y_true, y_pred)\n",
    "\n",
    "def weighted_mse_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    apply weights on heatmap mse loss to only pick valid keypoint heatmap\n",
    "    since y_true would be gt_heatmap with shape\n",
    "    (batch_size, heatmap_size[0], heatmap_size[1], num_keypoints)\n",
    "    we sum up the heatmap for each keypoints and check. Sum for invalid\n",
    "    keypoint would be 0, so we can get a keypoint weights tensor with shape\n",
    "    (batch_size, 1, 1, num_keypoints)\n",
    "    and multiply to loss\n",
    "    \"\"\"\n",
    "    heatmap_sum = K.sum(K.sum(y_true, axis=1, keepdims=True), axis=2, keepdims=True)\n",
    "\n",
    "    # keypoint_weights shape: (batch_size, 1, 1, num_keypoints), with\n",
    "    # valid_keypoint = 1.0, invalid_keypoint = 0.0\n",
    "    keypoint_weights = 1.0 - K.cast(K.equal(heatmap_sum, 0.0), 'float32')\n",
    "\n",
    "    return K.sqrt(K.mean(K.square((y_true - y_pred) * keypoint_weights)))\n",
    "\n",
    "def smooth_l1_loss(y_true, y_pred):\n",
    "    diff = K.abs(y_true - y_pred)\n",
    "    less_than_one = K.cast(K.less(diff, 1.0), 'float32')\n",
    "    loss = (less_than_one * 0.5 * diff**2) + (1 - less_than_one) * (diff - 0.5)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "parts = {'mpii':['rank', 'rkne', 'rhip',\n",
    "                 'lhip', 'lkne', 'lank',\n",
    "                 'pelv', 'thrx', 'neck', 'head',\n",
    "                 'rwri', 'relb', 'rsho',\n",
    "                 'lsho', 'lelb', 'lwri']}\n",
    "\n",
    "flipped_parts = {'mpii':[5, 4, 3, 2, 1, 0, 6, 7, 8, 9, 15, 14, 13, 12, 11, 10]}\n",
    "\n",
    "part_pairs = {'mpii':[[0, 5], [1, 4], [2, 3], [6], [7], [8], [9], [10, 15], [11, 14], [12, 13]]}\n",
    "\n",
    "pair_names = {'mpii':['ankle', 'knee', 'hip', 'pelvis', 'thorax', 'neck', 'head', 'wrist', 'elbow', 'shoulder']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import imageio\n",
    "\n",
    "class Dataset(tf.keras.utils.Sequence):\n",
    "    #Costruttore\n",
    "    def __init__(self,json_path,batch_size,input_shape=(256,256,3),output_shape=(64,64,16),train=True,dataset_name=\"MPII\"):\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "        self.batch_size = batch_size\n",
    "        f = open(json_path)\n",
    "        self.dataset = json.load(f)\n",
    "        if dataset_name == \"MPII\":\n",
    "            self.dataset = self.dataset[\"dataset\"][\"MPII\"][\"people\"]\n",
    "        if train:\n",
    "            self.dataset = self.dataset[:-7221]\n",
    "        self.batch_images = np.zeros(shape=((self.batch_size,)+(self.input_shape)), dtype=np.float32)\n",
    "        self.batch_heatmaps = np.zeros(shape=((self.batch_size,)+(self.output_shape)), dtype=np.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset) // self.batch_size\n",
    "    \n",
    "    def __getitem__(self,i):\n",
    "        for n, annotation in enumerate(self.dataset[i*self.batch_size:(i+1)*self.batch_size]):\n",
    "            #sample_index = i*self.batch_size + n\n",
    "            image, gt_heatmap = self.extract_imgs_hms(annotation)\n",
    "            gt_heatmap = np.transpose(gt_heatmap,(1,2,0))\n",
    "            self.batch_images[n,:,:,:] = image\n",
    "            self.batch_heatmaps[n, :, :, :] = gt_heatmap#gt_heatmap.reshape((self.output_shape))\n",
    "            \n",
    "        return self.batch_images, self.batch_heatmaps\n",
    "#getImgHms(img,c,s,keypoints,inp_res=(256,256),out_res=(64,64)):\n",
    "    \n",
    "    def extract_imgs_hms(self,annotation):\n",
    "        inp_res = self.input_shape[0:2]\n",
    "        out_res = self.output_shape[0:2]\n",
    "        img = imageio.imread(f\"../images_mpii/{annotation['filepath']}\")\n",
    "        c = [annotation[\"objpos\"][\"x\"],annotation[\"objpos\"][\"y\"]]\n",
    "        s = annotation[\"scale\"]\n",
    "        keypoints = annotation[\"keypoints\"]\n",
    "        cropped = crop(img,c,s,inp_res)\n",
    "        \n",
    "        orig_keypoints = []\n",
    "        for i in keypoints:\n",
    "            orig_keypoints.append(np.array([i[\"x\"],i[\"y\"]]))\n",
    "        orig_keypoints = np.array(orig_keypoints).reshape((1,16,2))\n",
    "        kptmp = np.copy(orig_keypoints)\n",
    "        for i in range(orig_keypoints.shape[1]):\n",
    "            if orig_keypoints[0,i,0] > 0:\n",
    "                orig_keypoints[0,i,:2] = transform(orig_keypoints[0,i,:2], c, s, inp_res)\n",
    "        keypoints = np.copy(orig_keypoints)\n",
    "        h, w = cropped.shape[0:2]\n",
    "        center = np.array((w/2,h/2))\n",
    "        scale = max(h,w)/200\n",
    "        aug_rot = (np.random.random()*2-1)*30\n",
    "        aug_scale = np.random.random() * (1.25-0.75)+0.75\n",
    "        scale *= aug_scale\n",
    "\n",
    "        mat_mask = get_transform(center, scale, out_res, aug_rot)[:2]\n",
    "        mat = get_transform(center, scale, inp_res, aug_rot)[:2]\n",
    "        inp = cv2.warpAffine(cropped, mat, inp_res).astype(np.float32)/255\n",
    "\n",
    "        keypoints[:,:,0:2] = kpt_affine(keypoints[:,:,0:2], mat_mask) \n",
    "\n",
    "        #print('\\n')\n",
    "\n",
    "\n",
    "        #Flip 50% probability\n",
    "        if np.random.randint(2) == 0:\n",
    "            inp = inp[:, ::-1]\n",
    "            keypoints = keypoints[:, flipped_parts['mpii']]\n",
    "            keypoints[:, :, 0] = 64 - keypoints[:, :, 0]\n",
    "            orig_keypoints = orig_keypoints[:, flipped_parts['mpii']]\n",
    "            orig_keypoints[:, :, 0] = 256 - orig_keypoints[:, :, 0]\n",
    "\n",
    "        ## set keypoints to 0 when were not visible initially (so heatmap all 0s)\n",
    "            for i in range(np.shape(orig_keypoints)[1]):\n",
    "                if kptmp[0,i,0] == 0 and kptmp[0,i,1] == 0:\n",
    "                    keypoints[0,i,0] = 0\n",
    "                    keypoints[0,i,1] = 0\n",
    "                    orig_keypoints[0,i,0] = 0\n",
    "                    orig_keypoints[0,i,1] = 0\n",
    "\n",
    "        heatmaps = generateHeatmap(keypoints,out_res[0],16)\n",
    "        return inp,heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import imageio\n",
    "\n",
    "class Dataset2(tf.keras.utils.Sequence):\n",
    "    #Costruttore\n",
    "    def __init__(self,json_path,batch_size,input_shape=(256,256,3),output_shape=(64,64,16),train=True,dataset_name=\"MPII\"):\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "        self.batch_size = batch_size\n",
    "        self.images = np.load(\"../imgs_mpii.npz\")['arr_0']\n",
    "        self.hms = np.load(\"../hms_mpii.npz\")['arr_0']\n",
    "        self.hms = self.hms.reshape((self.hms.shape[0],64,64,16))\n",
    "        if dataset_name == \"MPII\":\n",
    "            self.images = self.images[\"dataset\"][\"MPII\"][\"people\"]\n",
    "        if train:\n",
    "            self.images = self.images[:-8665]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset) // self.batch_size\n",
    "    \n",
    "    def __getitem__(self,i):\n",
    "        return self.images[i*self.batch_size:(i+1)*self.batch_size], self.hms[i*self.batch_size:(i+1)*self.batch_size]\n",
    "#getImgHms(img,c,s,keypoints,inp_res=(256,256),out_res=(64,64)):\n",
    "    \n",
    "    def extract_imgs_hms(self,annotation):\n",
    "        inp_res = self.input_shape[0:2]\n",
    "        out_res = self.output_shape[0:2]\n",
    "        img = imageio.imread(f\"../images_mpii/{annotation['filepath']}\")\n",
    "        c = [annotation[\"objpos\"][\"x\"],annotation[\"objpos\"][\"y\"]]\n",
    "        s = annotation[\"scale\"]\n",
    "        keypoints = annotation[\"keypoints\"]\n",
    "        cropped = crop(img,c,s,inp_res)\n",
    "        \n",
    "        orig_keypoints = []\n",
    "        for i in keypoints:\n",
    "            orig_keypoints.append(np.array([i[\"x\"],i[\"y\"]]))\n",
    "        orig_keypoints = np.array(orig_keypoints).reshape((1,16,2))\n",
    "        kptmp = np.copy(orig_keypoints)\n",
    "        for i in range(orig_keypoints.shape[1]):\n",
    "            if orig_keypoints[0,i,0] > 0:\n",
    "                orig_keypoints[0,i,:2] = transform(orig_keypoints[0,i,:2], c, s, inp_res)\n",
    "        keypoints = np.copy(orig_keypoints)\n",
    "        h, w = cropped.shape[0:2]\n",
    "        center = np.array((w/2,h/2))\n",
    "        scale = max(h,w)/200\n",
    "        aug_rot = (np.random.random()*2-1)*30\n",
    "        aug_scale = np.random.random() * (1.25-0.75)+0.75\n",
    "        scale *= aug_scale\n",
    "\n",
    "        mat_mask = get_transform(center, scale, out_res, aug_rot)[:2]\n",
    "        mat = get_transform(center, scale, inp_res, aug_rot)[:2]\n",
    "        inp = cv2.warpAffine(cropped, mat, inp_res).astype(np.float32)/255\n",
    "\n",
    "        keypoints[:,:,0:2] = kpt_affine(keypoints[:,:,0:2], mat_mask) \n",
    "\n",
    "        #print('\\n')\n",
    "\n",
    "\n",
    "        #Flip 50% probability\n",
    "        if np.random.randint(2) == 0:\n",
    "            inp = inp[:, ::-1]\n",
    "            keypoints = keypoints[:, flipped_parts['mpii']]\n",
    "            keypoints[:, :, 0] = 64 - keypoints[:, :, 0]\n",
    "            orig_keypoints = orig_keypoints[:, flipped_parts['mpii']]\n",
    "            orig_keypoints[:, :, 0] = 256 - orig_keypoints[:, :, 0]\n",
    "\n",
    "        ## set keypoints to 0 when were not visible initially (so heatmap all 0s)\n",
    "            for i in range(np.shape(orig_keypoints)[1]):\n",
    "                if kptmp[0,i,0] == 0 and kptmp[0,i,1] == 0:\n",
    "                    keypoints[0,i,0] = 0\n",
    "                    keypoints[0,i,1] = 0\n",
    "                    orig_keypoints[0,i,0] = 0\n",
    "                    orig_keypoints[0,i,1] = 0\n",
    "\n",
    "        heatmaps = generateHeatmap(keypoints,out_res[0],16)\n",
    "        return inp,heatmaps\n",
    "####################################################################àà\n",
    "\n",
    "\n",
    "def get_normalize(input_shape):\n",
    "    \"\"\"\n",
    "    rescale keypoint distance normalize coefficient\n",
    "    based on input shape, used for PCK evaluation\n",
    "    NOTE: 6.4 is standard normalize coefficient under\n",
    "          input shape (256,256)\n",
    "    # Arguments\n",
    "        input_shape: input image shape as (height, width)\n",
    "    # Returns\n",
    "        scale: normalize coefficient\n",
    "    \"\"\"\n",
    "    #assert input_shape[0] == input_shape[1], 'only support square input shape.'\n",
    "\n",
    "    # use averaged scale factor for non square input shape\n",
    "    scale = float((input_shape[0] + input_shape[1]) / 2) / 256.0\n",
    "\n",
    "    return 6.4*scale\n",
    "\n",
    "global_best_acc = 0.0\n",
    "\n",
    "class EvalCallBack(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, model_input_shape, fileName, imgs,hms):\n",
    "        self.normalize = get_normalize(model_input_shape)\n",
    "        self.model_input_shape = model_input_shape\n",
    "        self.best_acc = 0.0\n",
    "        self.fileName = fileName\n",
    "        self.eval_images = imgs#np.load(\"../imgs_val_mpii128.npz\")['arr_0']\n",
    "        self.eval_hms = hms#np.load(\"../hms_val_mpii128.npz\")['arr_0']\n",
    "        self.listAcc = []\n",
    "        #self.eval_hms = np.reshape(self.eval_hms,(self.eval_hms.shape[0],64,64,16))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        global global_best_acc\n",
    "        output = self.model.predict(self.eval_images)\n",
    "        #output = output.reshape( (output.shape[0],)+(16,64,64) )\n",
    "        output = np.transpose(output,(0,3,1,2))\n",
    "        val_acc = accuracy(output,self.eval_hms)\n",
    "        self.listAcc.append(val_acc[0])\n",
    "        print('\\nvalidate accuracy:\\n', val_acc, '@epoch', epoch)\n",
    "        f = open(self.fileName, \"a\")\n",
    "        if val_acc[0] > self.best_acc:\n",
    "            # Save best accuray value and model checkpoint\n",
    "            #checkpoint_dir = os.path.join(self.log_dir, 'ep{epoch:03d}-loss{loss:.3f}-val_acc{val_acc:.3f}.h5'.format(epoch=(epoch+1), loss=logs.get('loss'), val_acc=val_acc))\n",
    "            #self.model.save(f\"../modelsave/ep{epoch}_acc{val_acc[0]}.h5\")\n",
    "            self.model.save_weights(f\"../cunet{nUNet}_{m}{n}_best_sigmoidAdamQuasiDef3sx12_restartsig4.h5\")\n",
    "            print('Epoch {epoch:03d}: val_acc improved from {best_acc:.3f} to {val_acc:.3f}'.format(epoch=epoch+1, best_acc=self.best_acc, val_acc=val_acc[0]))# checkpoint_dir=checkpoint_dir))\n",
    "            message = 'Epoch {epoch:03d}: val_acc improved from {best_acc:.3f} to {val_acc:.3f}. Train loss is {loss:.3f}\\n'.format(epoch=epoch+1, best_acc=self.best_acc, val_acc=val_acc[0],loss=logs.get('loss'))\n",
    "            self.best_acc = val_acc[0]\n",
    "            global_best_acc = val_acc[0]\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            message = 'Epoch {epoch:03d}: val_acc did not improve from {best_acc:.3f}. Train loss is {loss:.3f}\\n'.format(epoch=epoch+1, best_acc=self.best_acc,loss=logs.get('loss'))\n",
    "            print('Epoch {epoch:03d}: val_acc did not improve from {best_acc:.3f}'.format(epoch=epoch+1, best_acc=self.best_acc))\n",
    "        f.write(message)\n",
    "        f.close()\n",
    "        if epoch == 150:\n",
    "            np.savez_compressed(f'../cunet{nUNet}_{m}{n}_best_sigmoidAdamQuasiDef3sx12_restartsig4_accs', self.listAcc)\n",
    "        gc.collect()\n",
    "        \n",
    "        \n",
    "class CustomLearningRateScheduler(tf.keras.callbacks.Callback):\n",
    "    \"\"\"Learning rate scheduler which sets the learning rate according to schedule.\n",
    "\n",
    "  Arguments:\n",
    "      schedule: a function that takes an epoch index\n",
    "          (integer, indexed from 0) and current learning rate\n",
    "          as inputs and returns a new learning rate as output (float).\n",
    "  \"\"\"\n",
    "\n",
    "    def __init__(self, patience,factor,fileName=None):\n",
    "        super(CustomLearningRateScheduler, self).__init__()\n",
    "        self.counter = 0\n",
    "        self.patience = patience\n",
    "        self.fileName = fileName\n",
    "        self.factor = factor\n",
    "        self.best_acc = 0.0\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        global global_best_acc\n",
    "        print(f\"Counter: {self.counter}, Global: {global_best_acc}, MyBest: {self.best_acc}\\n\")\n",
    "        if not hasattr(self.model.optimizer, \"lr\"):\n",
    "            raise ValueError('Optimizer must have a \"lr\" attribute.')\n",
    "        # Get the current learning rate from model's optimizer.\n",
    "        lr = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n",
    "        # Call schedule function to get the scheduled learning rate.\n",
    "        scheduled_lr = self.schedule(epoch, lr)\n",
    "        # Set the value back to the optimizer before this epoch starts\n",
    "        tf.keras.backend.set_value(self.model.optimizer.lr, scheduled_lr)\n",
    "    \n",
    "    def schedule(self,epoch,lr):\n",
    "        global global_best_acc\n",
    "        if self.counter == self.patience:\n",
    "            self.counter = 0 \n",
    "            print(\"Epoch %03d: Updating Learning rate.. New value is %f\" % (epoch, lr*self.factor))\n",
    "            message = \"Epoch %03d: Updating Learning rate.. New value is %f\" % (epoch, lr*self.factor)\n",
    "            f = open(self.fileName, \"a\")\n",
    "            f.write(message)\n",
    "            f.close()\n",
    "            return lr*self.factor\n",
    "        if self.best_acc == global_best_acc:\n",
    "            self.counter = self.counter + 1\n",
    "        elif self.best_acc < global_best_acc:\n",
    "            self.counter = 0\n",
    "            self.best_acc = global_best_acc\n",
    "        return lr\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finito 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ndataset = Dataset(\"datasets.json\",32)\\n\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle \n",
    "with open('../train_imgssx12.pickle', 'rb') as handle:\n",
    "    train_images = pickle.load(handle)\n",
    "with open('../train_hmssx12.pickle', 'rb') as handle:\n",
    "    train_hms = pickle.load(handle)\n",
    "\n",
    "eval_images = np.load(\"../imgs_val_mpii128sx12.npz\")['arr_0']\n",
    "eval_hms = np.load(\"../hms_val_mpii128sx12.npz\")['arr_0']\n",
    "\n",
    "#train_images = np.load(\"../imgs_train_mpii128.npz\")['arr_0']\n",
    "#train_hms = np.load(\"../hms_train_mpii128.npz\")['arr_0']\n",
    "train_hms = np.transpose(train_hms,(0,2,3,1))#np.reshape(train_hms,(train_hms.shape[0],64,64,16))\n",
    "eval_hms2 = np.transpose(eval_hms,(0,2,3,1))\n",
    "print(\"Finito 1\")\n",
    "\"\"\"\n",
    "dataset = Dataset(\"datasets.json\",32)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finito 2\n"
     ]
    }
   ],
   "source": [
    "evalcallback = EvalCallBack((128,128),\"../sigmoidLayersAdamSchedulingQuasiDef3sx12_restartsig4.txt\",eval_images,eval_hms)\n",
    "updateLR = CustomLearningRateScheduler(7,0.6,fileName=\"../sigmoidLayersAdamSchedulingQuasiDef3sx12_restartsig4.txt\")\n",
    "print(\"Finito 2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter: 0, Global: 0.0, MyBest: 0.0\n",
      "\n",
      "Epoch 1/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0954WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0070s vs `on_test_batch_end` time: 0.0370s). Check your callbacks.\n",
      "\n",
      "validate accuracy:\n",
      " [0.03633692 0.01697433 0.01187291 0.04539559 0.05359458 0.03624161\n",
      " 0.00063803 0.         0.06482258 0.04947589 0.06481481 0.022329\n",
      " 0.0051908  0.05519164 0.06899916 0.05799747 0.0278524 ] @epoch 0\n",
      "Epoch 001: val_acc improved from 0.000 to 0.036\n",
      "576/576 [==============================] - 125s 217ms/step - loss: 0.0954 - val_loss: 0.0293\n",
      "Counter: 1, Global: 0.036336924247734714, MyBest: 0.0\n",
      "\n",
      "Epoch 2/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0400\n",
      "validate accuracy:\n",
      " [0.06673929 0.02758328 0.03979933 0.13849258 0.07001873 0.0385906\n",
      " 0.00574224 0.09640121 0.17770328 0.21495457 0.01273148 0.04338609\n",
      " 0.04054433 0.00529617 0.13925286 0.00856621 0.00876573] @epoch 1\n",
      "Epoch 002: val_acc improved from 0.036 to 0.067\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0400 - val_loss: 0.0448\n",
      "Counter: 0, Global: 0.06673929386306554, MyBest: 0.036336924247734714\n",
      "\n",
      "Epoch 3/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0310\n",
      "validate accuracy:\n",
      " [0.07391859 0.0182474  0.01053512 0.19729067 0.22316669 0.01459732\n",
      " 0.00467886 0.12386183 0.24783459 0.14269741 0.04427083 0.02430752\n",
      " 0.07547699 0.01310105 0.00947867 0.01067266 0.02247985] @epoch 2\n",
      "Epoch 003: val_acc improved from 0.067 to 0.074\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0310 - val_loss: 0.0461\n",
      "Counter: 0, Global: 0.07391859099152498, MyBest: 0.06673929386306554\n",
      "\n",
      "Epoch 4/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0269\n",
      "validate accuracy:\n",
      " [0.31003558 0.13197538 0.12056856 0.31949848 0.28367671 0.1147651\n",
      " 0.11229264 0.41277641 0.62908632 0.64178896 0.52907985 0.20661391\n",
      " 0.23302469 0.40376306 0.40270421 0.2235641  0.19539092] @epoch 3\n",
      "Epoch 004: val_acc improved from 0.074 to 0.310\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0269 - val_loss: 0.0260\n",
      "Counter: 0, Global: 0.3100355817005038, MyBest: 0.07391859099152498\n",
      "\n",
      "Epoch 5/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0259\n",
      "validate accuracy:\n",
      " [0.33861281 0.15786123 0.18645485 0.32310131 0.30860105 0.18808725\n",
      " 0.14759676 0.40988582 0.67407095 0.68930817 0.58246529 0.20633127\n",
      " 0.26585299 0.423554   0.43615836 0.23170903 0.18676658] @epoch 4\n",
      "Epoch 005: val_acc improved from 0.310 to 0.339\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0259 - val_loss: 0.0258\n",
      "Counter: 0, Global: 0.3386128079146147, MyBest: 0.3100355817005038\n",
      "\n",
      "Epoch 6/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0253\n",
      "validate accuracy:\n",
      " [0.25555123 0.119669   0.11956522 0.1841764  0.20746291 0.09161074\n",
      " 0.08655891 0.21650527 0.55490363 0.56911248 0.49985531 0.19587338\n",
      " 0.2243266  0.30578396 0.35545024 0.16893695 0.1890287 ] @epoch 5\n",
      "Epoch 006: val_acc did not improve from 0.339\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0253 - val_loss: 0.0315\n",
      "Counter: 0, Global: 0.3386128079146147, MyBest: 0.3386128079146147\n",
      "\n",
      "Epoch 7/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0248\n",
      "validate accuracy:\n",
      " [0.43288587 0.287927   0.24515051 0.40394869 0.42328194 0.24060403\n",
      " 0.27201191 0.54155225 0.79184127 0.78001398 0.71006942 0.26681742\n",
      " 0.32912457 0.51512194 0.52076942 0.32860553 0.26933408] @epoch 6\n",
      "Epoch 007: val_acc improved from 0.339 to 0.433\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0248 - val_loss: 0.0250\n",
      "Counter: 1, Global: 0.43288587126880884, MyBest: 0.3386128079146147\n",
      "\n",
      "Epoch 8/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0245\n",
      "validate accuracy:\n",
      " [0.46049361 0.28495651 0.25953177 0.42426863 0.44345194 0.26543623\n",
      " 0.29051468 0.55152476 0.80902487 0.8177498  0.75260419 0.28688523\n",
      " 0.36560044 0.58132404 0.59199888 0.35163599 0.29138979] @epoch 7\n",
      "Epoch 008: val_acc improved from 0.433 to 0.460\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0245 - val_loss: 0.0247\n",
      "Counter: 0, Global: 0.46049360930919647, MyBest: 0.43288587126880884\n",
      "\n",
      "Epoch 9/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0243\n",
      "validate accuracy:\n",
      " [0.38080304 0.24824952 0.22591974 0.34644762 0.32733035 0.22751679\n",
      " 0.25818801 0.48518571 0.7524448  0.75485677 0.68706596 0.26229507\n",
      " 0.26332772 0.33031359 0.40563145 0.26358658 0.25448892] @epoch 8\n",
      "Epoch 009: val_acc did not improve from 0.460\n",
      "576/576 [==============================] - 122s 213ms/step - loss: 0.0243 - val_loss: 0.0253\n",
      "Counter: 0, Global: 0.46049360930919647, MyBest: 0.46049360930919647\n",
      "\n",
      "Epoch 10/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0240\n",
      "validate accuracy:\n",
      " [0.49411816 0.29174623 0.28294313 0.47931978 0.47687653 0.28238255\n",
      " 0.30051041 0.59271568 0.83053929 0.83647799 0.78168404 0.32221594\n",
      " 0.40151516 0.64167249 0.63102871 0.4187614  0.33550119] @epoch 9\n",
      "Epoch 010: val_acc improved from 0.460 to 0.494\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0240 - val_loss: 0.0245\n",
      "Counter: 1, Global: 0.49411815777421, MyBest: 0.46049360930919647\n",
      "\n",
      "Epoch 11/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0238\n",
      "validate accuracy:\n",
      " [0.5257065  0.32272437 0.28812709 0.52356249 0.52168274 0.31577182\n",
      " 0.31816247 0.62537938 0.850936   0.86443049 0.81235534 0.35754663\n",
      " 0.45159933 0.68222994 0.67925841 0.43785986 0.35967764] @epoch 10\n",
      "Epoch 011: val_acc improved from 0.494 to 0.526\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0238 - val_loss: 0.0242\n",
      "Counter: 0, Global: 0.5257064998149872, MyBest: 0.49411815777421\n",
      "\n",
      "Epoch 12/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0237\n",
      "validate accuracy:\n",
      " [0.49573554 0.30341607 0.2923077  0.48277849 0.49762282 0.29161075\n",
      " 0.29880902 0.5986414  0.83012015 0.84220827 0.7902199  0.29409271\n",
      " 0.40642536 0.63637632 0.6495679  0.40865046 0.30892125] @epoch 11\n",
      "Epoch 012: val_acc did not improve from 0.526\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0237 - val_loss: 0.0244\n",
      "Counter: 0, Global: 0.5257064998149872, MyBest: 0.5257064998149872\n",
      "\n",
      "Epoch 13/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0235\n",
      "validate accuracy:\n",
      " [0.49764991 0.28707829 0.27909699 0.49891916 0.51159775 0.28976509\n",
      " 0.28966397 0.58881342 0.82271582 0.82697415 0.78993058 0.31726965\n",
      " 0.42873177 0.6526829  0.6417619  0.42479989 0.31259722] @epoch 12\n",
      "Epoch 013: val_acc did not improve from 0.526\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0235 - val_loss: 0.0244\n",
      "Counter: 1, Global: 0.5257064998149872, MyBest: 0.5257064998149872\n",
      "\n",
      "Epoch 14/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0234\n",
      "validate accuracy:\n",
      " [0.5283105  0.32378528 0.30384615 0.51145697 0.52542859 0.3112416\n",
      " 0.29221609 0.6318832  0.85820061 0.86498952 0.82175928 0.36433014\n",
      " 0.46913579 0.67275262 0.66810703 0.46426064 0.36957443] @epoch 13\n",
      "Epoch 014: val_acc improved from 0.526 to 0.528\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0234 - val_loss: 0.0242\n",
      "Counter: 2, Global: 0.5283104963600636, MyBest: 0.5257064998149872\n",
      "\n",
      "Epoch 15/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0233\n",
      "validate accuracy:\n",
      " [0.53968964 0.32718015 0.31337792 0.5469088  0.54372567 0.33473155\n",
      " 0.31880051 0.62826997 0.86448729 0.87113905 0.82609951 0.37422273\n",
      " 0.46843433 0.69811845 0.69500977 0.46060947 0.36391914] @epoch 14\n",
      "Epoch 015: val_acc improved from 0.528 to 0.540\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0233 - val_loss: 0.0240\n",
      "Counter: 0, Global: 0.5396896433085203, MyBest: 0.5283104963600636\n",
      "\n",
      "Epoch 16/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0232\n",
      "validate accuracy:\n",
      " [0.54336756 0.31063017 0.30250835 0.55224097 0.55438697 0.32667786\n",
      " 0.32943428 0.63824254 0.86434758 0.86946189 0.81741899 0.38001695\n",
      " 0.47825477 0.70480835 0.69919151 0.47802275 0.38823697] @epoch 15\n",
      "Epoch 016: val_acc improved from 0.540 to 0.543\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0232 - val_loss: 0.0240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter: 0, Global: 0.5433675572276115, MyBest: 0.5396896433085203\n",
      "\n",
      "Epoch 17/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0230\n",
      "validate accuracy:\n",
      " [0.55490774 0.34521535 0.3110368  0.56852573 0.57052296 0.33338925\n",
      " 0.32347938 0.65385169 0.87887681 0.88273937 0.83608216 0.38072357\n",
      " 0.50266552 0.71874565 0.70880961 0.47746104 0.38639897] @epoch 16\n",
      "Epoch 017: val_acc improved from 0.543 to 0.555\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0230 - val_loss: 0.0238\n",
      "Counter: 0, Global: 0.5549077410250902, MyBest: 0.5433675572276115\n",
      "\n",
      "Epoch 18/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0229\n",
      "validate accuracy:\n",
      " [0.55858746 0.34754932 0.32324415 0.55036747 0.56821781 0.34731543\n",
      " 0.32879627 0.66006649 0.87161219 0.87658978 0.83622688 0.39400792\n",
      " 0.5138889  0.71177703 0.70699751 0.50105321 0.39968896] @epoch 17\n",
      "Epoch 018: val_acc improved from 0.555 to 0.559\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0229 - val_loss: 0.0239\n",
      "Counter: 0, Global: 0.5585874579846859, MyBest: 0.5549077410250902\n",
      "\n",
      "Epoch 19/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0229\n",
      "validate accuracy:\n",
      " [0.54586467 0.33672819 0.32709029 0.52860641 0.54098833 0.32651007\n",
      " 0.33028498 0.61829746 0.85945797 0.8701607  0.83000576 0.3834087\n",
      " 0.49396744 0.7154007  0.70393085 0.49136358 0.37763324] @epoch 18\n",
      "Epoch 019: val_acc did not improve from 0.559\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0229 - val_loss: 0.0240\n",
      "Counter: 0, Global: 0.5585874579846859, MyBest: 0.5585874579846859\n",
      "\n",
      "Epoch 20/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0227\n",
      "validate accuracy:\n",
      " [0.55340853 0.34203267 0.32541806 0.56578755 0.56605679 0.3432886\n",
      " 0.32900894 0.6509611  0.85792118 0.86596787 0.82971644 0.3894856\n",
      " 0.50911897 0.70592332 0.69919151 0.49052098 0.38413686] @epoch 19\n",
      "Epoch 020: val_acc did not improve from 0.559\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0227 - val_loss: 0.0239\n",
      "Counter: 1, Global: 0.5585874579846859, MyBest: 0.5585874579846859\n",
      "\n",
      "Epoch 21/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0227\n",
      "validate accuracy:\n",
      " [0.5611809  0.32866541 0.34749165 0.5618965  0.57902318 0.35939598\n",
      " 0.33092302 0.65645325 0.86714166 0.87519217 0.83521414 0.39909554\n",
      " 0.50996071 0.72627175 0.71187621 0.49908721 0.391206  ] @epoch 20\n",
      "Epoch 021: val_acc improved from 0.559 to 0.561\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0227 - val_loss: 0.0238\n",
      "Counter: 2, Global: 0.5611808989197016, MyBest: 0.5585874579846859\n",
      "\n",
      "Epoch 22/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0226\n",
      "validate accuracy:\n",
      " [0.5661464  0.33672819 0.32892975 0.57400203 0.58507419 0.34748322\n",
      " 0.3430455  0.65500796 0.87580329 0.88707197 0.84461808 0.39485586\n",
      " 0.52861953 0.72571427 0.7177307  0.51453447 0.39912343] @epoch 21\n",
      "Epoch 022: val_acc improved from 0.561 to 0.566\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0226 - val_loss: 0.0238\n",
      "Counter: 0, Global: 0.5661464016884565, MyBest: 0.5611808989197016\n",
      "\n",
      "Epoch 23/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0225\n",
      "validate accuracy:\n",
      " [0.56917717 0.34245703 0.3555184  0.57429022 0.56303126 0.36224833\n",
      " 0.33645257 0.65399623 0.8836267  0.8859539  0.8498264  0.41704354\n",
      " 0.5151515  0.72362369 0.71494287 0.51046199 0.41821009] @epoch 22\n",
      "Epoch 023: val_acc improved from 0.566 to 0.569\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0225 - val_loss: 0.0237\n",
      "Counter: 0, Global: 0.5691771693527699, MyBest: 0.5661464016884565\n",
      "\n",
      "Epoch 24/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0224\n",
      "validate accuracy:\n",
      " [0.56842619 0.34033525 0.35819399 0.5660758  0.57426882 0.37197986\n",
      " 0.33390048 0.65992194 0.87831795 0.88301885 0.8420139  0.40517241\n",
      " 0.51879913 0.73003483 0.72302759 0.50582784 0.40393043] @epoch 23\n",
      "Epoch 024: val_acc did not improve from 0.569\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0224 - val_loss: 0.0238\n",
      "Counter: 0, Global: 0.5691771693527699, MyBest: 0.5691771693527699\n",
      "\n",
      "Epoch 25/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0223\n",
      "validate accuracy:\n",
      " [0.56122377 0.34351793 0.35919732 0.56866986 0.57484514 0.36241612\n",
      " 0.3249681  0.66281253 0.86714166 0.87044024 0.8365162  0.3951385\n",
      " 0.51711559 0.70912892 0.69640368 0.50119364 0.39007494] @epoch 24\n",
      "Epoch 025: val_acc did not improve from 0.569\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0223 - val_loss: 0.0239\n",
      "Counter: 1, Global: 0.5691771693527699, MyBest: 0.5691771693527699\n",
      "\n",
      "Epoch 26/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0222\n",
      "validate accuracy:\n",
      " [0.56605122 0.34563971 0.3486622  0.5793342  0.57109928 0.35486576\n",
      " 0.32241601 0.66700393 0.87370771 0.87924528 0.83506942 0.40672696\n",
      " 0.51360828 0.70926827 0.71759129 0.51776433 0.41481692] @epoch 25\n",
      "Epoch 026: val_acc did not improve from 0.569\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0222 - val_loss: 0.0239\n",
      "Counter: 2, Global: 0.5691771693527699, MyBest: 0.5691771693527699\n",
      "\n",
      "Epoch 27/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0222\n",
      "validate accuracy:\n",
      " [0.57728695 0.34670061 0.36923078 0.58971035 0.57887912 0.3763423\n",
      " 0.34198213 0.67047262 0.88111204 0.88455623 0.84852433 0.41944602\n",
      " 0.53338945 0.72222996 0.72525787 0.52998173 0.41877562] @epoch 26\n",
      "Epoch 027: val_acc improved from 0.569 to 0.577\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0222 - val_loss: 0.0238\n",
      "Counter: 3, Global: 0.5772869475185871, MyBest: 0.5691771693527699\n",
      "\n",
      "Epoch 28/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0221\n",
      "validate accuracy:\n",
      " [0.478538   0.32208785 0.31254181 0.46317914 0.45468953 0.34530202\n",
      " 0.31348363 0.62566847 0.83822298 0.84598184 0.80859375 0.31797627\n",
      " 0.34736252 0.49881533 0.48522443 0.35823619 0.31924218] @epoch 27\n",
      "Epoch 028: val_acc did not improve from 0.577\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0221 - val_loss: 0.0247\n",
      "Counter: 0, Global: 0.5772869475185871, MyBest: 0.5772869475185871\n",
      "\n",
      "Epoch 29/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0220\n",
      "validate accuracy:\n",
      " [0.55718709 0.33609167 0.35301003 0.54993516 0.54905635 0.35067114\n",
      " 0.32475543 0.64373463 0.86560494 0.87379456 0.83637154 0.39570379\n",
      " 0.51024133 0.70578396 0.70839143 0.51046199 0.40138555] @epoch 28\n",
      "Epoch 029: val_acc did not improve from 0.577\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0220 - val_loss: 0.0242\n",
      "Counter: 1, Global: 0.5772869475185871, MyBest: 0.5772869475185871\n",
      "\n",
      "Epoch 30/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0220\n",
      "validate accuracy:\n",
      " [0.55084058 0.3276045  0.35451505 0.52831823 0.52614897 0.36057046\n",
      " 0.33071032 0.61714119 0.86420786 0.87183785 0.83998841 0.39245337\n",
      " 0.50799662 0.70285714 0.69807637 0.4957169  0.39530608] @epoch 29\n",
      "Epoch 030: val_acc did not improve from 0.577\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0220 - val_loss: 0.0240\n",
      "Counter: 2, Global: 0.5772869475185871, MyBest: 0.5772869475185871\n",
      "\n",
      "Epoch 31/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0219\n",
      "validate accuracy:\n",
      " [0.57717507 0.35879481 0.37207359 0.57126385 0.57153147 0.3692953\n",
      " 0.33411315 0.65370721 0.87594301 0.88553458 0.84375    0.42736009\n",
      " 0.54433221 0.72822303 0.73501533 0.53321165 0.43065178] @epoch 30\n",
      "Epoch 031: val_acc did not improve from 0.577\n",
      "576/576 [==============================] - 122s 213ms/step - loss: 0.0219 - val_loss: 0.0238\n",
      "Counter: 3, Global: 0.5772869475185871, MyBest: 0.5772869475185871\n",
      "\n",
      "Epoch 32/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0218\n",
      "validate accuracy:\n",
      " [0.58304374 0.35964355 0.3702341  0.58826917 0.59443885 0.38573825\n",
      " 0.33517653 0.67972249 0.88432521 0.88791054 0.84664351 0.42425099\n",
      " 0.54503369 0.73379791 0.74310011 0.53573936 0.41467553] @epoch 31\n",
      "Epoch 032: val_acc improved from 0.577 to 0.583\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0218 - val_loss: 0.0238\n",
      "Counter: 4, Global: 0.5830437373369932, MyBest: 0.5772869475185871\n",
      "\n",
      "Epoch 33/151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - ETA: 0s - loss: 0.0218\n",
      "validate accuracy:\n",
      " [0.56721947 0.34776151 0.35969901 0.57688427 0.57340443 0.37684563\n",
      " 0.31646109 0.65442985 0.86797988 0.87099928 0.83868635 0.40559638\n",
      " 0.53002244 0.71860629 0.7189852  0.51776433 0.40138555] @epoch 32\n",
      "Epoch 033: val_acc did not improve from 0.583\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0218 - val_loss: 0.0240\n",
      "Counter: 0, Global: 0.5830437373369932, MyBest: 0.5830437373369932\n",
      "\n",
      "Epoch 34/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0217\n",
      "validate accuracy:\n",
      " [0.57690836 0.35582432 0.37207359 0.562473   0.55582768 0.38137585\n",
      " 0.33113569 0.6401214  0.88418555 0.88972747 0.85315394 0.42227247\n",
      " 0.53507292 0.74578398 0.73836076 0.53489679 0.42824826] @epoch 33\n",
      "Epoch 034: val_acc did not improve from 0.583\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0217 - val_loss: 0.0238\n",
      "Counter: 1, Global: 0.5830437373369932, MyBest: 0.5830437373369932\n",
      "\n",
      "Epoch 35/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0217\n",
      "validate accuracy:\n",
      " [0.57517858 0.34903458 0.37424749 0.57256091 0.57513326 0.38255033\n",
      " 0.32305402 0.65558606 0.87664151 0.88287908 0.85069442 0.42015263\n",
      " 0.53689677 0.73254353 0.73027599 0.52267939 0.41792732] @epoch 34\n",
      "Epoch 035: val_acc did not improve from 0.583\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0217 - val_loss: 0.0239\n",
      "Counter: 2, Global: 0.5830437373369932, MyBest: 0.5830437373369932\n",
      "\n",
      "Epoch 36/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0216\n",
      "validate accuracy:\n",
      " [0.57942852 0.35837045 0.3819398  0.57717252 0.57599771 0.39194632\n",
      " 0.33304977 0.66526955 0.87859738 0.88120198 0.84780091 0.42396834\n",
      " 0.53731763 0.73867595 0.73571229 0.52604973 0.41778594] @epoch 35\n",
      "Epoch 036: val_acc did not improve from 0.583\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0216 - val_loss: 0.0238\n",
      "Counter: 3, Global: 0.5830437373369932, MyBest: 0.5830437373369932\n",
      "\n",
      "Epoch 37/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0216\n",
      "validate accuracy:\n",
      " [0.57310637 0.34945893 0.36755854 0.56362587 0.55625993 0.37785235\n",
      " 0.3215653  0.63578552 0.87999439 0.88874912 0.8527199  0.42750141\n",
      " 0.52777779 0.73463416 0.73417896 0.52548802 0.42655167] @epoch 36\n",
      "Epoch 037: val_acc did not improve from 0.583\n",
      "576/576 [==============================] - 122s 213ms/step - loss: 0.0216 - val_loss: 0.0239\n",
      "Counter: 4, Global: 0.5830437373369932, MyBest: 0.5830437373369932\n",
      "\n",
      "Epoch 38/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.5628022  0.32908976 0.35484949 0.57472259 0.57124335 0.36476511\n",
      " 0.34368354 0.6591993  0.85903883 0.87030047 0.82566553 0.41393444\n",
      " 0.5237093  0.70787454 0.70490658 0.5041427  0.39770961] @epoch 37\n",
      "Epoch 038: val_acc did not improve from 0.583\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0215 - val_loss: 0.0240\n",
      "Counter: 5, Global: 0.5830437373369932, MyBest: 0.5830437373369932\n",
      "\n",
      "Epoch 39/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.57255852 0.35136855 0.37709031 0.56939042 0.56749749 0.37751678\n",
      " 0.33156103 0.650383   0.86979604 0.87547171 0.83637154 0.42283776\n",
      " 0.53381032 0.72501743 0.72874266 0.53152645 0.4125548 ] @epoch 38\n",
      "Epoch 039: val_acc did not improve from 0.583\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0215 - val_loss: 0.0240\n",
      "Counter: 6, Global: 0.5830437373369932, MyBest: 0.5830437373369932\n",
      "\n",
      "Epoch 40/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0214\n",
      "validate accuracy:\n",
      " [0.57661026 0.34351793 0.38210702 0.58538693 0.57700622 0.38171142\n",
      " 0.32730752 0.66208988 0.8752445  0.87952483 0.84447336 0.42015263\n",
      " 0.54124582 0.72989547 0.72693056 0.53166687 0.41750318] @epoch 39\n",
      "Epoch 040: val_acc did not improve from 0.583\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0214 - val_loss: 0.0239\n",
      "Counter: 7, Global: 0.5830437373369932, MyBest: 0.5830437373369932\n",
      "\n",
      "Epoch 040: Updating Learning rate.. New value is 0.001500\n",
      "Epoch 41/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0210\n",
      "validate accuracy:\n",
      " [0.58307914 0.35476342 0.38076922 0.58091944 0.57556546 0.39848992\n",
      " 0.33921736 0.66440237 0.88181055 0.88819009 0.85373265 0.43470886\n",
      " 0.54433221 0.73477352 0.72483969 0.53602022 0.43673122] @epoch 40\n",
      "Epoch 041: val_acc improved from 0.583 to 0.583\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0210 - val_loss: 0.0239\n",
      "Counter: 0, Global: 0.5830791369080544, MyBest: 0.5830437373369932\n",
      "\n",
      "Epoch 42/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0209\n",
      "validate accuracy:\n",
      " [0.59244026 0.36134097 0.38979933 0.59158379 0.59760839 0.39848992\n",
      " 0.33645257 0.68015611 0.88823694 0.89266247 0.85474539 0.44248164\n",
      " 0.55513465 0.74634147 0.75048786 0.55862939 0.43489325] @epoch 41\n",
      "Epoch 042: val_acc improved from 0.583 to 0.592\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0209 - val_loss: 0.0239\n",
      "Counter: 0, Global: 0.5924402587115765, MyBest: 0.5830791369080544\n",
      "\n",
      "Epoch 43/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0208\n",
      "validate accuracy:\n",
      " [0.58556399 0.3579461  0.38712373 0.59086323 0.59184557 0.3899329\n",
      " 0.34134412 0.67119527 0.88390613 0.88679248 0.84620947 0.43371961\n",
      " 0.54405165 0.73881531 0.74142736 0.53503722 0.42881379] @epoch 42\n",
      "Epoch 043: val_acc did not improve from 0.592\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0208 - val_loss: 0.0240\n",
      "Counter: 0, Global: 0.5924402587115765, MyBest: 0.5924402587115765\n",
      "\n",
      "Epoch 44/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0208\n",
      "validate accuracy:\n",
      " [0.58386833 0.344791   0.39548495 0.58668399 0.58680308 0.39899328\n",
      " 0.33772862 0.67162883 0.87957531 0.88483578 0.84389466 0.42947993\n",
      " 0.54433221 0.73156792 0.73069417 0.54163742 0.43376219] @epoch 43\n",
      "Epoch 044: val_acc did not improve from 0.592\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0208 - val_loss: 0.0240\n",
      "Counter: 1, Global: 0.5924402587115765, MyBest: 0.5924402587115765\n",
      "\n",
      "Epoch 45/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0207\n",
      "validate accuracy:\n",
      " [0.58672125 0.35264164 0.39498329 0.59057504 0.58435386 0.3988255\n",
      " 0.34155679 0.66613674 0.87873709 0.88581413 0.8504051  0.42863199\n",
      " 0.55359149 0.7378397  0.74226373 0.54346299 0.43772092] @epoch 44\n",
      "Epoch 045: val_acc did not improve from 0.592\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0207 - val_loss: 0.0240\n",
      "Counter: 2, Global: 0.5924402587115765, MyBest: 0.5924402587115765\n",
      "\n",
      "Epoch 46/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0207\n",
      "validate accuracy:\n",
      " [0.58844677 0.35646084 0.39464882 0.58826917 0.59285408 0.39865771\n",
      " 0.34772438 0.67148429 0.87999439 0.88525504 0.85416669 0.43470886\n",
      " 0.54966331 0.74020904 0.73933649 0.54851848 0.43319666] @epoch 45\n",
      "Epoch 046: val_acc did not improve from 0.592\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0207 - val_loss: 0.0242\n",
      "Counter: 3, Global: 0.5924402587115765, MyBest: 0.5924402587115765\n",
      "\n",
      "Epoch 47/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0206\n",
      "validate accuracy:\n",
      " [0.58436515 0.35858265 0.38812709 0.57962245 0.58392161 0.39295301\n",
      " 0.34347087 0.66917187 0.87747973 0.88511533 0.85127312 0.42764273\n",
      " 0.54208755 0.73310107 0.73780316 0.54304171 0.43644845] @epoch 46\n",
      "Epoch 047: val_acc did not improve from 0.592\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0206 - val_loss: 0.0243\n",
      "Counter: 4, Global: 0.5924402587115765, MyBest: 0.5924402587115765\n",
      "\n",
      "Epoch 48/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0206\n",
      "validate accuracy:\n",
      " [0.58924128 0.35391471 0.39013377 0.58668399 0.59083706 0.4035235\n",
      " 0.34347087 0.66830468 0.88195026 0.88749129 0.85373265 0.43753535\n",
      " 0.55906284 0.73909408 0.74602735 0.54851848 0.43757954] @epoch 47\n",
      "Epoch 048: val_acc did not improve from 0.592\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0206 - val_loss: 0.0240\n",
      "Counter: 5, Global: 0.5924402587115765, MyBest: 0.5924402587115765\n",
      "\n",
      "Epoch 49/151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - ETA: 0s - loss: 0.0205\n",
      "validate accuracy:\n",
      " [0.58744256 0.36028007 0.38963211 0.57630783 0.5829131  0.39966443\n",
      " 0.33666524 0.66613674 0.88111204 0.88679248 0.84953701 0.43569812\n",
      " 0.54882157 0.74439025 0.74770004 0.55146748 0.44196239] @epoch 48\n",
      "Epoch 049: val_acc did not improve from 0.592\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0205 - val_loss: 0.0241\n",
      "Counter: 6, Global: 0.5924402587115765, MyBest: 0.5924402587115765\n",
      "\n",
      "Epoch 50/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0205\n",
      "validate accuracy:\n",
      " [0.58873189 0.359007   0.39565217 0.5884133  0.5935744  0.402349\n",
      " 0.3353892  0.67668736 0.88586199 0.88972747 0.84809029 0.43357828\n",
      " 0.55303031 0.73714286 0.7389183  0.54739505 0.43489325] @epoch 49\n",
      "Epoch 050: val_acc did not improve from 0.592\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0205 - val_loss: 0.0243\n",
      "Counter: 7, Global: 0.5924402587115765, MyBest: 0.5924402587115765\n",
      "\n",
      "Epoch 050: Updating Learning rate.. New value is 0.000900\n",
      "Epoch 51/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0203\n",
      "validate accuracy:\n",
      " [0.59098972 0.35837045 0.39648831 0.5884133  0.59040487 0.4080537\n",
      " 0.3396427  0.67148429 0.88670021 0.89126486 0.8532986  0.4385246\n",
      " 0.55373174 0.73742163 0.73989403 0.55933154 0.44281068] @epoch 50\n",
      "Epoch 051: val_acc did not improve from 0.592\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0203 - val_loss: 0.0242\n",
      "Counter: 0, Global: 0.5924402587115765, MyBest: 0.5924402587115765\n",
      "\n",
      "Epoch 52/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0202\n",
      "validate accuracy:\n",
      " [0.59251463 0.35349035 0.39665553 0.58783686 0.59242183 0.40989932\n",
      " 0.34878775 0.66714841 0.88767815 0.89084554 0.85546875 0.44389486\n",
      " 0.55232882 0.74745643 0.74867576 0.55525911 0.44238654] @epoch 51\n",
      "Epoch 052: val_acc improved from 0.592 to 0.593\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0202 - val_loss: 0.0242\n",
      "Counter: 1, Global: 0.5925146266818047, MyBest: 0.5924402587115765\n",
      "\n",
      "Epoch 53/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0201\n",
      "validate accuracy:\n",
      " [0.59134326 0.36155316 0.39464882 0.58495462 0.59170151 0.41308725\n",
      " 0.34262016 0.67784363 0.88837665 0.89112508 0.85026044 0.43908989\n",
      " 0.54727834 0.74216026 0.74533033 0.54978234 0.44167963] @epoch 52\n",
      "Epoch 053: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0201 - val_loss: 0.0242\n",
      "Counter: 0, Global: 0.5925146266818047, MyBest: 0.5925146266818047\n",
      "\n",
      "Epoch 54/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0201\n",
      "validate accuracy:\n",
      " [0.59021653 0.35582432 0.39866221 0.58149588 0.58709121 0.40604028\n",
      " 0.35048914 0.66469145 0.88558257 0.88846958 0.85112846 0.43979651\n",
      " 0.55036473 0.74662024 0.74700308 0.54753548 0.4426693 ] @epoch 53\n",
      "Epoch 054: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0201 - val_loss: 0.0242\n",
      "Counter: 1, Global: 0.5925146266818047, MyBest: 0.5925146266818047\n",
      "\n",
      "Epoch 55/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0200\n",
      "validate accuracy:\n",
      " [0.59129179 0.35264164 0.39615384 0.5884133  0.58939636 0.40620807\n",
      " 0.35325393 0.66281253 0.88572228 0.88930815 0.8527199  0.44022048\n",
      " 0.55359149 0.74229968 0.74588794 0.55371439 0.44832462] @epoch 54\n",
      "Epoch 055: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0200 - val_loss: 0.0243\n",
      "Counter: 2, Global: 0.5925146266818047, MyBest: 0.5925146266818047\n",
      "\n",
      "Epoch 56/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0199\n",
      "validate accuracy:\n",
      " [0.58894517 0.35985571 0.39113712 0.58437812 0.59285408 0.4045302\n",
      " 0.34049341 0.67249602 0.88278848 0.89014673 0.84577549 0.43753535\n",
      " 0.55078566 0.73449475 0.74003345 0.55371439 0.44210377] @epoch 55\n",
      "Epoch 056: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0199 - val_loss: 0.0243\n",
      "Counter: 3, Global: 0.5925146266818047, MyBest: 0.5925146266818047\n",
      "\n",
      "Epoch 57/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0199\n",
      "validate accuracy:\n",
      " [0.58718765 0.35051984 0.39080268 0.58898979 0.58709121 0.4045302\n",
      " 0.33581454 0.67307413 0.88083261 0.88315862 0.84765625 0.43583944\n",
      " 0.54854095 0.7410453  0.74156678 0.54739505 0.43814507] @epoch 56\n",
      "Epoch 057: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0199 - val_loss: 0.0244\n",
      "Counter: 4, Global: 0.5925146266818047, MyBest: 0.5925146266818047\n",
      "\n",
      "Epoch 58/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0199\n",
      "validate accuracy:\n",
      " [0.59136384 0.35582432 0.39866221 0.59461015 0.59876096 0.40486577\n",
      " 0.34347087 0.67148429 0.88572228 0.88735151 0.84751159 0.43626341\n",
      " 0.55373174 0.74341464 0.74811822 0.54950148 0.44252792] @epoch 57\n",
      "Epoch 058: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0199 - val_loss: 0.0243\n",
      "Counter: 5, Global: 0.5925146266818047, MyBest: 0.5925146266818047\n",
      "\n",
      "Epoch 59/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0198\n",
      "validate accuracy:\n",
      " [0.5891986  0.36049226 0.39247492 0.58682805 0.59515917 0.40067115\n",
      " 0.33921736 0.66526955 0.88516343 0.8895877  0.84780091 0.44064444\n",
      " 0.55289    0.74132407 0.74156678 0.54697376 0.4411141 ] @epoch 58\n",
      "Epoch 059: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0198 - val_loss: 0.0243\n",
      "Counter: 6, Global: 0.5925146266818047, MyBest: 0.5925146266818047\n",
      "\n",
      "Epoch 60/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0198\n",
      "validate accuracy:\n",
      " [0.59027675 0.36028007 0.3944816  0.59086323 0.59083706 0.40218121\n",
      " 0.34113142 0.66830468 0.88586199 0.89112508 0.84924769 0.43795931\n",
      " 0.55737936 0.74034846 0.74240315 0.55034405 0.44167963] @epoch 59\n",
      "Epoch 060: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0198 - val_loss: 0.0244\n",
      "Counter: 7, Global: 0.5925146266818047, MyBest: 0.5925146266818047\n",
      "\n",
      "Epoch 060: Updating Learning rate.. New value is 0.000540\n",
      "Epoch 61/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0196\n",
      "validate accuracy:\n",
      " [0.59065628 0.35624868 0.39347827 0.58927798 0.5940066  0.40469798\n",
      " 0.34049341 0.6685937  0.8865605  0.89028651 0.8498264  0.44022048\n",
      " 0.55681819 0.7360279  0.74351823 0.55933154 0.4411141 ] @epoch 60\n",
      "Epoch 061: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0196 - val_loss: 0.0244\n",
      "Counter: 0, Global: 0.5925146266818047, MyBest: 0.5925146266818047\n",
      "\n",
      "Epoch 62/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0196\n",
      "validate accuracy:\n",
      " [0.592196   0.35433906 0.40000001 0.58870155 0.59631175 0.40855706\n",
      " 0.346661   0.66888279 0.88600171 0.89126486 0.84924769 0.44078577\n",
      " 0.55443323 0.74257839 0.74533033 0.55343348 0.44860739] @epoch 61\n",
      "Epoch 062: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0196 - val_loss: 0.0245\n",
      "Counter: 1, Global: 0.5925146266818047, MyBest: 0.5925146266818047\n",
      "\n",
      "Epoch 63/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0195\n",
      "validate accuracy:\n",
      " [0.58972316 0.35539997 0.39565217 0.59086323 0.59314221 0.40469798\n",
      " 0.33794129 0.66787106 0.88222969 0.89000696 0.8509838  0.44092709\n",
      " 0.55050504 0.73770034 0.74435461 0.55048448 0.44281068] @epoch 62\n",
      "Epoch 063: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0195 - val_loss: 0.0245\n",
      "Counter: 2, Global: 0.5925146266818047, MyBest: 0.5925146266818047\n",
      "\n",
      "Epoch 64/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0195\n",
      "validate accuracy:\n",
      " [0.59285692 0.35921919 0.39648831 0.59316903 0.59631175 0.40520135\n",
      " 0.34517226 0.67076164 0.88697958 0.88972747 0.84910303 0.44092709\n",
      " 0.55962402 0.74578398 0.74421525 0.55399525 0.44903153] @epoch 63\n",
      "Epoch 064: val_acc improved from 0.593 to 0.593\n",
      "576/576 [==============================] - 121s 211ms/step - loss: 0.0195 - val_loss: 0.0244\n",
      "Counter: 3, Global: 0.5928569212555885, MyBest: 0.5925146266818047\n",
      "\n",
      "Epoch 65/151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - ETA: 0s - loss: 0.0195\n",
      "validate accuracy:\n",
      " [0.58947804 0.35709739 0.39632106 0.57962245 0.58651489 0.40755033\n",
      " 0.34410888 0.66252351 0.88572228 0.88846958 0.85112846 0.44120973\n",
      " 0.54966331 0.73895472 0.74170613 0.55273134 0.44832462] @epoch 64\n",
      "Epoch 065: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0195 - val_loss: 0.0245\n",
      "Counter: 0, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 66/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0195\n",
      "validate accuracy:\n",
      " [0.59033587 0.359007   0.39130434 0.58740455 0.59170151 0.40553692\n",
      " 0.34262016 0.66570312 0.88725901 0.8895877  0.84852433 0.44120973\n",
      " 0.55443323 0.74146342 0.74393642 0.55287176 0.44281068] @epoch 65\n",
      "Epoch 066: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0195 - val_loss: 0.0245\n",
      "Counter: 1, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 67/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0195\n",
      "validate accuracy:\n",
      " [0.59166771 0.35709739 0.40317726 0.59057504 0.59631175 0.4080537\n",
      " 0.34283283 0.67336321 0.88097233 0.8888889  0.85185188 0.43640473\n",
      " 0.55836141 0.73742163 0.73989403 0.55315262 0.44832462] @epoch 66\n",
      "Epoch 067: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0195 - val_loss: 0.0245\n",
      "Counter: 2, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 68/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0194\n",
      "validate accuracy:\n",
      " [0.59146699 0.36600891 0.39816055 0.58913386 0.58982855 0.4045302\n",
      " 0.34006804 0.66685939 0.88167083 0.89028651 0.84837961 0.44276428\n",
      " 0.55681819 0.74034846 0.74491221 0.55862939 0.4450728 ] @epoch 67\n",
      "Epoch 068: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0194 - val_loss: 0.0246\n",
      "Counter: 3, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 69/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0194\n",
      "validate accuracy:\n",
      " [0.58949881 0.36112881 0.3931438  0.58682805 0.59587955 0.40469798\n",
      " 0.33943003 0.67162883 0.88111204 0.88791054 0.84693289 0.43923122\n",
      " 0.55064535 0.73686409 0.74198496 0.55118662 0.44337621] @epoch 68\n",
      "Epoch 069: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0194 - val_loss: 0.0245\n",
      "Counter: 4, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 70/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0194\n",
      "validate accuracy:\n",
      " [0.59164903 0.36240187 0.39882943 0.59302491 0.59198964 0.40469798\n",
      " 0.3396427  0.66989452 0.88572228 0.89098531 0.84794563 0.4429056\n",
      " 0.55737936 0.74090594 0.74226373 0.55399525 0.44380036] @epoch 69\n",
      "Epoch 070: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0194 - val_loss: 0.0246\n",
      "Counter: 5, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 71/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0194\n",
      "validate accuracy:\n",
      " [0.59035632 0.36049226 0.39983279 0.58783686 0.59011668 0.40855706\n",
      " 0.34176946 0.67032808 0.88306791 0.88944793 0.84765625 0.44078577\n",
      " 0.55583614 0.73477352 0.73766381 0.55048448 0.44705218] @epoch 70\n",
      "Epoch 071: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0194 - val_loss: 0.0246\n",
      "Counter: 6, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 72/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0194\n",
      "validate accuracy:\n",
      " [0.59098122 0.36303839 0.39916387 0.58726043 0.59011668 0.41006711\n",
      " 0.34091875 0.66310161 0.88446492 0.88986725 0.84866899 0.44530809\n",
      " 0.55373174 0.74020904 0.74323946 0.55104619 0.44549695] @epoch 71\n",
      "Epoch 072: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0194 - val_loss: 0.0245\n",
      "Counter: 7, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 072: Updating Learning rate.. New value is 0.000324\n",
      "Epoch 73/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0193\n",
      "validate accuracy:\n",
      " [0.5911208  0.36643326 0.40050167 0.58769274 0.5940066  0.40771812\n",
      " 0.34453425 0.66671485 0.8823694  0.88944793 0.85026044 0.44135106\n",
      " 0.55218858 0.73797911 0.73738497 0.55413568 0.44521418] @epoch 72\n",
      "Epoch 073: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0193 - val_loss: 0.0246\n",
      "Counter: 0, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 74/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0192\n",
      "validate accuracy:\n",
      " [0.59075915 0.359007   0.39665553 0.58567518 0.58838785 0.41224831\n",
      " 0.34857509 0.66454691 0.88488406 0.8888889  0.84895831 0.44544941\n",
      " 0.55485409 0.73867595 0.73794258 0.55020362 0.44719356] @epoch 73\n",
      "Epoch 074: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0192 - val_loss: 0.0247\n",
      "Counter: 1, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 75/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0192\n",
      "validate accuracy:\n",
      " [0.58966051 0.36112881 0.39481604 0.58322525 0.58939636 0.40604028\n",
      " 0.34134412 0.66107821 0.88628107 0.88846958 0.84852433 0.44078577\n",
      " 0.55639732 0.73825783 0.73905772 0.55539954 0.44436589] @epoch 74\n",
      "Epoch 075: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0192 - val_loss: 0.0246\n",
      "Counter: 2, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 76/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0192\n",
      "validate accuracy:\n",
      " [0.58805149 0.35985571 0.39347827 0.58336937 0.58493012 0.4035235\n",
      " 0.34347087 0.65876573 0.88222969 0.8888889  0.84794563 0.44050312\n",
      " 0.55092591 0.73324043 0.74100918 0.55062491 0.44606251] @epoch 75\n",
      "Epoch 076: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0192 - val_loss: 0.0246\n",
      "Counter: 3, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 77/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0192\n",
      "validate accuracy:\n",
      " [0.58955824 0.35688522 0.39632106 0.58077532 0.58997262 0.40939596\n",
      " 0.34283283 0.66816014 0.88418555 0.88860935 0.84866899 0.44120973\n",
      " 0.55274969 0.73700351 0.73863953 0.55259091 0.44493142] @epoch 76\n",
      "Epoch 077: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0192 - val_loss: 0.0247\n",
      "Counter: 4, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 78/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0192\n",
      "validate accuracy:\n",
      " [0.5892609  0.35730958 0.39782608 0.58668399 0.58420974 0.40218121\n",
      " 0.34538496 0.66440237 0.88446492 0.89084554 0.84693289 0.44120973\n",
      " 0.55064535 0.73895472 0.73975468 0.55441654 0.44295207] @epoch 77\n",
      "Epoch 078: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0192 - val_loss: 0.0247\n",
      "Counter: 5, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 79/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0192\n",
      "validate accuracy:\n",
      " [0.58907955 0.35455126 0.40016723 0.58509874 0.58579457 0.40973154\n",
      " 0.34262016 0.66584766 0.88208997 0.88623339 0.8509838  0.43598077\n",
      " 0.55274969 0.74090594 0.73919708 0.54669291 0.44662803] @epoch 78\n",
      "Epoch 079: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0192 - val_loss: 0.0246\n",
      "Counter: 6, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 80/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0191\n",
      "validate accuracy:\n",
      " [0.58992627 0.36070442 0.39849499 0.58149588 0.58766747 0.40721476\n",
      " 0.34432158 0.66642576 0.88600171 0.89140463 0.84881365 0.43993783\n",
      " 0.55401236 0.73770034 0.73822135 0.55076534 0.44563833] @epoch 79\n",
      "Epoch 080: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0191 - val_loss: 0.0247\n",
      "Counter: 7, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 080: Updating Learning rate.. New value is 0.000194\n",
      "Epoch 81/151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - ETA: 0s - loss: 0.0191\n",
      "validate accuracy:\n",
      " [0.59032518 0.36197752 0.39765885 0.5871163  0.58867598 0.40604028\n",
      " 0.33921736 0.66888279 0.88264877 0.88944793 0.84910303 0.44191635\n",
      " 0.55471379 0.7385366  0.7389183  0.55273134 0.44761771] @epoch 80\n",
      "Epoch 081: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0191 - val_loss: 0.0247\n",
      "Counter: 0, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 82/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0191\n",
      "validate accuracy:\n",
      " [0.5895737  0.35539997 0.39749163 0.58221644 0.58406568 0.40939596\n",
      " 0.34581029 0.66512501 0.88292819 0.88972747 0.8498264  0.44050312\n",
      " 0.55289    0.7385366  0.7407304  0.54964191 0.44889015] @epoch 81\n",
      "Epoch 082: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0191 - val_loss: 0.0247\n",
      "Counter: 1, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 83/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0190\n",
      "validate accuracy:\n",
      " [0.58941167 0.36112881 0.3958194  0.58178413 0.58579457 0.40620807\n",
      " 0.33985537 0.66512501 0.88460463 0.88846958 0.84794563 0.44234031\n",
      " 0.55331087 0.73951221 0.73947591 0.55357397 0.44563833] @epoch 82\n",
      "Epoch 083: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0190 - val_loss: 0.0247\n",
      "Counter: 2, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 84/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0190\n",
      "validate accuracy:\n",
      " [0.59037911 0.359007   0.39866221 0.58754861 0.5889641  0.40989932\n",
      " 0.34155679 0.66570312 0.88404584 0.88707197 0.84722221 0.44120973\n",
      " 0.55780023 0.73881531 0.73919708 0.55231005 0.44705218] @epoch 83\n",
      "Epoch 084: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0190 - val_loss: 0.0248\n",
      "Counter: 3, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 85/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0190\n",
      "validate accuracy:\n",
      " [0.59108303 0.35752174 0.40183946 0.58668399 0.58954042 0.40738255\n",
      " 0.3432582  0.66700393 0.8836267  0.8895877  0.8504051  0.44530809\n",
      " 0.55317062 0.73979092 0.74003345 0.55441654 0.44775909] @epoch 84\n",
      "Epoch 085: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0190 - val_loss: 0.0247\n",
      "Counter: 4, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 86/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0190\n",
      "validate accuracy:\n",
      " [0.58923905 0.36218968 0.39665553 0.58524281 0.58392161 0.40771812\n",
      " 0.33857933 0.66498047 0.8823694  0.89000696 0.8509838  0.44007915\n",
      " 0.55415261 0.73560977 0.73696685 0.55287176 0.44549695] @epoch 85\n",
      "Epoch 086: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0190 - val_loss: 0.0248\n",
      "Counter: 5, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 87/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0190\n",
      "validate accuracy:\n",
      " [0.59044708 0.36197752 0.39916387 0.58855742 0.58665895 0.40587249\n",
      " 0.34495959 0.66353518 0.88250905 0.88832986 0.84910303 0.4416337\n",
      " 0.55401236 0.74076653 0.74198496 0.55245048 0.44563833] @epoch 86\n",
      "Epoch 087: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0190 - val_loss: 0.0247\n",
      "Counter: 6, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 88/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0190\n",
      "validate accuracy:\n",
      " [0.59044106 0.36049226 0.39916387 0.58726043 0.58968449 0.41073826\n",
      " 0.34049341 0.66483593 0.88013411 0.88693219 0.84895831 0.44205767\n",
      " 0.55723906 0.7378397  0.73961526 0.55413568 0.44747633] @epoch 87\n",
      "Epoch 088: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0190 - val_loss: 0.0248\n",
      "Counter: 7, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 088: Updating Learning rate.. New value is 0.000117\n",
      "Epoch 89/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0190\n",
      "validate accuracy:\n",
      " [0.58987035 0.36282623 0.3958194  0.58754861 0.58781153 0.40721476\n",
      " 0.34049341 0.6659922  0.88306791 0.89070582 0.84751159 0.43937254\n",
      " 0.55443323 0.73714286 0.73863953 0.55469739 0.44464865] @epoch 88\n",
      "Epoch 089: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0190 - val_loss: 0.0248\n",
      "Counter: 0, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 90/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0190\n",
      "validate accuracy:\n",
      " [0.58895008 0.36049226 0.39598662 0.582937   0.58262497 0.40822148\n",
      " 0.3396427  0.66310161 0.88153118 0.887631   0.85011572 0.44248164\n",
      " 0.5549944  0.73839724 0.73822135 0.55160791 0.44521418] @epoch 89\n",
      "Epoch 090: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0190 - val_loss: 0.0248\n",
      "Counter: 1, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 91/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0189\n",
      "validate accuracy:\n",
      " [0.58952167 0.35964355 0.39682275 0.58380169 0.58435386 0.40721476\n",
      " 0.34347087 0.66266799 0.88097233 0.88777077 0.84924769 0.44248164\n",
      " 0.5549944  0.74160278 0.73836076 0.55188876 0.44705218] @epoch 90\n",
      "Epoch 091: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0189 - val_loss: 0.0248\n",
      "Counter: 2, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 92/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0189\n",
      "validate accuracy:\n",
      " [0.58903385 0.35985571 0.39347827 0.58553106 0.58435386 0.40788591\n",
      " 0.34198213 0.66570312 0.88111204 0.88665271 0.84707755 0.43908989\n",
      " 0.55387205 0.73686409 0.73947591 0.55483782 0.44676942] @epoch 91\n",
      "Epoch 092: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0189 - val_loss: 0.0248\n",
      "Counter: 3, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 93/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0189\n",
      "validate accuracy:\n",
      " [0.58939616 0.36197752 0.39782608 0.58322525 0.58781153 0.40822148\n",
      " 0.34006804 0.66411328 0.88181055 0.88805032 0.84968174 0.44022048\n",
      " 0.55527496 0.735331   0.73877895 0.55245048 0.44549695] @epoch 92\n",
      "Epoch 093: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0189 - val_loss: 0.0248\n",
      "Counter: 4, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 94/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0189\n",
      "validate accuracy:\n",
      " [0.58843352 0.35921919 0.39816055 0.58380169 0.58305722 0.40738255\n",
      " 0.34176946 0.6612227  0.87985468 0.88819009 0.84722221 0.44248164\n",
      " 0.55359149 0.73797911 0.73445779 0.55062491 0.44592112] @epoch 93\n",
      "Epoch 094: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0189 - val_loss: 0.0248\n",
      "Counter: 5, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 95/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0189\n",
      "validate accuracy:\n",
      " [0.58869519 0.35985571 0.39749163 0.58221644 0.5829131  0.40587249\n",
      " 0.3430455  0.66382426 0.88153118 0.88777077 0.84823495 0.44022048\n",
      " 0.55429292 0.73993033 0.73877895 0.55188876 0.44125548] @epoch 94\n",
      "Epoch 095: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0189 - val_loss: 0.0248\n",
      "Counter: 6, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 96/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0189\n",
      "validate accuracy:\n",
      " [0.58783999 0.35815829 0.39732441 0.58207232 0.58334535 0.40285236\n",
      " 0.34134412 0.66237897 0.88069296 0.88874912 0.84924769 0.43894857\n",
      " 0.55260944 0.73630661 0.73473656 0.55273134 0.44394174] @epoch 95\n",
      "Epoch 096: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0189 - val_loss: 0.0248\n",
      "Counter: 7, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 096: Updating Learning rate.. New value is 0.000070\n",
      "Epoch 97/151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - ETA: 0s - loss: 0.0189\n",
      "validate accuracy:\n",
      " [0.5887096  0.35879481 0.39732441 0.58365756 0.58204871 0.4067114\n",
      " 0.3430455  0.66078913 0.87915617 0.88609362 0.84910303 0.44361222\n",
      " 0.55401236 0.73770034 0.7371062  0.55413568 0.44606251] @epoch 96\n",
      "Epoch 097: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0189 - val_loss: 0.0248\n",
      "Counter: 0, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 98/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0189\n",
      "validate accuracy:\n",
      " [0.58878603 0.36176533 0.39698997 0.58509874 0.58262497 0.40469798\n",
      " 0.33772862 0.66353518 0.88069296 0.88846958 0.84823495 0.44092709\n",
      " 0.55429292 0.74048781 0.73919708 0.55146748 0.44436589] @epoch 97\n",
      "Epoch 098: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0189 - val_loss: 0.0248\n",
      "Counter: 1, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 99/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0189\n",
      "validate accuracy:\n",
      " [0.58885156 0.36112881 0.3979933  0.58250469 0.58219278 0.40687919\n",
      " 0.34134412 0.66266799 0.88097233 0.88777077 0.84866899 0.44248164\n",
      " 0.55345118 0.73993033 0.73863953 0.54936105 0.44563833] @epoch 98\n",
      "Epoch 099: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0189 - val_loss: 0.0248\n",
      "Counter: 2, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 100/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0189\n",
      "validate accuracy:\n",
      " [0.58878574 0.35943136 0.39749163 0.58524281 0.58464199 0.40486577\n",
      " 0.34155679 0.66295707 0.88097233 0.88721174 0.84881365 0.44135106\n",
      " 0.55303031 0.73965156 0.73794258 0.55118662 0.44422451] @epoch 99\n",
      "Epoch 100: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0189 - val_loss: 0.0248\n",
      "Counter: 3, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 101/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0189\n",
      "validate accuracy:\n",
      " [0.58847785 0.36070442 0.39665553 0.58149588 0.5810402  0.40838927\n",
      " 0.34240749 0.66252351 0.88153118 0.88735151 0.84823495 0.44050312\n",
      " 0.55387205 0.73728222 0.73696685 0.55062491 0.44606251] @epoch 100\n",
      "Epoch 101: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 209ms/step - loss: 0.0189 - val_loss: 0.0248\n",
      "Counter: 4, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 102/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0189\n",
      "validate accuracy:\n",
      " [0.58817331 0.35773394 0.39782608 0.58192825 0.58233684 0.4045302\n",
      " 0.34283283 0.66180086 0.88069296 0.88916844 0.84997106 0.44078577\n",
      " 0.55274969 0.73505229 0.7371062  0.55146748 0.44479004] @epoch 101\n",
      "Epoch 102: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 120s 209ms/step - loss: 0.0189 - val_loss: 0.0248\n",
      "Counter: 5, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 103/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0189\n",
      "validate accuracy:\n",
      " [0.58856552 0.36112881 0.39615384 0.58149588 0.57887912 0.40536913\n",
      " 0.3430455  0.66136724 0.88153118 0.88832986 0.84910303 0.4416337\n",
      " 0.55485409 0.73825783 0.7371062  0.55287176 0.44592112] @epoch 102\n",
      "Epoch 103: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 209ms/step - loss: 0.0189 - val_loss: 0.0248\n",
      "Counter: 6, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 104/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0189\n",
      "validate accuracy:\n",
      " [0.58831864 0.36028007 0.39598662 0.58120769 0.57729435 0.40738255\n",
      " 0.34347087 0.66194534 0.87747973 0.88749129 0.84823495 0.44205767\n",
      " 0.55387205 0.7385366  0.73863953 0.55259091 0.44662803] @epoch 103\n",
      "Epoch 104: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0189 - val_loss: 0.0248\n",
      "Counter: 7, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 104: Updating Learning rate.. New value is 0.000042\n",
      "Epoch 105/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0189\n",
      "validate accuracy:\n",
      " [0.58824204 0.36176533 0.39531773 0.58466637 0.58276904 0.40654361\n",
      " 0.33985537 0.66078913 0.88069296 0.887631   0.84794563 0.4403618\n",
      " 0.55653757 0.73867595 0.73473656 0.54950148 0.44408312] @epoch 104\n",
      "Epoch 105: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0189 - val_loss: 0.0248\n",
      "Counter: 0, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 106/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0189\n",
      "validate accuracy:\n",
      " [0.58815348 0.35985571 0.39531773 0.58221644 0.5810402  0.40687919\n",
      " 0.34347087 0.66107821 0.87985468 0.88707197 0.84794563 0.44022048\n",
      " 0.55303031 0.73993033 0.73571229 0.55020362 0.44662803] @epoch 105\n",
      "Epoch 106: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0189 - val_loss: 0.0248\n",
      "Counter: 1, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 107/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0189\n",
      "validate accuracy:\n",
      " [0.58815334 0.36134097 0.39515051 0.58106357 0.58219278 0.40654361\n",
      " 0.34113142 0.6591993  0.88083261 0.88735151 0.84924769 0.4403618\n",
      " 0.55317062 0.73993033 0.7371062  0.55188876 0.44394174] @epoch 106\n",
      "Epoch 107: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0189 - val_loss: 0.0248\n",
      "Counter: 2, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 108/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0188\n",
      "validate accuracy:\n",
      " [0.58835436 0.35985571 0.39598662 0.5793342  0.58276904 0.40956375\n",
      " 0.34176946 0.66194534 0.88139147 0.8859539  0.84953701 0.44022048\n",
      " 0.55289    0.74020904 0.73626989 0.55160791 0.44436589] @epoch 107\n",
      "Epoch 108: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0188 - val_loss: 0.0248\n",
      "Counter: 3, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 109/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0188\n",
      "validate accuracy:\n",
      " [0.58824549 0.36070442 0.39698997 0.58164001 0.58219278 0.40721476\n",
      " 0.34219483 0.66180086 0.88167083 0.88735151 0.84852433 0.44106841\n",
      " 0.55471379 0.73825783 0.73501533 0.55048448 0.44210377] @epoch 108\n",
      "Epoch 109: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0188 - val_loss: 0.0248\n",
      "Counter: 4, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 110/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0188\n",
      "validate accuracy:\n",
      " [0.5882389  0.36028007 0.39632106 0.57962245 0.58348942 0.40704697\n",
      " 0.34240749 0.65992194 0.88055325 0.88721174 0.84910303 0.44191635\n",
      " 0.55303031 0.73881531 0.73668802 0.55062491 0.44479004] @epoch 109\n",
      "Epoch 110: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0188 - val_loss: 0.0248\n",
      "Counter: 5, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 111/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0188\n",
      "validate accuracy:\n",
      " [0.58834142 0.36155316 0.3936455  0.5806312  0.58060801 0.40956375\n",
      " 0.34070608 0.66107821 0.88041353 0.887631   0.84924769 0.44135106\n",
      " 0.55443323 0.73937285 0.73640925 0.55216962 0.44464865] @epoch 110\n",
      "Epoch 111: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 120s 209ms/step - loss: 0.0188 - val_loss: 0.0248\n",
      "Counter: 6, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 112/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0188\n",
      "validate accuracy:\n",
      " [0.58837938 0.36155316 0.39615384 0.57991064 0.58132833 0.40704697\n",
      " 0.34070608 0.65934384 0.88041353 0.88791054 0.84852433 0.44120973\n",
      " 0.55303031 0.74076653 0.73724562 0.55399525 0.44493142] @epoch 111\n",
      "Epoch 112: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 209ms/step - loss: 0.0188 - val_loss: 0.0248\n",
      "Counter: 7, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 112: Updating Learning rate.. New value is 0.000025\n",
      "Epoch 113/151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - ETA: 0s - loss: 0.0188\n",
      "validate accuracy:\n",
      " [0.58808468 0.36197752 0.39565217 0.58236057 0.5814724  0.40604028\n",
      " 0.34091875 0.65948838 0.87999439 0.88665271 0.84837961 0.44177502\n",
      " 0.55317062 0.73923343 0.73599106 0.55287176 0.44337621] @epoch 112\n",
      "Epoch 113: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0188 - val_loss: 0.0248\n",
      "Counter: 0, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 114/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0188\n",
      "validate accuracy:\n",
      " [0.58877705 0.36261404 0.39548495 0.58077532 0.58406568 0.40939596\n",
      " 0.34155679 0.65876573 0.88013411 0.88721174 0.84910303 0.44262296\n",
      " 0.55471379 0.73937285 0.73766381 0.55329305 0.44365898] @epoch 113\n",
      "Epoch 114: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0188 - val_loss: 0.0248\n",
      "Counter: 1, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 115/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0188\n",
      "validate accuracy:\n",
      " [0.5879256  0.36176533 0.39531773 0.58005476 0.58060801 0.40687919\n",
      " 0.34176946 0.65876573 0.87831795 0.88637316 0.84939235 0.44191635\n",
      " 0.55457354 0.73881531 0.73473656 0.55231005 0.44521418] @epoch 114\n",
      "Epoch 115: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0188 - val_loss: 0.0248\n",
      "Counter: 2, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 116/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0188\n",
      "validate accuracy:\n",
      " [0.58775754 0.36049226 0.39548495 0.58135176 0.58118427 0.40721476\n",
      " 0.33943003 0.65847665 0.87859738 0.88637316 0.84809029 0.44177502\n",
      " 0.55289    0.73839724 0.73571229 0.55301219 0.44563833] @epoch 115\n",
      "Epoch 116: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0188 - val_loss: 0.0248\n",
      "Counter: 3, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 117/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0188\n",
      "validate accuracy:\n",
      " [0.58790544 0.36218968 0.39565217 0.58034301 0.58060801 0.40738255\n",
      " 0.34176946 0.65934384 0.87845767 0.887631   0.84780091 0.44205767\n",
      " 0.55387205 0.73909408 0.7352941  0.55062491 0.44436589] @epoch 116\n",
      "Epoch 117: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0188 - val_loss: 0.0248\n",
      "Counter: 4, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 118/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0188\n",
      "validate accuracy:\n",
      " [0.58777911 0.36197752 0.39598662 0.57991064 0.5814724  0.40654361\n",
      " 0.34113142 0.65891027 0.87873709 0.88651294 0.84866899 0.44106841\n",
      " 0.55387205 0.73881531 0.73459715 0.55090576 0.44535556] @epoch 117\n",
      "Epoch 118: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0188 - val_loss: 0.0248\n",
      "Counter: 5, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 119/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0188\n",
      "validate accuracy:\n",
      " [0.58828853 0.36091661 0.39464882 0.58077532 0.58176053 0.40838927\n",
      " 0.34219483 0.65948838 0.87915617 0.88735151 0.84968174 0.44234031\n",
      " 0.55331087 0.73979092 0.73613048 0.55160791 0.4450728 ] @epoch 118\n",
      "Epoch 119: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0188 - val_loss: 0.0248\n",
      "Counter: 6, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 120/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0188\n",
      "validate accuracy:\n",
      " [0.5880457  0.36112881 0.39548495 0.58019888 0.58219278 0.40838927\n",
      " 0.34240749 0.66136724 0.87859738 0.88609362 0.84910303 0.44092709\n",
      " 0.55331087 0.73756099 0.73585171 0.55132705 0.44479004] @epoch 119\n",
      "Epoch 120: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0188 - val_loss: 0.0248\n",
      "Counter: 7, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 120: Updating Learning rate.. New value is 0.000015\n",
      "Epoch 121/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0188\n",
      "validate accuracy:\n",
      " [0.58807279 0.36134097 0.3958194  0.58048707 0.58262497 0.40687919\n",
      " 0.34091875 0.65876573 0.87929589 0.88707197 0.84852433 0.44248164\n",
      " 0.55289    0.73839724 0.73557287 0.55160791 0.44648665] @epoch 120\n",
      "Epoch 121: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0188 - val_loss: 0.0248\n",
      "Counter: 0, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 122/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0188\n",
      "validate accuracy:\n",
      " [0.58851593 0.36049226 0.39698997 0.57919008 0.58334535 0.40872484\n",
      " 0.34240749 0.66180086 0.87915617 0.88735151 0.84866899 0.44120973\n",
      " 0.55303031 0.73797911 0.73626989 0.55329305 0.44634527] @epoch 121\n",
      "Epoch 122: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0188 - val_loss: 0.0248\n",
      "Counter: 1, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 123/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0188\n",
      "validate accuracy:\n",
      " [0.58822124 0.36155316 0.39565217 0.58135176 0.58190465 0.40956375\n",
      " 0.34070608 0.66021103 0.87999439 0.88693219 0.84823495 0.44120973\n",
      " 0.55429292 0.73895472 0.73557287 0.55202919 0.44337621] @epoch 122\n",
      "Epoch 123: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0188 - val_loss: 0.0248\n",
      "Counter: 2, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 124/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0188\n",
      "validate accuracy:\n",
      " [0.58814444 0.36028007 0.39632106 0.58135176 0.58233684 0.40838927\n",
      " 0.34176946 0.66035557 0.87901646 0.88749129 0.84881365 0.44007915\n",
      " 0.55317062 0.73839724 0.73501533 0.55245048 0.4450728 ] @epoch 123\n",
      "Epoch 124: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0188 - val_loss: 0.0248\n",
      "Counter: 3, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 125/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0188\n",
      "validate accuracy:\n",
      " [0.58840044 0.36070442 0.39665553 0.5806312  0.58449793 0.4080537\n",
      " 0.34049341 0.66064459 0.88111204 0.88735151 0.84895831 0.43993783\n",
      " 0.55429292 0.73937285 0.73487592 0.55118662 0.44563833] @epoch 124\n",
      "Epoch 125: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0188 - val_loss: 0.0248\n",
      "Counter: 4, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 126/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0188\n",
      "validate accuracy:\n",
      " [0.58812559 0.3600679  0.39598662 0.58077532 0.58219278 0.40822148\n",
      " 0.34113142 0.65963292 0.87999439 0.88721174 0.84852433 0.43979651\n",
      " 0.55443323 0.73895472 0.73654866 0.55188876 0.44464865] @epoch 125\n",
      "Epoch 126: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0188 - val_loss: 0.0249\n",
      "Counter: 5, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 127/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0188\n",
      "validate accuracy:\n",
      " [0.58849894 0.35879481 0.3958194  0.58164001 0.5814724  0.40889263\n",
      " 0.34049341 0.66136724 0.87971503 0.88819009 0.84866899 0.44149238\n",
      " 0.55387205 0.73965156 0.73613048 0.55287176 0.4469108 ] @epoch 126\n",
      "Epoch 127: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0188 - val_loss: 0.0249\n",
      "Counter: 6, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 128/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0188\n",
      "validate accuracy:\n",
      " [0.5885194  0.36028007 0.39648831 0.58149588 0.58276904 0.40822148\n",
      " 0.34155679 0.66136724 0.88027382 0.887631   0.84895831 0.44106841\n",
      " 0.55331087 0.73909408 0.73613048 0.55245048 0.44521418] @epoch 127\n",
      "Epoch 128: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0188 - val_loss: 0.0249\n",
      "Counter: 7, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 128: Updating Learning rate.. New value is 0.000009\n",
      "Epoch 129/151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - ETA: 0s - loss: 0.0188\n",
      "validate accuracy:\n",
      " [0.58848792 0.3579461  0.3958194  0.58236057 0.58320129 0.40889263\n",
      " 0.34240749 0.66050005 0.87985468 0.88749129 0.84866899 0.4416337\n",
      " 0.55274969 0.74020904 0.73668802 0.55216962 0.44521418] @epoch 128\n",
      "Epoch 129: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0188 - val_loss: 0.0249\n",
      "Counter: 0, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 130/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0188\n",
      "validate accuracy:\n",
      " [0.5886614  0.36155316 0.39648831 0.58135176 0.58190465 0.40838927\n",
      " 0.34028074 0.66165632 0.87971503 0.88735151 0.84939235 0.44177502\n",
      " 0.55415261 0.73937285 0.7371062  0.55188876 0.44620389] @epoch 129\n",
      "Epoch 130: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0188 - val_loss: 0.0249\n",
      "Counter: 1, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 131/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0188\n",
      "validate accuracy:\n",
      " [0.58824043 0.359007   0.39682275 0.58236057 0.58176053 0.40872484\n",
      " 0.34091875 0.66093367 0.87901646 0.88651294 0.84866899 0.44022048\n",
      " 0.55485409 0.73951221 0.73543352 0.55231005 0.44479004] @epoch 130\n",
      "Epoch 131: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0188 - val_loss: 0.0249\n",
      "Counter: 2, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 132/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0188\n",
      "validate accuracy:\n",
      " [0.58791462 0.3600679  0.39749163 0.57962245 0.58060801 0.4080537\n",
      " 0.34176946 0.66136724 0.87859738 0.88707197 0.84809029 0.44078577\n",
      " 0.55359149 0.73867595 0.73571229 0.55118662 0.44394174] @epoch 131\n",
      "Epoch 132: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0188 - val_loss: 0.0249\n",
      "Counter: 3, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 133/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0188\n",
      "validate accuracy:\n",
      " [0.58815633 0.36028007 0.39715719 0.58005476 0.58334535 0.40721476\n",
      " 0.34049341 0.6612227  0.88083261 0.88735151 0.84794563 0.44120973\n",
      " 0.55246913 0.73867595 0.73613048 0.55118662 0.44493142] @epoch 132\n",
      "Epoch 133: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0188 - val_loss: 0.0249\n",
      "Counter: 4, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 134/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0188\n",
      "validate accuracy:\n",
      " [0.58815867 0.359007   0.39498329 0.58164001 0.58190465 0.40889263\n",
      " 0.34176946 0.66035557 0.87915617 0.88777077 0.84837961 0.44092709\n",
      " 0.55471379 0.73909408 0.73654866 0.55343348 0.44196239] @epoch 133\n",
      "Epoch 134: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0188 - val_loss: 0.0249\n",
      "Counter: 5, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 135/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0188\n",
      "validate accuracy:\n",
      " [0.58828286 0.36049226 0.39565217 0.58149588 0.58176053 0.40788591\n",
      " 0.34176946 0.65963292 0.87901646 0.88805032 0.84823495 0.44022048\n",
      " 0.5549944  0.73965156 0.73557287 0.55146748 0.44662803] @epoch 134\n",
      "Epoch 135: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0188 - val_loss: 0.0249\n",
      "Counter: 6, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 136/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0188\n",
      "validate accuracy:\n",
      " [0.58848561 0.35964355 0.39765885 0.57919008 0.58176053 0.40973154\n",
      " 0.34262016 0.66064459 0.87929589 0.88735151 0.84794563 0.44050312\n",
      " 0.55457354 0.73965156 0.73640925 0.55329305 0.44549695] @epoch 135\n",
      "Epoch 136: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0188 - val_loss: 0.0249\n",
      "Counter: 7, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 136: Updating Learning rate.. New value is 0.000005\n",
      "Epoch 137/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0188\n",
      "validate accuracy:\n",
      " [0.58818487 0.36049226 0.39548495 0.58192825 0.58118427 0.40687919\n",
      " 0.34219483 0.66064459 0.87985468 0.88777077 0.84866899 0.43979651\n",
      " 0.55232882 0.73839724 0.7371062  0.55301219 0.44521418] @epoch 136\n",
      "Epoch 137: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0188 - val_loss: 0.0249\n",
      "Counter: 0, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 138/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0188\n",
      "validate accuracy:\n",
      " [0.58801118 0.359007   0.3958194  0.5806312  0.58233684 0.40838927\n",
      " 0.34198213 0.66064459 0.87915617 0.88791054 0.84924769 0.4403618\n",
      " 0.55359149 0.73839724 0.73515475 0.55174834 0.44380036] @epoch 137\n",
      "Epoch 138: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0188 - val_loss: 0.0249\n",
      "Counter: 1, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 139/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0188\n",
      "validate accuracy:\n",
      " [0.58779361 0.36049226 0.39531773 0.58135176 0.58031982 0.40654361\n",
      " 0.34134412 0.66078913 0.87929589 0.88707197 0.84953701 0.43908989\n",
      " 0.55246913 0.7378397  0.7352941  0.55329305 0.44464865] @epoch 138\n",
      "Epoch 139: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0188 - val_loss: 0.0249\n",
      "Counter: 2, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 140/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0188\n",
      "validate accuracy:\n",
      " [0.58776259 0.35921919 0.39515051 0.58091944 0.58248091 0.40738255\n",
      " 0.34176946 0.66021103 0.87915617 0.88707197 0.84809029 0.43979651\n",
      " 0.55246913 0.73951221 0.73654866 0.55090576 0.4435176 ] @epoch 139\n",
      "Epoch 140: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0188 - val_loss: 0.0249\n",
      "Counter: 3, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 141/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0188\n",
      "validate accuracy:\n",
      " [0.58821648 0.36028007 0.39531773 0.58221644 0.58219278 0.40838927\n",
      " 0.34219483 0.6612227  0.87971503 0.88707197 0.84895831 0.43979651\n",
      " 0.55317062 0.73825783 0.73571229 0.55104619 0.44592112] @epoch 140\n",
      "Epoch 141: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0188 - val_loss: 0.0249\n",
      "Counter: 4, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 142/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0188\n",
      "validate accuracy:\n",
      " [0.58859319 0.36112881 0.39565217 0.5835135  0.58219278 0.4080537\n",
      " 0.34219483 0.66064459 0.87985468 0.88707197 0.84823495 0.44022048\n",
      " 0.55359149 0.73965156 0.73682743 0.55188876 0.44676942] @epoch 141\n",
      "Epoch 142: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0188 - val_loss: 0.0249\n",
      "Counter: 5, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 143/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0188\n",
      "validate accuracy:\n",
      " [0.58813863 0.35921919 0.39515051 0.58164001 0.58334535 0.40738255\n",
      " 0.34176946 0.66180086 0.87999439 0.88749129 0.84837961 0.44092709\n",
      " 0.55303031 0.73797911 0.73571229 0.55188876 0.44450727] @epoch 142\n",
      "Epoch 143: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0188 - val_loss: 0.0249\n",
      "Counter: 6, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 144/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0188\n",
      "validate accuracy:\n",
      " [0.58806815 0.36176533 0.39548495 0.58322525 0.58161646 0.40687919\n",
      " 0.34134412 0.65789855 0.87859738 0.88749129 0.84765625 0.44191635\n",
      " 0.5516274  0.73965156 0.73640925 0.55188876 0.44563833] @epoch 143\n",
      "Epoch 144: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0188 - val_loss: 0.0249\n",
      "Counter: 7, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 144: Updating Learning rate.. New value is 0.000003\n",
      "Epoch 145/151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - ETA: 0s - loss: 0.0188\n",
      "validate accuracy:\n",
      " [0.58782248 0.36155316 0.39498329 0.58322525 0.58075207 0.40738255\n",
      " 0.33985537 0.65891027 0.8794356  0.88777077 0.84809029 0.44135106\n",
      " 0.55373174 0.73979092 0.7340396  0.55006319 0.44422451] @epoch 144\n",
      "Epoch 145: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0188 - val_loss: 0.0249\n",
      "Counter: 0, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 146/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0188\n",
      "validate accuracy:\n",
      " [0.58828202 0.36070442 0.39548495 0.58279294 0.5814724  0.40889263\n",
      " 0.34219483 0.66093367 0.87915617 0.88791054 0.84852433 0.44022048\n",
      " 0.55359149 0.73993033 0.73557287 0.55090576 0.44422451] @epoch 145\n",
      "Epoch 146: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0188 - val_loss: 0.0249\n",
      "Counter: 1, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 147/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0188\n",
      "validate accuracy:\n",
      " [0.58792979 0.36028007 0.3958194  0.57947832 0.58161646 0.40838927\n",
      " 0.34262016 0.65862119 0.88041353 0.88749129 0.84837961 0.44050312\n",
      " 0.55373174 0.73951221 0.73362142 0.55146748 0.44493142] @epoch 146\n",
      "Epoch 147: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0188 - val_loss: 0.0249\n",
      "Counter: 2, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 148/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0188\n",
      "validate accuracy:\n",
      " [0.58849254 0.36155316 0.39682275 0.58437812 0.58305722 0.40704697\n",
      " 0.34028074 0.65847665 0.87901646 0.88777077 0.84809029 0.4416337\n",
      " 0.55387205 0.73881531 0.73640925 0.55202919 0.44662803] @epoch 147\n",
      "Epoch 148: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0188 - val_loss: 0.0249\n",
      "Counter: 3, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 149/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0188\n",
      "validate accuracy:\n",
      " [0.58821937 0.36049226 0.39615384 0.58149588 0.58219278 0.41006711\n",
      " 0.34113142 0.66050005 0.87999439 0.88707197 0.84809029 0.44022048\n",
      " 0.55471379 0.73979092 0.73445779 0.54992276 0.44521418] @epoch 148\n",
      "Epoch 149: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 123s 213ms/step - loss: 0.0188 - val_loss: 0.0249\n",
      "Counter: 4, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 150/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0188\n",
      "validate accuracy:\n",
      " [0.58831021 0.36091661 0.39531773 0.58207232 0.58248091 0.40838927\n",
      " 0.34070608 0.66021103 0.87957531 0.88735151 0.84852433 0.44064444\n",
      " 0.55373174 0.73965156 0.7352941  0.55132705 0.44676942] @epoch 149\n",
      "Epoch 150: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0188 - val_loss: 0.0249\n",
      "Counter: 5, Global: 0.5928569212555885, MyBest: 0.5928569212555885\n",
      "\n",
      "Epoch 151/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0188\n",
      "validate accuracy:\n",
      " [0.58783912 0.36091661 0.39515051 0.58048707 0.58262497 0.40838927\n",
      " 0.34113142 0.65948838 0.87999439 0.88707197 0.84780091 0.44078577\n",
      " 0.55331087 0.73825783 0.73445779 0.55034405 0.44521418] @epoch 150\n",
      "Epoch 151: val_acc did not improve from 0.593\n",
      "576/576 [==============================] - 123s 214ms/step - loss: 0.0188 - val_loss: 0.0249\n"
     ]
    }
   ],
   "source": [
    "\n",
    "net.compile(optimizer=optimizer, loss=weighted_mse_loss, metrics=[])\n",
    "#checkpointer = ModelCheckpoint(filepath=f'../cunet{nUNet}_{m}{n}_best.h5', verbose=1, monitor='val_loss', mode='auto', save_best_only=True)\n",
    "history = net.fit(train_images,train_hms,validation_data=(eval_images,eval_hms2),epochs=151, batch_size=32,shuffle=True,verbose=1, callbacks=[evalcallback,updateLR])#,use_multiprocessing=True,workers=20)#[checkpointer,updateLR])\n",
    "#np.savez_compressed(\"../history\",history)\n",
    "net.save_weights(f'../cunet{nUNet}_{m}{n}_last_sigmoidAdamQuasiDef3sx12_restartsig4.h5', overwrite=True)\n",
    "np.save('../history_sigmoidAdamQuasiDef3sx12_restartsig4.npy',history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnet.load_weights(\"../cunet2_6416_last_sigmoidAdamQuasiDef3sx12.h5\")\\noutput = net.predict(train_images)\\noutput = np.transpose(output,(0,3,1,2))\\nprint(accuracy(output,np.transpose(train_hms,(0,3,1,2))))\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "net.load_weights(\"../cunet2_6416_last_sigmoidAdamQuasiDef3sx12.h5\")\n",
    "output = net.predict(train_images)\n",
    "output = np.transpose(output,(0,3,1,2))\n",
    "print(accuracy(output,np.transpose(train_hms,(0,3,1,2))))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ho aumentato solo patience \n",
    "#Provato con dropout ma andato male"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
