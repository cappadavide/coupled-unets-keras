{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setGPU: Setting GPU to: 0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import setGPU\n",
    "import gc\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "160\n",
      "240\n",
      "320\n",
      "96\n",
      "192\n",
      "288\n",
      "384\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 128, 128, 64) 9408        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 128, 128, 64) 256         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 128, 128, 64) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 64, 64, 64)   0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 64, 64)   256         max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 64, 64)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 64)   4096        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 64, 64, 64)   256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 64, 64, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 64, 64, 16)   9216        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 64, 64, 80)   0           max_pooling2d[0][0]              \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 64, 64, 80)   320         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 64, 64, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 64, 64)   5120        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 64)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 64)   256         max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 64)   4096        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 64)   256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 16)   9216        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 80)   0           max_pooling2d_1[0][0]            \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 80)   320         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 80)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 64)   5120        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 64)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 64)   256         max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 64)   4096        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 64)   256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 64)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 16)   9216        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 16, 16, 80)   0           max_pooling2d_2[0][0]            \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 80)   320         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 80)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 64)   5120        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 64)     0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 8, 8, 64)     256         max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 8, 8, 64)     0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 8, 8, 64)     4096        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 8, 8, 64)     256         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 8, 8, 64)     0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 8, 8, 16)     9216        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 8, 8, 80)     0           max_pooling2d_3[0][0]            \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 8, 8, 80)     320         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 8, 8, 80)     0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 8, 8, 64)     5120        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 4, 4, 64)     0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 4, 4, 64)     256         max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 4, 4, 64)     0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 4, 4, 64)     4096        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 4, 4, 64)     256         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 4, 4, 64)     0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 8, 8, 80)     320         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 4, 4, 16)     9216        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 8, 8, 80)     0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 4, 4, 80)     0           max_pooling2d_4[0][0]            \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 8, 8, 64)     5120        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 8, 8, 80)     0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 8, 8, 144)    0           conv2d_16[0][0]                  \n",
      "                                                                 up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 8, 8, 144)    576         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 8, 8, 144)    0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 8, 8, 64)     9216        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 8, 8, 64)     256         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 8, 8, 64)     0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 80)   320         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 8, 8, 16)     9216        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 80)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 8, 8, 160)    0           concatenate_5[0][0]              \n",
      "                                                                 conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 64)   5120        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 16, 16, 160)  0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 16, 16, 224)  0           conv2d_12[0][0]                  \n",
      "                                                                 up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 16, 224)  896         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 224)  0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 16, 16, 64)   14336       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 16, 64)   256         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 64)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 80)   320         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 16, 16, 16)   9216        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 80)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 16, 16, 240)  0           concatenate_7[0][0]              \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 64)   5120        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 32, 32, 240)  0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 32, 32, 304)  0           conv2d_8[0][0]                   \n",
      "                                                                 up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 32, 32, 304)  1216        concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 32, 32, 304)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 32, 32, 64)   19456       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 32, 32, 64)   256         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 32, 32, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 64, 64, 80)   320         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 32, 32, 16)   9216        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 64, 64, 80)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 32, 32, 320)  0           concatenate_9[0][0]              \n",
      "                                                                 conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 64)   5120        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 64, 64, 320)  0           concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 64, 64, 384)  0           conv2d_4[0][0]                   \n",
      "                                                                 up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 64, 64, 384)  1536        concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 64, 64, 384)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 64, 64, 64)   24576       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 64, 64, 64)   256         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 64, 64, 64)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 64, 64, 16)   9216        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 64, 64, 400)  0           concatenate_11[0][0]             \n",
      "                                                                 conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 64, 64, 464)  0           max_pooling2d[0][0]              \n",
      "                                                                 concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 64, 64, 464)  1856        concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 64, 64, 464)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 64, 64, 64)   29696       activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 64, 64, 80)   0           conv2d_31[0][0]                  \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 64, 64, 80)   320         concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 64, 64, 80)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 64, 64, 64)   5120        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 64, 64, 64)   256         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 64, 64, 64)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 64, 64, 16)   9216        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 64, 64, 96)   0           concatenate_14[0][0]             \n",
      "                                                                 conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 64, 64, 96)   384         concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 64, 64, 96)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 64, 64, 64)   6144        activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 32, 32, 64)   0           conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 32, 32, 80)   0           max_pooling2d_5[0][0]            \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 32, 32, 80)   320         concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 32, 32, 80)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 32, 32, 64)   5120        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 32, 32, 64)   256         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 32, 32, 64)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 32, 32, 16)   9216        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 32, 32, 96)   0           concatenate_16[0][0]             \n",
      "                                                                 conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 32, 32, 96)   384         concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 32, 32, 96)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 32, 32, 64)   6144        activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 16, 16, 64)   0           conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 16, 16, 80)   0           max_pooling2d_6[0][0]            \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 16, 16, 80)   320         concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 16, 16, 80)   0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 16, 16, 64)   5120        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 16, 16, 64)   256         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 16, 16, 64)   0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 16, 16, 16)   9216        activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 16, 16, 96)   0           concatenate_18[0][0]             \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 16, 16, 96)   384         concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 16, 16, 96)   0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 16, 16, 64)   6144        activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 8, 8, 64)     0           conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 8, 8, 80)     0           max_pooling2d_7[0][0]            \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 8, 8, 80)     320         concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 8, 8, 80)     0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 8, 8, 64)     5120        activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 8, 8, 64)     256         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 8, 8, 64)     0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 8, 8, 16)     9216        activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 8, 8, 96)     0           concatenate_20[0][0]             \n",
      "                                                                 conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 8, 8, 96)     384         concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 8, 8, 96)     0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 8, 8, 64)     6144        activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 4, 4, 64)     0           conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 4, 4, 80)     0           max_pooling2d_8[0][0]            \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 4, 4, 80)     320         concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 4, 4, 80)     0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 4, 4, 64)     5120        activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 4, 4, 64)     256         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 4, 4, 64)     0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 8, 8, 96)     384         concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 4, 4, 16)     9216        activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 8, 8, 96)     0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 4, 4, 96)     0           concatenate_22[0][0]             \n",
      "                                                                 conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 8, 8, 64)     6144        activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 8, 8, 96)     0           concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 8, 8, 176)    0           conv2d_47[0][0]                  \n",
      "                                                                 up_sampling2d_4[0][0]            \n",
      "                                                                 conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 8, 8, 176)    704         concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 8, 8, 176)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 8, 8, 64)     11264       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 8, 8, 64)     256         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 8, 8, 64)     0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 16, 16, 96)   384         concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 8, 8, 16)     9216        activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 16, 16, 96)   0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 8, 8, 192)    0           concatenate_24[0][0]             \n",
      "                                                                 conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 16, 16, 64)   6144        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 16, 16, 192)  0           concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 16, 16, 272)  0           conv2d_43[0][0]                  \n",
      "                                                                 up_sampling2d_5[0][0]            \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 16, 16, 272)  1088        concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 16, 16, 272)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 16, 16, 64)   17408       activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 16, 16, 64)   256         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 16, 16, 64)   0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 32, 32, 96)   384         concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 16, 16, 16)   9216        activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 32, 32, 96)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 16, 16, 288)  0           concatenate_26[0][0]             \n",
      "                                                                 conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 32, 32, 64)   6144        activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2D)  (None, 32, 32, 288)  0           concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 32, 32, 368)  0           conv2d_39[0][0]                  \n",
      "                                                                 up_sampling2d_6[0][0]            \n",
      "                                                                 conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 32, 32, 368)  1472        concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 32, 32, 368)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 32, 32, 64)   23552       activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 32, 32, 64)   256         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 32, 32, 64)   0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 64, 64, 96)   384         concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 32, 32, 16)   9216        activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 64, 64, 96)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 32, 32, 384)  0           concatenate_28[0][0]             \n",
      "                                                                 conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 64, 64, 64)   6144        activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2D)  (None, 64, 64, 384)  0           concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 64, 64, 464)  0           conv2d_35[0][0]                  \n",
      "                                                                 up_sampling2d_7[0][0]            \n",
      "                                                                 conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 64, 64, 464)  1856        concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 64, 64, 464)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 64, 64, 64)   29696       activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 64, 64, 64)   256         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 64, 64, 64)   0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 64, 64, 16)   9216        activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 64, 64, 480)  0           concatenate_30[0][0]             \n",
      "                                                                 conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 64, 64, 480)  1920        concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 64, 64, 480)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 64, 64, 16)   7680        activation_62[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 524,864\n",
      "Trainable params: 511,616\n",
      "Non-trainable params: 13,248\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Definizione Modello\n",
    "def getUnit1(layerPrec, filters, kernel_size = (1, 1), activation='relu', kernel_initializer='he_normal'):\n",
    "  l = BatchNormalization()(layerPrec)\n",
    "  l = Activation('relu')(l)\n",
    "  l = Conv2D(filters, kernel_size, kernel_initializer=kernel_initializer, padding='same',use_bias=False)(l)\n",
    "  return l\n",
    "\n",
    "def getUnit2(layerPrec, filters, kernel_size = (3, 3), activation='relu', kernel_initializer='he_normal'):\n",
    "  l = BatchNormalization()(layerPrec)\n",
    "  l = Activation('relu')(l)\n",
    "  l = Conv2D(filters, kernel_size, kernel_initializer=kernel_initializer, padding='same',use_bias=False)(l)\n",
    "  return l\n",
    "\n",
    "def getDownBlock(layerPrec,m,n,indexBlock):\n",
    "  l = getUnit1(layerPrec,4*n)\n",
    "  l = getUnit2(l,n)\n",
    "  nets[\"layers\"][f\"down{indexBlock}\"].append(l)\n",
    "\n",
    "  concat = Concatenate()([layerPrec,l])\n",
    "  l = getUnit1(concat,m)\n",
    "  maxPooling = MaxPool2D(padding='same')(l)\n",
    "  return maxPooling, getUnit1(concat,m)\n",
    "\n",
    "def getUpBlock(layerPrec,skipConn,m,n,indexBlock,upLayers=[]):\n",
    "  l = getUnit1(layerPrec,m)\n",
    "  l = UpSampling2D()(layerPrec)\n",
    "  concat = Concatenate()([skipConn,l]+upLayers)\n",
    "  l = getUnit1(concat,4*n)\n",
    "  l = getUnit2(l,n)\n",
    "  nets[\"layers\"][f\"up{indexBlock}\"].append(l)\n",
    "  concat = Concatenate()([concat,l])\n",
    "  return concat\n",
    "\n",
    "def getUNet(input,m,n,indexUNet,nUNet, nBlocks):\n",
    "  layerPrec = input\n",
    "  listSkipConn = []\n",
    "\n",
    "  if indexUNet != 0:\n",
    "    layerPrec = nets[f\"unet{indexUNet-1}\"]\n",
    "    #layerPrec = Concatenate()([input,layerPrec]) #l'abbiamo fatto giù con l'if dopo l'up\n",
    "    layerPrec = getUnit1(layerPrec,m)\n",
    "\n",
    "  # down\n",
    "  for i in range(nBlocks):\n",
    "    if nets[\"layers\"][f\"down{i}\"]:\n",
    "        layerPrec = Concatenate()([layerPrec]+nets[\"layers\"][f\"down{i}\"])\n",
    "    layerPrec, skipConn = getDownBlock(layerPrec,m,n,i)\n",
    "    listSkipConn.append(skipConn)\n",
    "\n",
    "  # bottle neck\n",
    "  if nets[\"layers\"][f\"bn\"]:\n",
    "      layerPrec = Concatenate()([layerPrec]+nets[\"layers\"][f\"bn\"])\n",
    "\n",
    "  l = getUnit1(layerPrec,4*n)\n",
    "  l = getUnit2(l,n)\n",
    "  nets[\"layers\"][\"bn\"].append(l)\n",
    "  concat = Concatenate()([layerPrec,l])\n",
    "\n",
    "  # up\n",
    "  layerPrec = concat\n",
    "  for i in range(nBlocks):\n",
    "    layerPrec = getUpBlock(layerPrec,listSkipConn[-(i+1)],m,n,i,upLayers=nets[\"layers\"][f\"up{i}\"])\n",
    "\n",
    "\n",
    "  if indexUNet != nUNet - 1:\n",
    "    l = Concatenate()([input,layerPrec])\n",
    "  else:\n",
    "    l = getUnit1(layerPrec,16,activation=\"sigmoid\") #era linear\n",
    "\n",
    "  return l\n",
    "\n",
    "def trasformationInput(x, filters):\n",
    "  #x = BatchNormalization()(x)\n",
    "  #x = Activation('relu')(x)\n",
    "  #x = Conv2D(filters, kernel_size=(7,7), strides=(2,2), kernel_initializer=\"he_normal\", padding='same',use_bias=False)(x)\n",
    "  #maxPooling = MaxPool2D(padding='same')(x)\n",
    "  \n",
    "  #x = Conv2D(filters*2, kernel_size=(5,5), strides=(1,1), kernel_initializer=\"he_normal\", padding='same',use_bias=False)(x)\n",
    "  #x = BatchNormalization()(x)\n",
    "  #x = Activation('relu')(x)\n",
    "  x = Conv2D(filters, kernel_size=(7,7), strides=(1,1), kernel_initializer=\"he_normal\", padding='same',use_bias=False)(x) #era 3x3\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = MaxPool2D(padding='same')(x)\n",
    "\n",
    "  return x#maxPooling\n",
    "\n",
    "def getCUNet(shape,m,n,nUNet,nBlocks):\n",
    "  for i in range(nUNet):\n",
    "    nets[f\"unet{i}\"] = None\n",
    "\n",
    "  for j in range(nBlocks):\n",
    "    nets[\"layers\"][f\"down{j}\"] = []\n",
    "    nets[\"layers\"][f\"up{j}\"] = []\n",
    "    \n",
    "  input = Input(shape=shape)\n",
    "  \n",
    "  t_input = trasformationInput(input,m) # per le heatmap da 64x64\n",
    "\n",
    "  for i in range(nUNet):\n",
    "    nets[f\"unet{i}\"] = getUNet(t_input,m,n,i,nUNet,nBlocks)\n",
    "\n",
    "  output = nets[f\"unet{nUNet-1}\"]\n",
    "  return Model(inputs=input, outputs=output)\n",
    "\n",
    "nets = {}\n",
    "nets[\"layers\"] = {}\n",
    "nets[\"layers\"][\"bn\"] = []\n",
    "shape = (128,128,3)\n",
    "m = 64\n",
    "n = 16\n",
    "nUNet = 2\n",
    "nBlocks = 4\n",
    "#mirrored_strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\n",
    "#with mirrored_strategy.scope():\n",
    "net = getCUNet(shape,m,n,nUNet,nBlocks)\n",
    "\n",
    "layers = net.layers\n",
    "#print(layers[57].input)\n",
    "for i in range(len(layers)):\n",
    "    if isinstance(layers[i], tf.python.keras.layers.convolutional.Conv2D):\n",
    "        if isinstance(layers[i-1].input,list):\n",
    "            in_chan = 0\n",
    "            for k in layers[i-1].input:\n",
    "                in_chan = in_chan + k.shape[-1]\n",
    "            print(in_chan)\n",
    "        else:\n",
    "            in_chan = layers[i-1].input.shape[-1]\n",
    "            \n",
    "        n1 = layers[i].kernel_size[0] * layers[i].kernel_size[1] * in_chan\n",
    "        stdv = 1/math.sqrt(n1)\n",
    "        layers[i].kernel_initializer = tf.keras.initializers.RandomUniform(minval=-stdv, maxval=stdv)\n",
    "\n",
    "net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_preds(heatmaps):\n",
    "    \"\"\"Get keypoint predictions from score maps.\n",
    "    Note:\n",
    "        batch_size: N\n",
    "        num_keypoints: K\n",
    "        heatmap height: H\n",
    "        heatmap width: W\n",
    "    Args:\n",
    "        heatmaps (np.ndarray[N, K, H, W]): model predicted heatmaps.\n",
    "    Returns:\n",
    "        tuple: A tuple containing aggregated results.\n",
    "        - preds (np.ndarray[N, K, 2]): Predicted keypoint location.  \n",
    "        - maxvals (np.ndarray[N, K, 1]): Scores (confidence) of the keypoints. non lo restituiamo\n",
    "    \"\"\"\n",
    "    #assert isinstance(heatmaps, np.ndarray), ('heatmaps should be numpy.ndarray')\n",
    "    #assert heatmaps.ndim == 4, 'batch_images should be 4-ndim'\n",
    "\n",
    "    N, K, _, W = heatmaps.shape\n",
    "    heatmaps_reshaped = heatmaps.reshape((N, K, -1))\n",
    "    idx = np.argmax(heatmaps_reshaped, 2).reshape((N, K, 1))\n",
    "    maxvals = np.amax(heatmaps_reshaped, 2).reshape((N, K, 1))\n",
    "\n",
    "    preds = np.tile(idx, (1, 1, 2)).astype(np.float32)\n",
    "    preds[:, :, 0] = preds[:, :, 0] % W\n",
    "    preds[:, :, 1] = preds[:, :, 1] // W\n",
    "\n",
    "    preds = np.where(np.tile(maxvals, (1, 1, 2)) > 0.0, preds, -1)\n",
    "    return preds#, maxvals\n",
    "\n",
    "def calc_dists(preds, target, normalize, use_zero=False):\n",
    "    preds = preds.astype(np.float32)\n",
    "    target = target.astype(np.float32)\n",
    "    normalize = normalize.astype(np.float32)\n",
    "    dists = np.zeros((preds.shape[1], preds.shape[0]))\n",
    "    if use_zero:\n",
    "        boundary = 0\n",
    "    else:\n",
    "        boundary = 1\n",
    "    for n in range(preds.shape[0]):\n",
    "        for c in range(preds.shape[1]):\n",
    "            if target[n,c,0] > boundary and target[n, c, 1] > boundary:\n",
    "                dists[c, n] = np.linalg.norm((preds[n,c,:]- target[n,c,:])/normalize[n]) # axis ricavato da solo\n",
    "            else:\n",
    "                dists[c, n] = -1\n",
    "    return dists\n",
    "\n",
    "def dist_acc(dists, thr=0.5):\n",
    "\n",
    "  #Return percentage below threshold while ignoring values with a -1\n",
    "\n",
    "  if (dists!=-1).sum() > 0:\n",
    "\n",
    "    return ((dists<=thr) == (dists!=-1)).sum().astype(np.float32) / (dists!=-1).sum().astype(np.float32)\n",
    "\n",
    "  else:\n",
    "\n",
    "    return -1\n",
    "\n",
    "def accuracy(output, target, thr=0.5):\n",
    "  ''' Calculate accuracy according to PCK, but uses ground truth heatmap rather than x,y locations\n",
    "        First value to be returned is average accuracy across 'idxs', followed by individual accuracies\n",
    "    '''\n",
    "  #output = output.numpy()\n",
    "  #print(output.__class__)\n",
    "  #target = target.numpy()\n",
    "\n",
    "  idkp = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "  preds = get_max_preds(output)\n",
    "  gts = get_max_preds(target)\n",
    "  norm = np.ones(preds.shape[0])*output.shape[3]/10\n",
    "\n",
    "  dists = calc_dists(preds, gts, norm)\n",
    "\n",
    "  acc = np.zeros(len(idkp)+1)\n",
    "  avg_acc = 0\n",
    "  cnt = 0\n",
    "\n",
    "  for i in range(len(idkp)):\n",
    "    acc[i+1] = dist_acc(dists[idkp[i]])\n",
    "    if acc[i+1] >= 0: \n",
    "      avg_acc = avg_acc + acc[i+1]\n",
    "      cnt += 1\n",
    "            \n",
    "  if cnt != 0:  \n",
    "    acc[0] = avg_acc / cnt\n",
    "\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.misc\n",
    "import cv2\n",
    "\n",
    "# =============================================================================\n",
    "# General image processing functions\n",
    "# =============================================================================\n",
    "\n",
    "def get_transform(center, scale, res, rot=0):\n",
    "    # Generate transformation matrix\n",
    "    h = 200 * scale\n",
    "    t = np.zeros((3, 3))\n",
    "    t[0, 0] = float(res[1]) / h\n",
    "    t[1, 1] = float(res[0]) / h\n",
    "    t[0, 2] = res[1] * (-float(center[0]) / h + .5)\n",
    "    t[1, 2] = res[0] * (-float(center[1]) / h + .5)\n",
    "    t[2, 2] = 1\n",
    "    if not rot == 0:\n",
    "        rot = -rot # To match direction of rotation from cropping\n",
    "        rot_mat = np.zeros((3,3))\n",
    "        rot_rad = rot * np.pi / 180\n",
    "        sn,cs = np.sin(rot_rad), np.cos(rot_rad)\n",
    "        rot_mat[0,:2] = [cs, -sn]\n",
    "        rot_mat[1,:2] = [sn, cs]\n",
    "        rot_mat[2,2] = 1\n",
    "        # Need to rotate around center\n",
    "        t_mat = np.eye(3)\n",
    "        t_mat[0,2] = -res[1]/2\n",
    "        t_mat[1,2] = -res[0]/2\n",
    "        t_inv = t_mat.copy()\n",
    "        t_inv[:2,2] *= -1\n",
    "        t = np.dot(t_inv,np.dot(rot_mat,np.dot(t_mat,t)))\n",
    "    return t\n",
    "\n",
    "def transform(pt, center, scale, res, invert=0, rot=0):\n",
    "    # Transform pixel location to different reference\n",
    "    t = get_transform(center, scale, res, rot=rot)\n",
    "    if invert:\n",
    "        t = np.linalg.inv(t)\n",
    "    new_pt = np.array([pt[0], pt[1], 1.]).T\n",
    "    new_pt = np.dot(t, new_pt)\n",
    "    return new_pt[:2].astype(int)\n",
    "\n",
    "def crop(img, center, scale, res, rot=0):\n",
    "    # Upper left point\n",
    "    ul = np.array(transform([0, 0], center, scale, res, invert=1))\n",
    "    # Bottom right point\n",
    "    br = np.array(transform(res, center, scale, res, invert=1))\n",
    "\n",
    "    new_shape = [br[1] - ul[1], br[0] - ul[0]]\n",
    "    if len(img.shape) > 2:\n",
    "        new_shape += [img.shape[2]]\n",
    "    new_img = np.zeros(new_shape)\n",
    "\n",
    "    # Range to fill new array\n",
    "    new_x = max(0, -ul[0]), min(br[0], len(img[0])) - ul[0]\n",
    "    new_y = max(0, -ul[1]), min(br[1], len(img)) - ul[1]\n",
    "    # Range to sample from original image\n",
    "    old_x = max(0, ul[0]), min(len(img[0]), br[0])\n",
    "    old_y = max(0, ul[1]), min(len(img), br[1])\n",
    "    new_img[new_y[0]:new_y[1], new_x[0]:new_x[1]] = img[old_y[0]:old_y[1], old_x[0]:old_x[1]]\n",
    "\n",
    "    return cv2.resize(new_img, res)\n",
    "\n",
    "def inv_mat(mat):\n",
    "    ans = np.linalg.pinv(np.array(mat).tolist() + [[0,0,1]])\n",
    "    return ans[:2]\n",
    "\n",
    "def kpt_affine(kpt, mat):\n",
    "    kpt = np.array(kpt)\n",
    "    shape = kpt.shape\n",
    "    kpt = kpt.reshape(-1, 2)\n",
    "    return np.dot( np.concatenate((kpt, kpt[:, 0:1]*0+1), axis = 1), mat.T ).reshape(shape)\n",
    "\n",
    "\n",
    "def resize(im, res):\n",
    "    return np.array([cv2.resize(im[i],res) for i in range(im.shape[0])])\n",
    "\n",
    "def generateHeatmap(keypoints,output_res,num_parts):\n",
    "    #Init\n",
    "    sigma = output_res/64\n",
    "    size = 6*sigma+3\n",
    "    x = np.arange(0, size, 1, float) #crea un array composto da nove 1.0 vettore 1-D (9,)\n",
    "    y = x[:, np.newaxis] #Vettore 2-D (9,1)\n",
    "    x0, y0 = 3*sigma + 1, 3*sigma + 1 #vedi giù a tutto\n",
    "    g = np.exp(- ((x - x0) ** 2 + (y - y0) ** 2) / (2 * sigma ** 2))\n",
    "    #Generation\n",
    "    hms = np.zeros(shape = (num_parts, output_res, output_res), dtype = np.float32) #crea vettore (16,64,64), cioè 16 heatmaps nere\n",
    "    for p in keypoints:\n",
    "        for idx, pt in enumerate(p): #ottiene id + [x,y] di ogni keypoint\n",
    "            if pt[0] > 0: \n",
    "                x, y = int(pt[0]), int(pt[1])\n",
    "                if x<0 or y<0 or x>=output_res or y>=output_res: #se succede questo, rimane heatmap idx-esima  tutta a 0\n",
    "                    continue\n",
    "                ul = int(x - 3*sigma - 1), int(y - 3*sigma - 1)\n",
    "                br = int(x + 3*sigma + 2), int(y + 3*sigma + 2)\n",
    "\n",
    "                c,d = max(0, -ul[0]), min(br[0], output_res) - ul[0]\n",
    "                a,b = max(0, -ul[1]), min(br[1], output_res) - ul[1]\n",
    "\n",
    "                cc,dd = max(0, ul[0]), min(br[0], output_res)\n",
    "                aa,bb = max(0, ul[1]), min(br[1], output_res)\n",
    "                hms[idx, aa:bb,cc:dd] = np.maximum(hms[idx, aa:bb,cc:dd], g[a:b,c:d])\n",
    "    return hms\n",
    "def getImgHms(img,c,s,keypoints,inp_res=(256,256),out_res=(64,64)):\n",
    "    cropped = crop(img,c,s,inp_res)\n",
    "    orig_keypoints = []\n",
    "    for i in keypoints:\n",
    "        orig_keypoints.append(np.array([i[\"x\"],i[\"y\"]]))\n",
    "    orig_keypoints = np.array(orig_keypoints).reshape((1,16,2))\n",
    "    kptmp = np.copy(orig_keypoints)\n",
    "    for i in range(orig_keypoints.shape[1]):\n",
    "        if orig_keypoints[0,i,0] > 0:\n",
    "            orig_keypoints[0,i,:2] = transform(orig_keypoints[0,i,:2], c, s, inp_res)\n",
    "    keypoints = np.copy(orig_keypoints)\n",
    "    h, w = cropped.shape[0:2]\n",
    "    center = np.array((w/2,h/2))\n",
    "    scale = max(h,w)/200\n",
    "    aug_rot = (np.random.random()*2-1)*30\n",
    "    aug_scale = np.random.random() * (1.25-0.75)+0.75\n",
    "    scale *= aug_scale\n",
    "\n",
    "    mat_mask = get_transform(center, scale, out_res, aug_rot)[:2]\n",
    "    mat = get_transform(center, scale, inp_res, aug_rot)[:2]\n",
    "    inp = cv2.warpAffine(cropped, mat, inp_res).astype(np.float32)/255\n",
    "\n",
    "    keypoints[:,:,0:2] = kpt_affine(keypoints[:,:,0:2], mat_mask) \n",
    "    \n",
    "    #print('\\n')\n",
    "\n",
    "\n",
    "    #Flip 50% probability\n",
    "    if np.random.randint(2) == 0:\n",
    "        inp = inp[:, ::-1]\n",
    "        keypoints = keypoints[:, flipped_parts['mpii']]\n",
    "        keypoints[:, :, 0] = 64 - keypoints[:, :, 0]\n",
    "        orig_keypoints = orig_keypoints[:, flipped_parts['mpii']]\n",
    "        orig_keypoints[:, :, 0] = 256 - orig_keypoints[:, :, 0]\n",
    "\n",
    "    ## set keypoints to 0 when were not visible initially (so heatmap all 0s)\n",
    "        for i in range(np.shape(orig_keypoints)[1]):\n",
    "            if kptmp[0,i,0] == 0 and kptmp[0,i,1] == 0:\n",
    "                keypoints[0,i,0] = 0\n",
    "                keypoints[0,i,1] = 0\n",
    "                orig_keypoints[0,i,0] = 0\n",
    "                orig_keypoints[0,i,1] = 0\n",
    "\n",
    "    heatmaps = generateHeatmap(keypoints,out_res[0],16)\n",
    "    return inp,heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.RMSprop(\n",
    "    learning_rate=6.7e-3, rho=0.99, momentum=0.0, epsilon=1e-08\n",
    ")\n",
    "#optimizer = tf.keras.optimizers.Adam(learning_rate=6.7e-3)\n",
    "\n",
    "\n",
    "def heatmapLoss(y_true,y_pred):\n",
    "    l = tf.math.square((y_pred - y_true))\n",
    "    l = tf.reduce_mean(l,axis=3)\n",
    "    l = tf.reduce_mean(l,axis=2)\n",
    "    l = tf.reduce_mean(l,axis=1)\n",
    "    return l\n",
    "\n",
    "def euclidean_loss(y_true, y_pred):\n",
    "    return K.sqrt(K.sum(K.square(y_true - y_pred)))\n",
    "\n",
    "def dice(y_true,y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + 1) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1 - dice(y_true, y_pred)\n",
    "\n",
    "def weighted_mse_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    apply weights on heatmap mse loss to only pick valid keypoint heatmap\n",
    "    since y_true would be gt_heatmap with shape\n",
    "    (batch_size, heatmap_size[0], heatmap_size[1], num_keypoints)\n",
    "    we sum up the heatmap for each keypoints and check. Sum for invalid\n",
    "    keypoint would be 0, so we can get a keypoint weights tensor with shape\n",
    "    (batch_size, 1, 1, num_keypoints)\n",
    "    and multiply to loss\n",
    "    \"\"\"\n",
    "    heatmap_sum = K.sum(K.sum(y_true, axis=1, keepdims=True), axis=2, keepdims=True)\n",
    "\n",
    "    # keypoint_weights shape: (batch_size, 1, 1, num_keypoints), with\n",
    "    # valid_keypoint = 1.0, invalid_keypoint = 0.0\n",
    "    keypoint_weights = 1.0 - K.cast(K.equal(heatmap_sum, 0.0), 'float32')\n",
    "\n",
    "    return K.sqrt(K.mean(K.square((y_true - y_pred) * keypoint_weights)))\n",
    "\n",
    "def smooth_l1_loss(y_true, y_pred):\n",
    "    diff = K.abs(y_true - y_pred)\n",
    "    less_than_one = K.cast(K.less(diff, 1.0), 'float32')\n",
    "    loss = (less_than_one * 0.5 * diff**2) + (1 - less_than_one) * (diff - 0.5)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "parts = {'mpii':['rank', 'rkne', 'rhip',\n",
    "                 'lhip', 'lkne', 'lank',\n",
    "                 'pelv', 'thrx', 'neck', 'head',\n",
    "                 'rwri', 'relb', 'rsho',\n",
    "                 'lsho', 'lelb', 'lwri']}\n",
    "\n",
    "flipped_parts = {'mpii':[5, 4, 3, 2, 1, 0, 6, 7, 8, 9, 15, 14, 13, 12, 11, 10]}\n",
    "\n",
    "part_pairs = {'mpii':[[0, 5], [1, 4], [2, 3], [6], [7], [8], [9], [10, 15], [11, 14], [12, 13]]}\n",
    "\n",
    "pair_names = {'mpii':['ankle', 'knee', 'hip', 'pelvis', 'thorax', 'neck', 'head', 'wrist', 'elbow', 'shoulder']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import imageio\n",
    "\n",
    "class Dataset(tf.keras.utils.Sequence):\n",
    "    #Costruttore\n",
    "    def __init__(self,json_path,batch_size,input_shape=(256,256,3),output_shape=(64,64,16),train=True,dataset_name=\"MPII\"):\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "        self.batch_size = batch_size\n",
    "        f = open(json_path)\n",
    "        self.dataset = json.load(f)\n",
    "        if dataset_name == \"MPII\":\n",
    "            self.dataset = self.dataset[\"dataset\"][\"MPII\"][\"people\"]\n",
    "        if train:\n",
    "            self.dataset = self.dataset[:-7221]\n",
    "        self.batch_images = np.zeros(shape=((self.batch_size,)+(self.input_shape)), dtype=np.float32)\n",
    "        self.batch_heatmaps = np.zeros(shape=((self.batch_size,)+(self.output_shape)), dtype=np.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset) // self.batch_size\n",
    "    \n",
    "    def __getitem__(self,i):\n",
    "        for n, annotation in enumerate(self.dataset[i*self.batch_size:(i+1)*self.batch_size]):\n",
    "            #sample_index = i*self.batch_size + n\n",
    "            image, gt_heatmap = self.extract_imgs_hms(annotation)\n",
    "            gt_heatmap = np.transpose(gt_heatmap,(1,2,0))\n",
    "            self.batch_images[n,:,:,:] = image\n",
    "            self.batch_heatmaps[n, :, :, :] = gt_heatmap#gt_heatmap.reshape((self.output_shape))\n",
    "            \n",
    "        return self.batch_images, self.batch_heatmaps\n",
    "#getImgHms(img,c,s,keypoints,inp_res=(256,256),out_res=(64,64)):\n",
    "    \n",
    "    def extract_imgs_hms(self,annotation):\n",
    "        inp_res = self.input_shape[0:2]\n",
    "        out_res = self.output_shape[0:2]\n",
    "        img = imageio.imread(f\"../images_mpii/{annotation['filepath']}\")\n",
    "        c = [annotation[\"objpos\"][\"x\"],annotation[\"objpos\"][\"y\"]]\n",
    "        s = annotation[\"scale\"]\n",
    "        keypoints = annotation[\"keypoints\"]\n",
    "        cropped = crop(img,c,s,inp_res)\n",
    "        \n",
    "        orig_keypoints = []\n",
    "        for i in keypoints:\n",
    "            orig_keypoints.append(np.array([i[\"x\"],i[\"y\"]]))\n",
    "        orig_keypoints = np.array(orig_keypoints).reshape((1,16,2))\n",
    "        kptmp = np.copy(orig_keypoints)\n",
    "        for i in range(orig_keypoints.shape[1]):\n",
    "            if orig_keypoints[0,i,0] > 0:\n",
    "                orig_keypoints[0,i,:2] = transform(orig_keypoints[0,i,:2], c, s, inp_res)\n",
    "        keypoints = np.copy(orig_keypoints)\n",
    "        h, w = cropped.shape[0:2]\n",
    "        center = np.array((w/2,h/2))\n",
    "        scale = max(h,w)/200\n",
    "        aug_rot = (np.random.random()*2-1)*30\n",
    "        aug_scale = np.random.random() * (1.25-0.75)+0.75\n",
    "        scale *= aug_scale\n",
    "\n",
    "        mat_mask = get_transform(center, scale, out_res, aug_rot)[:2]\n",
    "        mat = get_transform(center, scale, inp_res, aug_rot)[:2]\n",
    "        inp = cv2.warpAffine(cropped, mat, inp_res).astype(np.float32)/255\n",
    "\n",
    "        keypoints[:,:,0:2] = kpt_affine(keypoints[:,:,0:2], mat_mask) \n",
    "\n",
    "        #print('\\n')\n",
    "\n",
    "\n",
    "        #Flip 50% probability\n",
    "        if np.random.randint(2) == 0:\n",
    "            inp = inp[:, ::-1]\n",
    "            keypoints = keypoints[:, flipped_parts['mpii']]\n",
    "            keypoints[:, :, 0] = 64 - keypoints[:, :, 0]\n",
    "            orig_keypoints = orig_keypoints[:, flipped_parts['mpii']]\n",
    "            orig_keypoints[:, :, 0] = 256 - orig_keypoints[:, :, 0]\n",
    "\n",
    "        ## set keypoints to 0 when were not visible initially (so heatmap all 0s)\n",
    "            for i in range(np.shape(orig_keypoints)[1]):\n",
    "                if kptmp[0,i,0] == 0 and kptmp[0,i,1] == 0:\n",
    "                    keypoints[0,i,0] = 0\n",
    "                    keypoints[0,i,1] = 0\n",
    "                    orig_keypoints[0,i,0] = 0\n",
    "                    orig_keypoints[0,i,1] = 0\n",
    "\n",
    "        heatmaps = generateHeatmap(keypoints,out_res[0],16)\n",
    "        return inp,heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import imageio\n",
    "\n",
    "class Dataset2(tf.keras.utils.Sequence):\n",
    "    #Costruttore\n",
    "    def __init__(self,json_path,batch_size,input_shape=(256,256,3),output_shape=(64,64,16),train=True,dataset_name=\"MPII\"):\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "        self.batch_size = batch_size\n",
    "        self.images = np.load(\"../imgs_mpii.npz\")['arr_0']\n",
    "        self.hms = np.load(\"../hms_mpii.npz\")['arr_0']\n",
    "        self.hms = self.hms.reshape((self.hms.shape[0],64,64,16))\n",
    "        if dataset_name == \"MPII\":\n",
    "            self.images = self.images[\"dataset\"][\"MPII\"][\"people\"]\n",
    "        if train:\n",
    "            self.images = self.images[:-8665]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset) // self.batch_size\n",
    "    \n",
    "    def __getitem__(self,i):\n",
    "        return self.images[i*self.batch_size:(i+1)*self.batch_size], self.hms[i*self.batch_size:(i+1)*self.batch_size]\n",
    "#getImgHms(img,c,s,keypoints,inp_res=(256,256),out_res=(64,64)):\n",
    "    \n",
    "    def extract_imgs_hms(self,annotation):\n",
    "        inp_res = self.input_shape[0:2]\n",
    "        out_res = self.output_shape[0:2]\n",
    "        img = imageio.imread(f\"../images_mpii/{annotation['filepath']}\")\n",
    "        c = [annotation[\"objpos\"][\"x\"],annotation[\"objpos\"][\"y\"]]\n",
    "        s = annotation[\"scale\"]\n",
    "        keypoints = annotation[\"keypoints\"]\n",
    "        cropped = crop(img,c,s,inp_res)\n",
    "        \n",
    "        orig_keypoints = []\n",
    "        for i in keypoints:\n",
    "            orig_keypoints.append(np.array([i[\"x\"],i[\"y\"]]))\n",
    "        orig_keypoints = np.array(orig_keypoints).reshape((1,16,2))\n",
    "        kptmp = np.copy(orig_keypoints)\n",
    "        for i in range(orig_keypoints.shape[1]):\n",
    "            if orig_keypoints[0,i,0] > 0:\n",
    "                orig_keypoints[0,i,:2] = transform(orig_keypoints[0,i,:2], c, s, inp_res)\n",
    "        keypoints = np.copy(orig_keypoints)\n",
    "        h, w = cropped.shape[0:2]\n",
    "        center = np.array((w/2,h/2))\n",
    "        scale = max(h,w)/200\n",
    "        aug_rot = (np.random.random()*2-1)*30\n",
    "        aug_scale = np.random.random() * (1.25-0.75)+0.75\n",
    "        scale *= aug_scale\n",
    "\n",
    "        mat_mask = get_transform(center, scale, out_res, aug_rot)[:2]\n",
    "        mat = get_transform(center, scale, inp_res, aug_rot)[:2]\n",
    "        inp = cv2.warpAffine(cropped, mat, inp_res).astype(np.float32)/255\n",
    "\n",
    "        keypoints[:,:,0:2] = kpt_affine(keypoints[:,:,0:2], mat_mask) \n",
    "\n",
    "        #print('\\n')\n",
    "\n",
    "\n",
    "        #Flip 50% probability\n",
    "        if np.random.randint(2) == 0:\n",
    "            inp = inp[:, ::-1]\n",
    "            keypoints = keypoints[:, flipped_parts['mpii']]\n",
    "            keypoints[:, :, 0] = 64 - keypoints[:, :, 0]\n",
    "            orig_keypoints = orig_keypoints[:, flipped_parts['mpii']]\n",
    "            orig_keypoints[:, :, 0] = 256 - orig_keypoints[:, :, 0]\n",
    "\n",
    "        ## set keypoints to 0 when were not visible initially (so heatmap all 0s)\n",
    "            for i in range(np.shape(orig_keypoints)[1]):\n",
    "                if kptmp[0,i,0] == 0 and kptmp[0,i,1] == 0:\n",
    "                    keypoints[0,i,0] = 0\n",
    "                    keypoints[0,i,1] = 0\n",
    "                    orig_keypoints[0,i,0] = 0\n",
    "                    orig_keypoints[0,i,1] = 0\n",
    "\n",
    "        heatmaps = generateHeatmap(keypoints,out_res[0],16)\n",
    "        return inp,heatmaps\n",
    "####################################################################àà\n",
    "\n",
    "\n",
    "def get_normalize(input_shape):\n",
    "    \"\"\"\n",
    "    rescale keypoint distance normalize coefficient\n",
    "    based on input shape, used for PCK evaluation\n",
    "    NOTE: 6.4 is standard normalize coefficient under\n",
    "          input shape (256,256)\n",
    "    # Arguments\n",
    "        input_shape: input image shape as (height, width)\n",
    "    # Returns\n",
    "        scale: normalize coefficient\n",
    "    \"\"\"\n",
    "    #assert input_shape[0] == input_shape[1], 'only support square input shape.'\n",
    "\n",
    "    # use averaged scale factor for non square input shape\n",
    "    scale = float((input_shape[0] + input_shape[1]) / 2) / 256.0\n",
    "\n",
    "    return 6.4*scale\n",
    "\n",
    "global_best_acc = 0.0\n",
    "\n",
    "class EvalCallBack(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, model_input_shape, fileName, imgs,hms):\n",
    "        self.normalize = get_normalize(model_input_shape)\n",
    "        self.model_input_shape = model_input_shape\n",
    "        self.best_acc = 0.0\n",
    "        self.fileName = fileName\n",
    "        self.eval_images = imgs#np.load(\"../imgs_val_mpii128.npz\")['arr_0']\n",
    "        self.eval_hms = hms#np.load(\"../hms_val_mpii128.npz\")['arr_0']\n",
    "        self.listAcc = []\n",
    "        #self.eval_hms = np.reshape(self.eval_hms,(self.eval_hms.shape[0],64,64,16))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        global global_best_acc\n",
    "        output = self.model.predict(self.eval_images)\n",
    "        #output = output.reshape( (output.shape[0],)+(16,64,64) )\n",
    "        output = np.transpose(output,(0,3,1,2))\n",
    "        val_acc = accuracy(output,self.eval_hms)\n",
    "        self.listAcc.append(val_acc[0])\n",
    "        print('\\nvalidate accuracy:\\n', val_acc, '@epoch', epoch)\n",
    "        f = open(self.fileName, \"a\")\n",
    "        if val_acc[0] > self.best_acc:\n",
    "            # Save best accuray value and model checkpoint\n",
    "            #checkpoint_dir = os.path.join(self.log_dir, 'ep{epoch:03d}-loss{loss:.3f}-val_acc{val_acc:.3f}.h5'.format(epoch=(epoch+1), loss=logs.get('loss'), val_acc=val_acc))\n",
    "            #self.model.save(f\"../modelsave/ep{epoch}_acc{val_acc[0]}.h5\")\n",
    "            self.model.save_weights(f\"../cunet{nUNet}_{m}{n}_best_sigmoidAdamQuasiDef3sx12_restartsig3.h5\")\n",
    "            print('Epoch {epoch:03d}: val_acc improved from {best_acc:.3f} to {val_acc:.3f}'.format(epoch=epoch+1, best_acc=self.best_acc, val_acc=val_acc[0]))# checkpoint_dir=checkpoint_dir))\n",
    "            message = 'Epoch {epoch:03d}: val_acc improved from {best_acc:.3f} to {val_acc:.3f}. Train loss is {loss:.3f}\\n'.format(epoch=epoch+1, best_acc=self.best_acc, val_acc=val_acc[0],loss=logs.get('loss'))\n",
    "            self.best_acc = val_acc[0]\n",
    "            global_best_acc = val_acc[0]\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            message = 'Epoch {epoch:03d}: val_acc did not improve from {best_acc:.3f}. Train loss is {loss:.3f}\\n'.format(epoch=epoch+1, best_acc=self.best_acc,loss=logs.get('loss'))\n",
    "            print('Epoch {epoch:03d}: val_acc did not improve from {best_acc:.3f}'.format(epoch=epoch+1, best_acc=self.best_acc))\n",
    "        f.write(message)\n",
    "        f.close()\n",
    "        if epoch == 150:\n",
    "            np.savez_compressed(f'../cunet{nUNet}_{m}{n}_best_sigmoidAdamQuasiDef3sx12_restartsig3_accs', self.listAcc)\n",
    "        gc.collect()\n",
    "        \n",
    "        \n",
    "class CustomLearningRateScheduler(tf.keras.callbacks.Callback):\n",
    "    \"\"\"Learning rate scheduler which sets the learning rate according to schedule.\n",
    "\n",
    "  Arguments:\n",
    "      schedule: a function that takes an epoch index\n",
    "          (integer, indexed from 0) and current learning rate\n",
    "          as inputs and returns a new learning rate as output (float).\n",
    "  \"\"\"\n",
    "\n",
    "    def __init__(self, patience,factor,fileName=None):\n",
    "        super(CustomLearningRateScheduler, self).__init__()\n",
    "        self.counter = 0\n",
    "        self.patience = patience\n",
    "        self.fileName = fileName\n",
    "        self.factor = factor\n",
    "        self.best_acc = 0.0\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        global global_best_acc\n",
    "        print(f\"Counter: {self.counter}, Global: {global_best_acc}, MyBest: {self.best_acc}\\n\")\n",
    "        if not hasattr(self.model.optimizer, \"lr\"):\n",
    "            raise ValueError('Optimizer must have a \"lr\" attribute.')\n",
    "        # Get the current learning rate from model's optimizer.\n",
    "        lr = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n",
    "        # Call schedule function to get the scheduled learning rate.\n",
    "        scheduled_lr = self.schedule(epoch, lr)\n",
    "        # Set the value back to the optimizer before this epoch starts\n",
    "        tf.keras.backend.set_value(self.model.optimizer.lr, scheduled_lr)\n",
    "    \n",
    "    def schedule(self,epoch,lr):\n",
    "        global global_best_acc\n",
    "        if self.counter == self.patience:\n",
    "            self.counter = 0 \n",
    "            print(\"Epoch %03d: Updating Learning rate.. New value is %f\" % (epoch, lr*self.factor))\n",
    "            message = \"Epoch %03d: Updating Learning rate.. New value is %f\" % (epoch, lr*self.factor)\n",
    "            f = open(self.fileName, \"a\")\n",
    "            f.write(message)\n",
    "            f.close()\n",
    "            return lr*self.factor\n",
    "        if self.best_acc == global_best_acc:\n",
    "            self.counter = self.counter + 1\n",
    "        elif self.best_acc < global_best_acc:\n",
    "            self.counter = 0\n",
    "            self.best_acc = global_best_acc\n",
    "        return lr\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finito 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ndataset = Dataset(\"datasets.json\",32)\\n\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle \n",
    "with open('../train_imgssx12.pickle', 'rb') as handle:\n",
    "    train_images = pickle.load(handle)\n",
    "with open('../train_hmssx12.pickle', 'rb') as handle:\n",
    "    train_hms = pickle.load(handle)\n",
    "\n",
    "eval_images = np.load(\"../imgs_val_mpii128sx12.npz\")['arr_0']\n",
    "eval_hms = np.load(\"../hms_val_mpii128sx12.npz\")['arr_0']\n",
    "\n",
    "#train_images = np.load(\"../imgs_train_mpii128.npz\")['arr_0']\n",
    "#train_hms = np.load(\"../hms_train_mpii128.npz\")['arr_0']\n",
    "train_hms = np.transpose(train_hms,(0,2,3,1))#np.reshape(train_hms,(train_hms.shape[0],64,64,16))\n",
    "eval_hms2 = np.transpose(eval_hms,(0,2,3,1))\n",
    "print(\"Finito 1\")\n",
    "\"\"\"\n",
    "dataset = Dataset(\"datasets.json\",32)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finito 2\n"
     ]
    }
   ],
   "source": [
    "evalcallback = EvalCallBack((128,128),\"../sigmoidLayersAdamSchedulingQuasiDef3sx12_restartsig3.txt\",eval_images,eval_hms)\n",
    "updateLR = CustomLearningRateScheduler(7,0.2,fileName=\"../sigmoidLayersAdamSchedulingQuasiDef3sx12_restartsig3.txt\")\n",
    "print(\"Finito 2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter: 0, Global: 0.0, MyBest: 0.0\n",
      "\n",
      "Epoch 1/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0668WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0057s vs `on_test_batch_end` time: 0.0379s). Check your callbacks.\n",
      "\n",
      "validate accuracy:\n",
      " [0.02932805 0.         0.00384615 0.04424269 0.0151275  0.00083893\n",
      " 0.00021268 0.01401937 0.05350656 0.02334032 0.04239004 0.04352742\n",
      " 0.05723906 0.09212544 0.04028436 0.02808594 0.01046232] @epoch 0\n",
      "Epoch 001: val_acc improved from 0.000 to 0.029\n",
      "576/576 [==============================] - 121s 210ms/step - loss: 0.0668 - val_loss: 0.0265\n",
      "Counter: 1, Global: 0.02932804886404483, MyBest: 0.0\n",
      "\n",
      "Epoch 2/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0266\n",
      "validate accuracy:\n",
      " [0.06124741 0.04434543 0.04481605 0.12350482 0.11655381 0.02449664\n",
      " 0.03360272 0.14496315 0.06286673 0.10440251 0.03602431 0.04352742\n",
      " 0.00939955 0.07609756 0.04209646 0.01713243 0.05612894] @epoch 1\n",
      "Epoch 002: val_acc improved from 0.029 to 0.061\n",
      "576/576 [==============================] - 119s 206ms/step - loss: 0.0266 - val_loss: 0.0264\n",
      "Counter: 0, Global: 0.06124740821542218, MyBest: 0.02932804886404483\n",
      "\n",
      "Epoch 3/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0319\n",
      "validate accuracy:\n",
      " [0.07839157 0.028432   0.04949833 0.13892491 0.13096096 0.04161074\n",
      " 0.04296044 0.13513513 0.09695446 0.10412299 0.05020254 0.07377049\n",
      " 0.07014591 0.06341463 0.09478673 0.05940177 0.07394316] @epoch 2\n",
      "Epoch 003: val_acc improved from 0.061 to 0.078\n",
      "576/576 [==============================] - 119s 207ms/step - loss: 0.0319 - val_loss: 0.0268\n",
      "Counter: 0, Global: 0.0783915740903467, MyBest: 0.06124740821542218\n",
      "\n",
      "Epoch 4/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0264\n",
      "validate accuracy:\n",
      " [0.22896192 0.06980692 0.1167224  0.28937888 0.28454113 0.1181208\n",
      " 0.05380689 0.34860528 0.45613301 0.50621945 0.21108218 0.19460148\n",
      " 0.18069585 0.23540069 0.21968219 0.19182698 0.18676658] @epoch 3\n",
      "Epoch 004: val_acc improved from 0.078 to 0.229\n",
      "576/576 [==============================] - 120s 208ms/step - loss: 0.0264 - val_loss: 0.0262\n",
      "Counter: 0, Global: 0.22896191873587668, MyBest: 0.0783915740903467\n",
      "\n",
      "Epoch 5/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0259\n",
      "validate accuracy:\n",
      " [0.25622436 0.08656906 0.12742475 0.31719267 0.30125341 0.11996644\n",
      " 0.09081242 0.41797948 0.41436157 0.53053808 0.32002315 0.21834369\n",
      " 0.24242425 0.23233449 0.25606355 0.22721528 0.19708751] @epoch 4\n",
      "Epoch 005: val_acc improved from 0.229 to 0.256\n",
      "576/576 [==============================] - 120s 208ms/step - loss: 0.0259 - val_loss: 0.0260\n",
      "Counter: 0, Global: 0.25622436264529824, MyBest: 0.22896191873587668\n",
      "\n",
      "Epoch 6/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0257\n",
      "validate accuracy:\n",
      " [0.2998831  0.11033312 0.14715719 0.33030695 0.31335542 0.13389261\n",
      " 0.09251382 0.44775257 0.57921207 0.6668064  0.38570601 0.17750141\n",
      " 0.24172278 0.39275262 0.32980207 0.24996489 0.19934964] @epoch 5\n",
      "Epoch 006: val_acc improved from 0.256 to 0.300\n",
      "576/576 [==============================] - 120s 208ms/step - loss: 0.0257 - val_loss: 0.0257\n",
      "Counter: 0, Global: 0.299883097410202, MyBest: 0.25622436264529824\n",
      "\n",
      "Epoch 7/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0254\n",
      "validate accuracy:\n",
      " [0.35675545 0.1379164  0.16421404 0.3461594  0.31623685 0.14832215\n",
      " 0.09953211 0.50383002 0.67462981 0.74996507 0.60416669 0.22032222\n",
      " 0.25968012 0.50466901 0.48564261 0.27959555 0.21320514] @epoch 6\n",
      "Epoch 007: val_acc improved from 0.300 to 0.357\n",
      "576/576 [==============================] - 120s 208ms/step - loss: 0.0254 - val_loss: 0.0255\n",
      "Counter: 0, Global: 0.35675545036792755, MyBest: 0.299883097410202\n",
      "\n",
      "Epoch 8/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0251\n",
      "validate accuracy:\n",
      " [0.37175174 0.14937407 0.14648829 0.35120335 0.3377035  0.11996644\n",
      " 0.14738409 0.51250184 0.68846047 0.76324248 0.67896414 0.21424533\n",
      " 0.28030303 0.52682924 0.53275716 0.29939616 0.19920826] @epoch 7\n",
      "Epoch 008: val_acc improved from 0.357 to 0.372\n",
      "576/576 [==============================] - 120s 209ms/step - loss: 0.0251 - val_loss: 0.0252\n",
      "Counter: 0, Global: 0.371751741040498, MyBest: 0.35675545036792755\n",
      "\n",
      "Epoch 9/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0249\n",
      "validate accuracy:\n",
      " [0.40871267 0.15573944 0.13277592 0.39991352 0.39936608 0.14446309\n",
      " 0.13037005 0.51857203 0.72757751 0.79972047 0.7650463  0.28490672\n",
      " 0.37261504 0.54815328 0.54209644 0.33899733 0.27908948] @epoch 8\n",
      "Epoch 009: val_acc improved from 0.372 to 0.409\n",
      "576/576 [==============================] - 120s 208ms/step - loss: 0.0249 - val_loss: 0.0250\n",
      "Counter: 0, Global: 0.40871266834437847, MyBest: 0.371751741040498\n",
      "\n",
      "Epoch 10/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0247\n",
      "validate accuracy:\n",
      " [0.37541567 0.10205813 0.1416388  0.38665515 0.38553524 0.13271812\n",
      " 0.10697576 0.50758779 0.69977647 0.75136268 0.67216438 0.2741662\n",
      " 0.29391134 0.49365854 0.47783664 0.29953659 0.28106886] @epoch 9\n",
      "Epoch 010: val_acc did not improve from 0.409\n",
      "576/576 [==============================] - 120s 208ms/step - loss: 0.0247 - val_loss: 0.0253\n",
      "Counter: 0, Global: 0.40871266834437847, MyBest: 0.40871266834437847\n",
      "\n",
      "Epoch 11/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0246\n",
      "validate accuracy:\n",
      " [0.42782848 0.08338638 0.15150502 0.43147427 0.42746001 0.11510067\n",
      " 0.08996172 0.53114611 0.79561329 0.81229907 0.76866317 0.31613907\n",
      " 0.3684063  0.58425087 0.61639255 0.41244206 0.34101513] @epoch 10\n",
      "Epoch 011: val_acc improved from 0.409 to 0.428\n",
      "576/576 [==============================] - 120s 209ms/step - loss: 0.0246 - val_loss: 0.0248\n",
      "Counter: 1, Global: 0.427828480489552, MyBest: 0.40871266834437847\n",
      "\n",
      "Epoch 12/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0244\n",
      "validate accuracy:\n",
      " [0.43815019 0.14725228 0.16505016 0.45827928 0.46131682 0.13909397\n",
      " 0.14313059 0.56279808 0.80064261 0.81844866 0.78718174 0.30879027\n",
      " 0.38916948 0.57825786 0.54279339 0.3732622  0.33493567] @epoch 11\n",
      "Epoch 012: val_acc improved from 0.428 to 0.438\n",
      "576/576 [==============================] - 120s 209ms/step - loss: 0.0244 - val_loss: 0.0249\n",
      "Counter: 0, Global: 0.4381501907482743, MyBest: 0.427828480489552\n",
      "\n",
      "Epoch 13/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0243\n",
      "validate accuracy:\n",
      " [0.46373026 0.15658817 0.16822742 0.47326705 0.47140181 0.14312081\n",
      " 0.15440238 0.57378232 0.82215703 0.83018869 0.7890625  0.34412098\n",
      " 0.42999437 0.64139372 0.63200444 0.42760849 0.3623639 ] @epoch 12\n",
      "Epoch 013: val_acc improved from 0.438 to 0.464\n",
      "576/576 [==============================] - 120s 208ms/step - loss: 0.0243 - val_loss: 0.0246\n",
      "Counter: 0, Global: 0.4637302551418543, MyBest: 0.4381501907482743\n",
      "\n",
      "Epoch 14/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0242\n",
      "validate accuracy:\n",
      " [0.45920319 0.15022279 0.16505016 0.45366767 0.46996111 0.14060403\n",
      " 0.13504891 0.57681745 0.79659122 0.82250172 0.77835649 0.38482192\n",
      " 0.45272166 0.6062718  0.59785336 0.43856201 0.37819877] @epoch 13\n",
      "Epoch 014: val_acc did not improve from 0.464\n",
      "576/576 [==============================] - 119s 207ms/step - loss: 0.0242 - val_loss: 0.0248\n",
      "Counter: 0, Global: 0.4637302551418543, MyBest: 0.4637302551418543\n",
      "\n",
      "Epoch 15/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0241\n",
      "validate accuracy:\n",
      " [0.44407    0.14640357 0.15752508 0.42498919 0.44244346 0.13691275\n",
      " 0.11420672 0.5795635  0.8147527  0.83941299 0.79166669 0.34836066\n",
      " 0.39295736 0.59623694 0.579593   0.40219072 0.33790472] @epoch 14\n",
      "Epoch 015: val_acc did not improve from 0.464\n",
      "576/576 [==============================] - 120s 208ms/step - loss: 0.0241 - val_loss: 0.0248\n",
      "Counter: 1, Global: 0.4637302551418543, MyBest: 0.4637302551418543\n",
      "\n",
      "Epoch 16/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0240\n",
      "validate accuracy:\n",
      " [0.470831   0.13409717 0.14180602 0.46678194 0.47716469 0.11291946\n",
      " 0.13292216 0.56511056 0.82299525 0.84626138 0.80656826 0.40149802\n",
      " 0.46801347 0.64961672 0.62698632 0.47577587 0.40477875] @epoch 15\n",
      "Epoch 016: val_acc improved from 0.464 to 0.471\n",
      "576/576 [==============================] - 120s 208ms/step - loss: 0.0240 - val_loss: 0.0245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter: 2, Global: 0.4708310030400753, MyBest: 0.4637302551418543\n",
      "\n",
      "Epoch 17/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0239\n",
      "validate accuracy:\n",
      " [0.46738482 0.13261193 0.14414716 0.48393139 0.47385103 0.10637584\n",
      " 0.10676308 0.57407141 0.81880414 0.82935011 0.80251735 0.4130865\n",
      " 0.46450618 0.63986063 0.62656814 0.46060947 0.40110278] @epoch 16\n",
      "Epoch 017: val_acc did not improve from 0.471\n",
      "576/576 [==============================] - 120s 208ms/step - loss: 0.0239 - val_loss: 0.0246\n",
      "Counter: 0, Global: 0.4708310030400753, MyBest: 0.4708310030400753\n",
      "\n",
      "Epoch 18/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0239\n",
      "validate accuracy:\n",
      " [0.45160668 0.16083175 0.16722408 0.49473989 0.47918168 0.12197986\n",
      " 0.10995321 0.58693451 0.78806931 0.80712789 0.7505787  0.3350763\n",
      " 0.44514591 0.61365855 0.55087817 0.46383935 0.35048777] @epoch 17\n",
      "Epoch 018: val_acc did not improve from 0.471\n",
      "576/576 [==============================] - 120s 208ms/step - loss: 0.0239 - val_loss: 0.0247\n",
      "Counter: 1, Global: 0.4708310030400753, MyBest: 0.4708310030400753\n",
      "\n",
      "Epoch 19/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0238\n",
      "validate accuracy:\n",
      " [0.47329961 0.15276894 0.14431438 0.49128115 0.49013111 0.14161074\n",
      " 0.13462356 0.5837549  0.82215703 0.83731657 0.80164933 0.39584512\n",
      " 0.44809204 0.6394425  0.64399219 0.44909424 0.39671993] @epoch 18\n",
      "Epoch 019: val_acc improved from 0.471 to 0.473\n",
      "576/576 [==============================] - 120s 208ms/step - loss: 0.0238 - val_loss: 0.0246\n",
      "Counter: 2, Global: 0.4732996076345444, MyBest: 0.4708310030400753\n",
      "\n",
      "Epoch 20/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0237\n",
      "validate accuracy:\n",
      " [0.47954087 0.13579461 0.16989967 0.51030409 0.49963981 0.1204698\n",
      " 0.12930667 0.59748518 0.82662755 0.83661777 0.81409144 0.40531373\n",
      " 0.47053874 0.64278746 0.63646501 0.47437158 0.40294075] @epoch 19\n",
      "Epoch 020: val_acc improved from 0.473 to 0.480\n",
      "576/576 [==============================] - 120s 209ms/step - loss: 0.0237 - val_loss: 0.0245\n",
      "Counter: 0, Global: 0.47954086726531386, MyBest: 0.4732996076345444\n",
      "\n",
      "Epoch 21/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0237\n",
      "validate accuracy:\n",
      " [0.39796673 0.10608954 0.11638796 0.42657444 0.42299381 0.10738255\n",
      " 0.09315185 0.53562653 0.72883487 0.74032146 0.69632524 0.32589033\n",
      " 0.37079126 0.51651567 0.50738782 0.38533914 0.28785524] @epoch 20\n",
      "Epoch 021: val_acc did not improve from 0.480\n",
      "576/576 [==============================] - 120s 208ms/step - loss: 0.0237 - val_loss: 0.0252\n",
      "Counter: 0, Global: 0.47954086726531386, MyBest: 0.47954086726531386\n",
      "\n",
      "Epoch 22/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0236\n",
      "validate accuracy:\n",
      " [0.49006192 0.11797157 0.14397994 0.52385068 0.52528453 0.11610738\n",
      " 0.1056997  0.61078191 0.84911984 0.85758209 0.82291669 0.41040134\n",
      " 0.50448936 0.67888504 0.66155559 0.4966999  0.41566521] @epoch 21\n",
      "Epoch 022: val_acc improved from 0.480 to 0.490\n",
      "576/576 [==============================] - 120s 208ms/step - loss: 0.0236 - val_loss: 0.0244\n",
      "Counter: 1, Global: 0.4900619233958423, MyBest: 0.47954086726531386\n",
      "\n",
      "Epoch 23/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0235\n",
      "validate accuracy:\n",
      " [0.46207636 0.14067473 0.15635452 0.47643754 0.46707967 0.12734899\n",
      " 0.13653764 0.59286022 0.81433362 0.83060795 0.80685765 0.36998305\n",
      " 0.42157689 0.60822302 0.60189575 0.44474092 0.39770961] @epoch 23\n",
      "Epoch 024: val_acc did not improve from 0.490\n",
      "576/576 [==============================] - 120s 208ms/step - loss: 0.0235 - val_loss: 0.0246\n",
      "Counter: 1, Global: 0.4900619233958423, MyBest: 0.4900619233958423\n",
      "\n",
      "Epoch 25/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0235\n",
      "validate accuracy:\n",
      " [0.49807892 0.14364524 0.15702341 0.52716529 0.53133553 0.11342282\n",
      " 0.13228413 0.62465674 0.83948028 0.85366875 0.84346062 0.43075183\n",
      " 0.50196409 0.66675961 0.66699189 0.50119364 0.43545878] @epoch 24\n",
      "Epoch 025: val_acc improved from 0.490 to 0.498\n",
      "576/576 [==============================] - 120s 209ms/step - loss: 0.0235 - val_loss: 0.0243\n",
      "Counter: 2, Global: 0.49807891668751836, MyBest: 0.4900619233958423\n",
      "\n",
      "Epoch 26/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0234\n",
      "validate accuracy:\n",
      " [0.46961106 0.1317632  0.13862877 0.48321083 0.46318975 0.10855705\n",
      " 0.11590812 0.59632897 0.82313496 0.84248775 0.83188659 0.40248728\n",
      " 0.47039843 0.6220209  0.62322277 0.46496278 0.39558885] @epoch 25\n",
      "Epoch 026: val_acc did not improve from 0.498\n",
      "576/576 [==============================] - 120s 208ms/step - loss: 0.0234 - val_loss: 0.0245\n",
      "Counter: 0, Global: 0.49807891668751836, MyBest: 0.49807891668751836\n",
      "\n",
      "Epoch 27/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0234\n",
      "validate accuracy:\n",
      " [0.49255245 0.14025037 0.13177258 0.51952732 0.52168274 0.12416107\n",
      " 0.13441089 0.61873102 0.83892149 0.85730261 0.83087385 0.42170718\n",
      " 0.4914422  0.65533102 0.66016167 0.49655947 0.43800369] @epoch 26\n",
      "Epoch 027: val_acc did not improve from 0.498\n",
      "576/576 [==============================] - 120s 208ms/step - loss: 0.0234 - val_loss: 0.0243\n",
      "Counter: 1, Global: 0.49807891668751836, MyBest: 0.49807891668751836\n",
      "\n",
      "Epoch 28/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0233\n",
      "validate accuracy:\n",
      " [0.4292164  0.12603438 0.14314382 0.45698228 0.44878259 0.12634228\n",
      " 0.11846023 0.55311459 0.77395922 0.77246678 0.73987269 0.33013001\n",
      " 0.40137485 0.58216029 0.5650962  0.39474794 0.33479428] @epoch 27\n",
      "Epoch 028: val_acc did not improve from 0.498\n",
      "576/576 [==============================] - 120s 208ms/step - loss: 0.0233 - val_loss: 0.0249\n",
      "Counter: 2, Global: 0.49807891668751836, MyBest: 0.49807891668751836\n",
      "\n",
      "Epoch 29/151\n",
      "297/576 [==============>...............] - ETA: 46s - loss: 0.0233"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - ETA: 0s - loss: 0.0228\n",
      "validate accuracy:\n",
      " [0.52344759 0.32527053 0.14214046 0.51837438 0.52629304 0.1318792\n",
      " 0.31305829 0.61555135 0.86281085 0.86568832 0.83376735 0.44799322\n",
      " 0.50238496 0.6783275  0.67033732 0.5061087  0.43517601] @epoch 37\n",
      "Epoch 038: val_acc did not improve from 0.529\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0228 - val_loss: 0.0241\n",
      "Counter: 0, Global: 0.5289528770372272, MyBest: 0.5289528770372272\n",
      "\n",
      "Epoch 39/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0228\n",
      "validate accuracy:\n",
      " [0.53178267 0.31657118 0.1645485  0.53120047 0.5314796  0.14463088\n",
      " 0.31731179 0.61959821 0.8658843  0.87658978 0.8425926  0.45845109\n",
      " 0.51122332 0.68641114 0.68190688 0.50105321 0.4590697 ] @epoch 38\n",
      "Epoch 039: val_acc improved from 0.529 to 0.532\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0228 - val_loss: 0.0242\n",
      "Counter: 1, Global: 0.5317826652899384, MyBest: 0.5289528770372272\n",
      "\n",
      "Epoch 40/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0227\n",
      "validate accuracy:\n",
      " [0.53039947 0.31423721 0.15200669 0.52932698 0.52773374 0.125\n",
      " 0.32730752 0.61482871 0.87063426 0.87561148 0.83622688 0.45293951\n",
      " 0.51346803 0.68989545 0.67549485 0.51200676 0.4696734 ] @epoch 39\n",
      "Epoch 040: val_acc did not improve from 0.532\n",
      "576/576 [==============================] - 122s 211ms/step - loss: 0.0227 - val_loss: 0.0241\n",
      "Counter: 0, Global: 0.5317826652899384, MyBest: 0.5317826652899384\n",
      "\n",
      "Epoch 41/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0227\n",
      "validate accuracy:\n",
      " [0.51894631 0.31402504 0.15735786 0.52572417 0.52413195 0.14010067\n",
      " 0.30901745 0.60514528 0.85554624 0.86191475 0.82913774 0.42071792\n",
      " 0.49691358 0.68390244 0.66727072 0.49501476 0.41722041] @epoch 40\n",
      "Epoch 041: val_acc did not improve from 0.532\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0227 - val_loss: 0.0243\n",
      "Counter: 1, Global: 0.5317826652899384, MyBest: 0.5317826652899384\n",
      "\n",
      "Epoch 42/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0227\n",
      "validate accuracy:\n",
      " [0.51695569 0.3133885  0.16254181 0.51405102 0.50525862 0.11996644\n",
      " 0.32433006 0.59589535 0.85638446 0.86149544 0.82103586 0.42001131\n",
      " 0.50224465 0.67540067 0.65597993 0.49978936 0.4435176 ] @epoch 41\n",
      "Epoch 042: val_acc did not improve from 0.532\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0227 - val_loss: 0.0243\n",
      "Counter: 2, Global: 0.5317826652899384, MyBest: 0.5317826652899384\n",
      "\n",
      "Epoch 43/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0226\n",
      "validate accuracy:\n",
      " [0.51321668 0.29577765 0.13996656 0.51015997 0.51793689 0.10167785\n",
      " 0.29902169 0.59806329 0.85568595 0.86317259 0.83203125 0.42693612\n",
      " 0.49368685 0.67512196 0.67075551 0.49361044 0.43786231] @epoch 42\n",
      "Epoch 043: val_acc did not improve from 0.532\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0226 - val_loss: 0.0243\n",
      "Counter: 3, Global: 0.5317826652899384, MyBest: 0.5317826652899384\n",
      "\n",
      "Epoch 44/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0226\n",
      "validate accuracy:\n",
      " [0.53705199 0.31996605 0.15719064 0.53451508 0.53277624 0.14144295\n",
      " 0.33368778 0.62407863 0.87077397 0.87631029 0.84186924 0.46184283\n",
      " 0.53409094 0.70006967 0.68385839 0.51916867 0.46119043] @epoch 43\n",
      "Epoch 044: val_acc improved from 0.532 to 0.537\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0226 - val_loss: 0.0242\n",
      "Counter: 4, Global: 0.5370519878342748, MyBest: 0.5317826652899384\n",
      "\n",
      "Epoch 45/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0226\n",
      "validate accuracy:\n",
      " [0.53289303 0.31423721 0.15033445 0.54517943 0.53580177 0.11291946\n",
      " 0.32475543 0.62783641 0.87203127 0.87896574 0.83333331 0.45576596\n",
      " 0.52020204 0.69491291 0.68553108 0.51018113 0.46430087] @epoch 44\n",
      "Epoch 045: val_acc did not improve from 0.537\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0226 - val_loss: 0.0241\n",
      "Counter: 0, Global: 0.5370519878342748, MyBest: 0.5370519878342748\n",
      "\n",
      "Epoch 46/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0226\n",
      "validate accuracy:\n",
      " [0.53388551 0.32102695 0.15317726 0.52572417 0.52571678 0.12432886\n",
      " 0.33262441 0.60485619 0.87259012 0.87938505 0.84418404 0.46240813\n",
      " 0.52875984 0.69588852 0.67884028 0.51944953 0.47320798] @epoch 45\n",
      "Epoch 046: val_acc did not improve from 0.537\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0226 - val_loss: 0.0241\n",
      "Counter: 1, Global: 0.5370519878342748, MyBest: 0.5370519878342748\n",
      "\n",
      "Epoch 47/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0225\n",
      "validate accuracy:\n",
      " [0.53474725 0.32378528 0.1528428  0.54604411 0.53796285 0.13087249\n",
      " 0.31497234 0.62740278 0.87091368 0.87547171 0.8342014  0.45717919\n",
      " 0.52398992 0.69700348 0.69013101 0.51411319 0.4590697 ] @epoch 46\n",
      "Epoch 047: val_acc did not improve from 0.537\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0225 - val_loss: 0.0242\n",
      "Counter: 2, Global: 0.5370519878342748, MyBest: 0.5370519878342748\n",
      "\n",
      "Epoch 48/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0225\n",
      "validate accuracy:\n",
      " [0.53554652 0.32887757 0.15301004 0.53249747 0.53796285 0.13171141\n",
      " 0.32709485 0.62754732 0.87538421 0.88064289 0.84418404 0.45816845\n",
      " 0.52721661 0.69031358 0.67479789 0.5242241  0.455111  ] @epoch 47\n",
      "Epoch 048: val_acc did not improve from 0.537\n",
      "576/576 [==============================] - 122s 211ms/step - loss: 0.0225 - val_loss: 0.0241\n",
      "Counter: 3, Global: 0.5370519878342748, MyBest: 0.5370519878342748\n",
      "\n",
      "Epoch 49/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0225\n",
      "validate accuracy:\n",
      " [0.53663575 0.32187566 0.1528428  0.54604411 0.53508139 0.12114094\n",
      " 0.33113569 0.62769186 0.8693769  0.87645006 0.84736687 0.46113622\n",
      " 0.52342874 0.69783974 0.69040984 0.51425362 0.47009754] @epoch 48\n",
      "Epoch 049: val_acc did not improve from 0.537\n",
      "576/576 [==============================] - 122s 211ms/step - loss: 0.0225 - val_loss: 0.0243\n",
      "Counter: 4, Global: 0.5370519878342748, MyBest: 0.5370519878342748\n",
      "\n",
      "Epoch 50/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0225\n",
      "validate accuracy:\n",
      " [0.52789247 0.3216635  0.14749163 0.51059228 0.5185132  0.13305369\n",
      " 0.31646109 0.61858648 0.86742109 0.87197763 0.84577549 0.45096099\n",
      " 0.5140292  0.68864113 0.67159188 0.51214719 0.45737311] @epoch 49\n",
      "Epoch 050: val_acc did not improve from 0.537\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0225 - val_loss: 0.0242\n",
      "Counter: 5, Global: 0.5370519878342748, MyBest: 0.5370519878342748\n",
      "\n",
      "Epoch 51/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0224\n",
      "validate accuracy:\n",
      " [0.52636822 0.31678337 0.13511705 0.5330739  0.52557266 0.12919463\n",
      " 0.30710337 0.6054343  0.86364907 0.86806428 0.83492476 0.44954777\n",
      " 0.51711559 0.68250871 0.68357956 0.51284933 0.45737311] @epoch 50\n",
      "Epoch 051: val_acc did not improve from 0.537\n",
      "576/576 [==============================] - 122s 211ms/step - loss: 0.0224 - val_loss: 0.0242\n",
      "Counter: 6, Global: 0.5370519878342748, MyBest: 0.5370519878342748\n",
      "\n",
      "Epoch 52/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0224\n",
      "validate accuracy:\n",
      " [0.506267   0.30914491 0.15602006 0.48162559 0.48998705 0.13909397\n",
      " 0.30625266 0.59690708 0.84255379 0.85129279 0.8185764  0.42227247\n",
      " 0.48007858 0.65463412 0.63953161 0.4853251  0.42697582] @epoch 51\n",
      "Epoch 052: val_acc did not improve from 0.537\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0224 - val_loss: 0.0245\n",
      "Counter: 7, Global: 0.5370519878342748, MyBest: 0.5370519878342748\n",
      "\n",
      "Epoch 052: Updating Learning rate.. New value is 0.001340\n",
      "Epoch 53/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0220\n",
      "validate accuracy:\n",
      " [0.54720638 0.32887757 0.16538462 0.54301775 0.54934448 0.13607383\n",
      " 0.32581881 0.63303947 0.87789887 0.88413697 0.85069442 0.48106274\n",
      " 0.54264873 0.70954704 0.70072484 0.53756493 0.489467  ] @epoch 52\n",
      "Epoch 053: val_acc improved from 0.537 to 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0220 - val_loss: 0.0241\n",
      "Counter: 0, Global: 0.5472063794732094, MyBest: 0.5370519878342748\n",
      "\n",
      "Epoch 54/151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - ETA: 0s - loss: 0.0219\n",
      "validate accuracy:\n",
      " [0.54468492 0.33503076 0.16772576 0.54532355 0.54718339 0.12483221\n",
      " 0.3283709  0.63058245 0.8723107  0.88148147 0.84678817 0.47752967\n",
      " 0.53956228 0.70480835 0.69626427 0.53321165 0.48395306] @epoch 53\n",
      "Epoch 054: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 211ms/step - loss: 0.0219 - val_loss: 0.0242\n",
      "Counter: 0, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 55/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0219\n",
      "validate accuracy:\n",
      " [0.54509562 0.33206025 0.16371237 0.54589999 0.53464919 0.13674496\n",
      " 0.32964694 0.63202775 0.87678123 0.88343817 0.84620947 0.47569248\n",
      " 0.54026377 0.70703834 0.69737941 0.53419465 0.48579103] @epoch 54\n",
      "Epoch 055: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 211ms/step - loss: 0.0219 - val_loss: 0.0241\n",
      "Counter: 1, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 56/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0218\n",
      "validate accuracy:\n",
      " [0.54341727 0.33057502 0.16204013 0.54748523 0.53853911 0.13171141\n",
      " 0.33028498 0.62798095 0.87678123 0.88371766 0.84360534 0.47555116\n",
      " 0.53409094 0.70369339 0.69821578 0.52942002 0.48098403] @epoch 55\n",
      "Epoch 056: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0218 - val_loss: 0.0241\n",
      "Counter: 2, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 57/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0218\n",
      "validate accuracy:\n",
      " [0.54472659 0.33821344 0.16755852 0.54604411 0.53450513 0.13489933\n",
      " 0.32943428 0.63029337 0.87314892 0.88148147 0.84823495 0.47795364\n",
      " 0.54068464 0.70452964 0.6977976  0.52675188 0.48409444] @epoch 56\n",
      "Epoch 057: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 211ms/step - loss: 0.0218 - val_loss: 0.0242\n",
      "Counter: 3, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 58/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0218\n",
      "validate accuracy:\n",
      " [0.5428664  0.32930192 0.16137123 0.53898257 0.54257309 0.12281879\n",
      " 0.32666951 0.63246131 0.87538421 0.8832984  0.84375    0.47314867\n",
      " 0.53731763 0.70411152 0.69974911 0.52998173 0.48494273] @epoch 57\n",
      "Epoch 058: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0218 - val_loss: 0.0242\n",
      "Counter: 4, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 59/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0218\n",
      "validate accuracy:\n",
      " [0.54169517 0.33460641 0.16839465 0.540856   0.53738654 0.13338926\n",
      " 0.32773289 0.62552392 0.87538421 0.88092244 0.84910303 0.46537593\n",
      " 0.53254771 0.69867593 0.69403404 0.52998173 0.47320798] @epoch 58\n",
      "Epoch 059: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 211ms/step - loss: 0.0218 - val_loss: 0.0242\n",
      "Counter: 5, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 60/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0217\n",
      "validate accuracy:\n",
      " [0.54342636 0.32930192 0.16304348 0.53941488 0.5356577  0.13926175\n",
      " 0.33007231 0.63029337 0.87412685 0.88162124 0.8425926  0.47724703\n",
      " 0.54012346 0.70257843 0.6941734  0.53517765 0.48013574] @epoch 59\n",
      "Epoch 060: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 211ms/step - loss: 0.0217 - val_loss: 0.0242\n",
      "Counter: 6, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 61/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0217\n",
      "validate accuracy:\n",
      " [0.54175432 0.33396986 0.16588628 0.53782964 0.53234404 0.13171141\n",
      " 0.33113569 0.62841451 0.87007546 0.88106221 0.84447336 0.47215942\n",
      " 0.53535354 0.70369339 0.69138557 0.52815616 0.4804185 ] @epoch 60\n",
      "Epoch 061: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 121s 211ms/step - loss: 0.0217 - val_loss: 0.0242\n",
      "Counter: 7, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 061: Updating Learning rate.. New value is 0.000268\n",
      "Epoch 62/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0216\n",
      "validate accuracy:\n",
      " [0.54263049 0.33121154 0.16287625 0.54345006 0.53666621 0.12013423\n",
      " 0.32985964 0.62566847 0.8730092  0.8813417  0.84693289 0.47696438\n",
      " 0.53942198 0.70759583 0.69528854 0.5308243  0.48084265] @epoch 61\n",
      "Epoch 062: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 211ms/step - loss: 0.0216 - val_loss: 0.0242\n",
      "Counter: 0, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 63/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0216\n",
      "validate accuracy:\n",
      " [0.54332069 0.32908976 0.16588628 0.54301775 0.53666621 0.13171141\n",
      " 0.32900894 0.62855905 0.87314892 0.88176101 0.84577549 0.47244206\n",
      " 0.5409652  0.70536584 0.69765818 0.53321165 0.47886327] @epoch 62\n",
      "Epoch 063: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 211ms/step - loss: 0.0216 - val_loss: 0.0243\n",
      "Counter: 1, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 64/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0216\n",
      "validate accuracy:\n",
      " [0.54160988 0.33142373 0.16204013 0.5427295  0.53508139 0.11963087\n",
      " 0.32794556 0.62682468 0.87314892 0.87994409 0.84620947 0.47131148\n",
      " 0.53858024 0.70773518 0.69445217 0.53040302 0.47829774] @epoch 63\n",
      "Epoch 064: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 211ms/step - loss: 0.0216 - val_loss: 0.0243\n",
      "Counter: 2, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 65/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0216\n",
      "validate accuracy:\n",
      " [0.54270672 0.33121154 0.16170569 0.5372532  0.53666621 0.13540268\n",
      " 0.33049765 0.62812543 0.8730092  0.87938505 0.84418404 0.47286603\n",
      " 0.53928173 0.70675957 0.69361585 0.53377336 0.47957021] @epoch 64\n",
      "Epoch 065: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0216 - val_loss: 0.0243\n",
      "Counter: 3, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 66/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0216\n",
      "validate accuracy:\n",
      " [0.54261609 0.32930192 0.16471572 0.53898257 0.53263217 0.1364094\n",
      " 0.32858357 0.62711376 0.87272984 0.88008386 0.84375    0.47329\n",
      " 0.53984284 0.70592332 0.69500977 0.53321165 0.48027712] @epoch 65\n",
      "Epoch 066: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0216 - val_loss: 0.0243\n",
      "Counter: 4, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 67/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0216\n",
      "validate accuracy:\n",
      " [0.54212734 0.32887757 0.1645485  0.54157662 0.52859819 0.13775168\n",
      " 0.32879627 0.62480128 0.8723107  0.87686932 0.84389466 0.47286603\n",
      " 0.53970259 0.70522648 0.69528854 0.53236908 0.48055989] @epoch 66\n",
      "Epoch 067: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0216 - val_loss: 0.0243\n",
      "Counter: 5, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 68/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0216\n",
      "validate accuracy:\n",
      " [0.54136333 0.33142373 0.16521738 0.53898257 0.53162366 0.12634228\n",
      " 0.32688218 0.62277788 0.87398714 0.88008386 0.84534144 0.47215942\n",
      " 0.53675646 0.70355403 0.69403404 0.53222865 0.4804185 ] @epoch 67\n",
      "Epoch 068: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 211ms/step - loss: 0.0216 - val_loss: 0.0243\n",
      "Counter: 6, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 69/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0216\n",
      "validate accuracy:\n",
      " [0.54286095 0.32718015 0.16605352 0.54056782 0.53479326 0.13926175\n",
      " 0.32794556 0.62740278 0.87189162 0.87882602 0.84534144 0.47258338\n",
      " 0.53914142 0.70620209 0.69863397 0.53377336 0.47617701] @epoch 68\n",
      "Epoch 069: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 211ms/step - loss: 0.0216 - val_loss: 0.0243\n",
      "Counter: 7, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 069: Updating Learning rate.. New value is 0.000054\n",
      "Epoch 70/151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - ETA: 0s - loss: 0.0216\n",
      "validate accuracy:\n",
      " [0.54316221 0.33184808 0.16404682 0.53984725 0.53781873 0.14060403\n",
      " 0.32900894 0.62610203 0.87328863 0.88050312 0.8443287  0.47258338\n",
      " 0.53858024 0.70550525 0.6941734  0.53335208 0.47900465] @epoch 69\n",
      "Epoch 070: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0216 - val_loss: 0.0243\n",
      "Counter: 0, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 71/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0216\n",
      "validate accuracy:\n",
      " [0.54309593 0.32845321 0.16304348 0.53912669 0.53724247 0.1385906\n",
      " 0.3319864  0.62552392 0.87328863 0.88008386 0.8454861  0.47173545\n",
      " 0.53843993 0.70550525 0.69542795 0.53447551 0.48112541] @epoch 70\n",
      "Epoch 071: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0216 - val_loss: 0.0243\n",
      "Counter: 1, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 72/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0216\n",
      "validate accuracy:\n",
      " [0.54263814 0.32887757 0.16404682 0.53653264 0.53407288 0.1397651\n",
      " 0.33113569 0.62407863 0.87412685 0.8803634  0.84461808 0.47272471\n",
      " 0.53914142 0.70522648 0.69542795 0.53363293 0.47843912] @epoch 71\n",
      "Epoch 072: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0216 - val_loss: 0.0243\n",
      "Counter: 2, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 73/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0216\n",
      "validate accuracy:\n",
      " [0.5423675  0.32908976 0.16471572 0.5359562  0.53364068 0.13657717\n",
      " 0.33007231 0.62653565 0.87259012 0.87910551 0.84418404 0.47102883\n",
      " 0.53886086 0.70689893 0.69570673 0.53405422 0.47886327] @epoch 72\n",
      "Epoch 073: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0216 - val_loss: 0.0243\n",
      "Counter: 3, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 74/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0216\n",
      "validate accuracy:\n",
      " [0.54286291 0.33015063 0.16856188 0.53927076 0.53392881 0.13825503\n",
      " 0.32985964 0.62552392 0.87342834 0.87994409 0.84649885 0.47258338\n",
      " 0.5377385  0.70536584 0.69431281 0.53236908 0.47801498] @epoch 73\n",
      "Epoch 074: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 211ms/step - loss: 0.0216 - val_loss: 0.0243\n",
      "Counter: 4, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 75/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0216\n",
      "validate accuracy:\n",
      " [0.54287905 0.33142373 0.1680602  0.53927076 0.5329203  0.13808724\n",
      " 0.33241174 0.62494582 0.87426656 0.8796646  0.84461808 0.47230074\n",
      " 0.53717732 0.70620209 0.69319767 0.53194773 0.47957021] @epoch 74\n",
      "Epoch 075: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 211ms/step - loss: 0.0216 - val_loss: 0.0243\n",
      "Counter: 5, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 76/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54242926 0.32972628 0.16605352 0.53739733 0.53205591 0.13808724\n",
      " 0.33219907 0.62566847 0.87272984 0.87868625 0.8449074  0.47102883\n",
      " 0.53703701 0.70508713 0.69570673 0.53349251 0.47900465] @epoch 75\n",
      "Epoch 076: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 6, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 77/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.5426884  0.32824105 0.16404682 0.5372532  0.53349662 0.13808724\n",
      " 0.33071032 0.62422317 0.87370771 0.88050312 0.84534144 0.47244206\n",
      " 0.53801906 0.70564461 0.6959855  0.53531808 0.47999436] @epoch 76\n",
      "Epoch 077: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 211ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 7, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 077: Updating Learning rate.. New value is 0.000011\n",
      "Epoch 78/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54221168 0.32802886 0.16421404 0.53710908 0.53219998 0.13775168\n",
      " 0.32964694 0.62465674 0.87342834 0.87924528 0.84577549 0.47173545\n",
      " 0.5377385  0.70564461 0.69514912 0.53349251 0.47957021] @epoch 77\n",
      "Epoch 078: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 0, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 79/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54236483 0.32718015 0.1645485  0.53653264 0.53306442 0.1375839\n",
      " 0.33071032 0.62436765 0.87286949 0.87938505 0.84461808 0.47272471\n",
      " 0.53815937 0.70634145 0.69570673 0.53461593 0.47942883] @epoch 78\n",
      "Epoch 079: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 1, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 80/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54264127 0.32930192 0.16421404 0.5372532  0.53407288 0.13926175\n",
      " 0.33071032 0.62610203 0.87314892 0.88008386 0.84505206 0.47088751\n",
      " 0.53787881 0.704669   0.694731   0.53461593 0.48027712] @epoch 79\n",
      "Epoch 080: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 2, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 81/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54265801 0.32951412 0.16538462 0.53739733 0.53392881 0.13825503\n",
      " 0.33134836 0.62581301 0.87314892 0.87994409 0.84403938 0.4714528\n",
      " 0.53745788 0.704669   0.69542795 0.53531808 0.47942883] @epoch 80\n",
      "Epoch 081: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 3, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 82/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54287995 0.32887757 0.16605352 0.53797376 0.53320849 0.13959731\n",
      " 0.33028498 0.62595749 0.8730092  0.88064289 0.84519678 0.47046354\n",
      " 0.53858024 0.70592332 0.69612491 0.53475636 0.47942883] @epoch 81\n",
      "Epoch 082: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 211ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 4, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 83/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54250696 0.33015063 0.16521738 0.5385502  0.53335255 0.1385906\n",
      " 0.32964694 0.62523484 0.87356806 0.87952483 0.84519678 0.4714528\n",
      " 0.53787881 0.70452964 0.69528854 0.53391379 0.47801498] @epoch 82\n",
      "Epoch 083: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 5, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 84/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54230885 0.33036283 0.1645485  0.53826201 0.5329203  0.1375839\n",
      " 0.33007231 0.62494582 0.87272984 0.87910551 0.84505206 0.47159413\n",
      " 0.53689677 0.70536584 0.69570673 0.53279036 0.47900465] @epoch 83\n",
      "Epoch 084: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 6, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 85/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54222825 0.32930192 0.16438127 0.53667676 0.53320849 0.13775168\n",
      " 0.32985964 0.62552392 0.87342834 0.87952483 0.84505206 0.47046354\n",
      " 0.53731763 0.70480835 0.694731   0.53433508 0.47928745] @epoch 84\n",
      "Epoch 085: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 211ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 7, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 085: Updating Learning rate.. New value is 0.000002\n",
      "Epoch 86/151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.5428246  0.32866541 0.16622074 0.53782964 0.53277624 0.13825503\n",
      " 0.33134836 0.62696922 0.8730092  0.87938505 0.84447336 0.47173545\n",
      " 0.53815937 0.70689893 0.69584614 0.53447551 0.47914603] @epoch 85\n",
      "Epoch 086: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 211ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 0, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 87/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54271016 0.32845321 0.16605352 0.53682089 0.53320849 0.13775168\n",
      " 0.32985964 0.62465674 0.87314892 0.87924528 0.84649885 0.47117016\n",
      " 0.5364759  0.70703834 0.6965431  0.53616065 0.48027712] @epoch 86\n",
      "Epoch 087: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 211ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 1, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 88/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.542744   0.32866541 0.16571906 0.53999138 0.53349662 0.13926175\n",
      " 0.33134836 0.62465674 0.87328863 0.87910551 0.84505206 0.47201809\n",
      " 0.53731763 0.70620209 0.69570673 0.53335208 0.47872189] @epoch 87\n",
      "Epoch 088: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 2, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 89/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54263376 0.32866541 0.16605352 0.53739733 0.53219998 0.13657717\n",
      " 0.33028498 0.62639111 0.87342834 0.8803634  0.84534144 0.47187677\n",
      " 0.5377385  0.70606273 0.69514912 0.53461593 0.47999436] @epoch 88\n",
      "Epoch 089: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 211ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 3, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 90/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54269688 0.32845321 0.16471572 0.53826201 0.53464919 0.13892618\n",
      " 0.33241174 0.62639111 0.8730092  0.87910551 0.84389466 0.47215942\n",
      " 0.53717732 0.70592332 0.69500977 0.53363293 0.47942883] @epoch 89\n",
      "Epoch 090: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 4, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 91/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54246627 0.32908976 0.1645485  0.53667676 0.53277624 0.13775168\n",
      " 0.33049765 0.62581301 0.87328863 0.87952483 0.84505206 0.4714528\n",
      " 0.53717732 0.70648086 0.69556731 0.53447551 0.47928745] @epoch 90\n",
      "Epoch 091: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 5, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 92/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54248546 0.32845321 0.16505016 0.53739733 0.53407288 0.13775168\n",
      " 0.33071032 0.62639111 0.87342834 0.87896574 0.84563076 0.47117016\n",
      " 0.53689677 0.70550525 0.69528854 0.53461593 0.47843912] @epoch 91\n",
      "Epoch 092: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 121s 211ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 6, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 93/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.542639   0.32866541 0.1645485  0.53768557 0.53349662 0.1375839\n",
      " 0.33113569 0.62552392 0.87426656 0.87994409 0.8454861  0.47187677\n",
      " 0.53633559 0.70675957 0.69542795 0.53335208 0.48013574] @epoch 92\n",
      "Epoch 093: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 121s 211ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 7, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 093: Updating Learning rate.. New value is 0.000000\n",
      "Epoch 94/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54258249 0.32972628 0.1645485  0.53739733 0.53320849 0.13791946\n",
      " 0.33049765 0.62668014 0.8730092  0.87896574 0.84534144 0.4714528\n",
      " 0.53801906 0.70522648 0.69570673 0.53461593 0.47900465] @epoch 93\n",
      "Epoch 094: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 211ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 0, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 95/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54256241 0.32887757 0.16555184 0.53754145 0.53248811 0.13724832\n",
      " 0.32985964 0.62653565 0.8730092  0.88022363 0.84534144 0.47187677\n",
      " 0.53759819 0.70550525 0.69445217 0.53517765 0.47971159] @epoch 94\n",
      "Epoch 095: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 1, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 96/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54258648 0.32908976 0.1645485  0.5385502  0.53205591 0.13909397\n",
      " 0.33007231 0.62610203 0.87342834 0.87952483 0.84447336 0.47215942\n",
      " 0.53829968 0.70564461 0.69514912 0.53531808 0.47787359] @epoch 95\n",
      "Epoch 096: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 2, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 97/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54242728 0.32739231 0.16638796 0.53768557 0.53176779 0.13724832\n",
      " 0.33092302 0.62523484 0.87342834 0.87924528 0.84563076 0.47173545\n",
      " 0.53745788 0.70606273 0.69487035 0.53405422 0.47971159] @epoch 96\n",
      "Epoch 097: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 3, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 98/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.5423165  0.32845321 0.16538462 0.53624439 0.53306442 0.13741611\n",
      " 0.33049765 0.62465674 0.87384742 0.87980431 0.84534144 0.47173545\n",
      " 0.53675646 0.70522648 0.694731   0.53447551 0.47942883] @epoch 97\n",
      "Epoch 098: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 4, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 99/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54247379 0.32887757 0.16622074 0.53667676 0.53263217 0.13741611\n",
      " 0.33049765 0.62523484 0.87314892 0.8796646  0.84505206 0.47131148\n",
      " 0.53787881 0.70634145 0.69500977 0.53503722 0.4785805 ] @epoch 98\n",
      "Epoch 099: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 5, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 100/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54223172 0.32718015 0.16521738 0.53941488 0.5314796  0.13724832\n",
      " 0.32985964 0.62610203 0.87370771 0.87910551 0.8449074  0.47032222\n",
      " 0.53759819 0.7071777  0.69431281 0.53335208 0.47872189] @epoch 99\n",
      "Epoch 100: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 6, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 101/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54254594 0.32972628 0.1645485  0.53782964 0.53335255 0.13775168\n",
      " 0.33177373 0.62624657 0.87286949 0.87924528 0.84461808 0.47272471\n",
      " 0.53703701 0.70536584 0.694731   0.53447551 0.47843912] @epoch 100\n",
      "Epoch 101: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 211ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 7, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 101: Updating Learning rate.. New value is 0.000000\n",
      "Epoch 102/151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54261652 0.32824105 0.16354515 0.53768557 0.53407288 0.13791946\n",
      " 0.33156103 0.62595749 0.87342834 0.87924528 0.84461808 0.47357264\n",
      " 0.53745788 0.70606273 0.694731   0.53405422 0.47971159] @epoch 101\n",
      "Epoch 102: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 0, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 103/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54271274 0.32802886 0.1667224  0.53811789 0.53407288 0.13926175\n",
      " 0.33092302 0.62494582 0.87286949 0.87938505 0.84476274 0.47187677\n",
      " 0.53717732 0.70550525 0.69528854 0.53503722 0.47942883] @epoch 102\n",
      "Epoch 103: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 1, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 104/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.5426587  0.32972628 0.16555184 0.53797376 0.53306442 0.13842282\n",
      " 0.33092302 0.62610203 0.8730092  0.87924528 0.8449074  0.47159413\n",
      " 0.53731763 0.70564461 0.69431281 0.53573936 0.47900465] @epoch 103\n",
      "Epoch 104: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 2, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 105/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54240201 0.32718015 0.16521738 0.53840613 0.5329203  0.13724832\n",
      " 0.33156103 0.62610203 0.87328863 0.87938505 0.84519678 0.47131148\n",
      " 0.53675646 0.70592332 0.69459158 0.53377336 0.47957021] @epoch 104\n",
      "Epoch 105: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 3, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 106/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54258171 0.32824105 0.16438127 0.53768557 0.53277624 0.13808724\n",
      " 0.3319864  0.62624657 0.87272984 0.87910551 0.8449074  0.47272471\n",
      " 0.53759819 0.70662022 0.69431281 0.53447551 0.47942883] @epoch 105\n",
      "Epoch 106: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 4, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 107/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54254328 0.32887757 0.16438127 0.5385502  0.53349662 0.13791946\n",
      " 0.33156103 0.62639111 0.8730092  0.87910551 0.84519678 0.47102883\n",
      " 0.5364759  0.70522648 0.69570673 0.53405422 0.47971159] @epoch 106\n",
      "Epoch 107: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 5, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 108/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54239843 0.32824105 0.16438127 0.53912669 0.53248811 0.13775168\n",
      " 0.33113569 0.62783641 0.87328863 0.8796646  0.84563076 0.47046354\n",
      " 0.53731763 0.70522648 0.6941734  0.53349251 0.47815636] @epoch 107\n",
      "Epoch 108: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 6, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 109/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54246223 0.32972628 0.16438127 0.53782964 0.53364068 0.13909397\n",
      " 0.33134836 0.62639111 0.87314892 0.87980431 0.84461808 0.47230074\n",
      " 0.53549385 0.70439023 0.69445217 0.53405422 0.47872189] @epoch 108\n",
      "Epoch 109: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 7, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 109: Updating Learning rate.. New value is 0.000000\n",
      "Epoch 110/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54285154 0.32951412 0.16655518 0.53696495 0.53407288 0.1375839\n",
      " 0.33113569 0.62552392 0.87342834 0.8796646  0.84534144 0.47187677\n",
      " 0.5377385  0.7071777  0.69528854 0.53517765 0.4785805 ] @epoch 109\n",
      "Epoch 110: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 0, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 111/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54278359 0.32908976 0.16622074 0.53797376 0.53392881 0.13808724\n",
      " 0.32985964 0.62566847 0.87286949 0.87994409 0.8449074  0.47215942\n",
      " 0.5377385  0.70662022 0.69542795 0.53503722 0.47900465] @epoch 110\n",
      "Epoch 111: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 211ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 1, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 112/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54259548 0.32845321 0.16471572 0.53782964 0.53335255 0.13875839\n",
      " 0.3319864  0.62509036 0.87272984 0.88022363 0.84505206 0.47244206\n",
      " 0.53717732 0.704669   0.69556731 0.53447551 0.47900465] @epoch 111\n",
      "Epoch 112: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 121s 211ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 2, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 113/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54270409 0.32887757 0.16538462 0.53768557 0.53248811 0.13741611\n",
      " 0.33092302 0.62465674 0.87328863 0.88022363 0.84563076 0.47272471\n",
      " 0.53815937 0.70536584 0.6965431  0.53545851 0.47843912] @epoch 112\n",
      "Epoch 113: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 3, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 114/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54240352 0.32781667 0.16421404 0.53739733 0.53277624 0.1375839\n",
      " 0.33071032 0.62523484 0.87286949 0.87952483 0.8443287  0.47230074\n",
      " 0.53745788 0.70592332 0.69556731 0.53475636 0.47999436] @epoch 113\n",
      "Epoch 114: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 211ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 4, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 115/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54259629 0.32845321 0.16605352 0.53840613 0.53248811 0.13909397\n",
      " 0.33156103 0.62624657 0.87272984 0.87910551 0.84534144 0.47102883\n",
      " 0.53661615 0.70550525 0.69528854 0.53433508 0.47928745] @epoch 114\n",
      "Epoch 115: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 211ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 5, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 116/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54254771 0.32951412 0.16488294 0.53797376 0.53320849 0.13842282\n",
      " 0.33071032 0.62653565 0.87356806 0.87910551 0.84505206 0.4714528\n",
      " 0.53633559 0.70480835 0.69542795 0.53419465 0.47957021] @epoch 115\n",
      "Epoch 116: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 6, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 117/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54262601 0.33057502 0.16337793 0.53754145 0.53407288 0.13808724\n",
      " 0.33134836 0.62566847 0.87314892 0.87938505 0.84505206 0.47159413\n",
      " 0.5377385  0.70606273 0.69403404 0.53433508 0.47999436] @epoch 116\n",
      "Epoch 117: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 7, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 117: Updating Learning rate.. New value is 0.000000\n",
      "Epoch 118/151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54278704 0.32887757 0.16571906 0.53869432 0.53335255 0.13875839\n",
      " 0.33134836 0.62610203 0.87342834 0.87882602 0.84461808 0.47230074\n",
      " 0.53717732 0.70564461 0.69668245 0.53349251 0.47957021] @epoch 117\n",
      "Epoch 118: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 211ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 0, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 119/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54280886 0.32866541 0.16371237 0.53883845 0.53378475 0.13926175\n",
      " 0.33049765 0.62480128 0.8730092  0.88022363 0.8443287  0.47286603\n",
      " 0.53801906 0.70592332 0.69640368 0.53517765 0.47942883] @epoch 118\n",
      "Epoch 119: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 211ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 1, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 120/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.542647   0.32845321 0.16538462 0.53768557 0.53133553 0.13825503\n",
      " 0.33156103 0.62595749 0.87370771 0.88022363 0.8449074  0.47131148\n",
      " 0.53829968 0.70578396 0.69445217 0.53475636 0.48027712] @epoch 119\n",
      "Epoch 120: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 211ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 2, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 121/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54238869 0.32802886 0.16521738 0.53754145 0.53306442 0.1385906\n",
      " 0.33092302 0.62523484 0.87314892 0.87924528 0.8443287  0.47117016\n",
      " 0.53633559 0.70634145 0.69584614 0.53377336 0.47942883] @epoch 120\n",
      "Epoch 121: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 3, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 122/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54264374 0.32739231 0.16521738 0.53754145 0.53320849 0.13791946\n",
      " 0.33092302 0.62552392 0.87259012 0.87952483 0.8449074  0.47201809\n",
      " 0.53787881 0.70536584 0.69570673 0.53573936 0.48084265] @epoch 121\n",
      "Epoch 122: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 211ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 4, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 123/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54267663 0.32887757 0.16622074 0.5385502  0.53407288 0.13708054\n",
      " 0.33113569 0.62581301 0.87286949 0.87910551 0.8454861  0.47187677\n",
      " 0.53619528 0.70634145 0.69459158 0.53475636 0.47985297] @epoch 122\n",
      "Epoch 123: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 211ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 5, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 124/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.5424666  0.32718015 0.16505016 0.53840613 0.5329203  0.13691275\n",
      " 0.33156103 0.62581301 0.87342834 0.87910551 0.84577549 0.47117016\n",
      " 0.5377385  0.70648086 0.69528854 0.53405422 0.4785805 ] @epoch 123\n",
      "Epoch 124: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 211ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 6, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 125/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54258283 0.33015063 0.16438127 0.53883845 0.53335255 0.13808724\n",
      " 0.33113569 0.6272583  0.87259012 0.87868625 0.84519678 0.47187677\n",
      " 0.53745788 0.70522648 0.69459158 0.53377336 0.47872189] @epoch 124\n",
      "Epoch 125: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 211ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 7, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 125: Updating Learning rate.. New value is 0.000000\n",
      "Epoch 126/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54262841 0.32866541 0.16471572 0.53869432 0.53320849 0.13808724\n",
      " 0.33113569 0.62552392 0.87356806 0.87952483 0.8449074  0.47201809\n",
      " 0.53717732 0.70634145 0.69570673 0.53349251 0.47928745] @epoch 125\n",
      "Epoch 126: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 211ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 0, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 127/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54239746 0.32866541 0.1632107  0.53638852 0.53407288 0.13926175\n",
      " 0.33156103 0.62610203 0.87342834 0.87994409 0.8449074  0.47117016\n",
      " 0.53717732 0.70452964 0.69431281 0.53363293 0.47999436] @epoch 126\n",
      "Epoch 127: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 1, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 128/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54238328 0.32866541 0.16505016 0.53782964 0.53234404 0.13791946\n",
      " 0.32985964 0.62566847 0.87272984 0.87924528 0.84577549 0.47088751\n",
      " 0.53689677 0.70578396 0.69500977 0.53489679 0.47957021] @epoch 127\n",
      "Epoch 128: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 2, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 129/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54258125 0.32887757 0.16538462 0.53739733 0.53364068 0.13791946\n",
      " 0.33177373 0.62610203 0.87356806 0.87910551 0.84476274 0.47187677\n",
      " 0.53745788 0.70522648 0.69487035 0.53475636 0.4785805 ] @epoch 128\n",
      "Epoch 129: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 3, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 130/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.5429592  0.32930192 0.16488294 0.53811789 0.53479326 0.13892618\n",
      " 0.33134836 0.62610203 0.87328863 0.88022363 0.84534144 0.47272471\n",
      " 0.5377385  0.70564461 0.69500977 0.53461593 0.47928745] @epoch 129\n",
      "Epoch 130: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 211ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 4, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 131/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54254476 0.32866541 0.16505016 0.53840613 0.534217   0.1385906\n",
      " 0.32985964 0.62682468 0.87328863 0.87938505 0.84563076 0.47060487\n",
      " 0.53661615 0.70522648 0.694731   0.53475636 0.47886327] @epoch 130\n",
      "Epoch 131: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 211ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 5, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 132/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54264944 0.32951412 0.16538462 0.53797376 0.53349662 0.13791946\n",
      " 0.33049765 0.62682468 0.87356806 0.87924528 0.84534144 0.47187677\n",
      " 0.53745788 0.70578396 0.69542795 0.53264993 0.47942883] @epoch 131\n",
      "Epoch 132: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 6, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 133/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54275872 0.32972628 0.16404682 0.53840613 0.53234404 0.1385906\n",
      " 0.33177373 0.62581301 0.87384742 0.8796646  0.84461808 0.47343132\n",
      " 0.53731763 0.70578396 0.69459158 0.53489679 0.47928745] @epoch 132\n",
      "Epoch 133: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 7, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 133: Updating Learning rate.. New value is 0.000000\n",
      "Epoch 134/151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54245267 0.32930192 0.16555184 0.53883845 0.5314796  0.1364094\n",
      " 0.33134836 0.62581301 0.8730092  0.87882602 0.84534144 0.47230074\n",
      " 0.53619528 0.70662022 0.69487035 0.53475636 0.4785805 ] @epoch 133\n",
      "Epoch 134: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 0, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 135/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54252432 0.32824105 0.1632107  0.53682089 0.53306442 0.13724832\n",
      " 0.33071032 0.62595749 0.87398714 0.8796646  0.8454861  0.47215942\n",
      " 0.5377385  0.70578396 0.69542795 0.53531808 0.47957021] @epoch 134\n",
      "Epoch 135: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 1, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 136/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54270627 0.32802886 0.16521738 0.53667676 0.53335255 0.13892618\n",
      " 0.33113569 0.62610203 0.8730092  0.87924528 0.84505206 0.47230074\n",
      " 0.53787881 0.70606273 0.6959855  0.53475636 0.47957021] @epoch 135\n",
      "Epoch 136: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 2, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 137/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54214929 0.32866541 0.16588628 0.53739733 0.53162366 0.13724832\n",
      " 0.33007231 0.62422317 0.87259012 0.87924528 0.84620947 0.47173545\n",
      " 0.53661615 0.70620209 0.69403404 0.53335208 0.47928745] @epoch 136\n",
      "Epoch 137: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 211ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 3, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 138/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54261369 0.32930192 0.16505016 0.53682089 0.53277624 0.13741611\n",
      " 0.33049765 0.62566847 0.87370771 0.8803634  0.84534144 0.47131148\n",
      " 0.53801906 0.70550525 0.69514912 0.53503722 0.47985297] @epoch 137\n",
      "Epoch 138: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 211ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 4, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 139/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54226766 0.32824105 0.16505016 0.53754145 0.53119147 0.1385906\n",
      " 0.33092302 0.62494582 0.87370771 0.87938505 0.84563076 0.47074619\n",
      " 0.53717732 0.70536584 0.694731   0.53461593 0.47843912] @epoch 138\n",
      "Epoch 139: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 5, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 140/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54267481 0.32993847 0.16471572 0.53710908 0.53335255 0.13808724\n",
      " 0.33092302 0.62537938 0.87370771 0.88022363 0.84505206 0.47159413\n",
      " 0.53731763 0.70564461 0.69528854 0.53545851 0.47900465] @epoch 139\n",
      "Epoch 140: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 211ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 6, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 141/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54246787 0.32845321 0.16588628 0.53797376 0.53263217 0.13808724\n",
      " 0.33156103 0.62480128 0.87286949 0.87924528 0.84519678 0.4714528\n",
      " 0.53731763 0.70522648 0.69459158 0.53391379 0.48027712] @epoch 140\n",
      "Epoch 141: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 211ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 7, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 141: Updating Learning rate.. New value is 0.000000\n",
      "Epoch 142/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54277424 0.32866541 0.16421404 0.53782964 0.53306442 0.13808724\n",
      " 0.33113569 0.62639111 0.87342834 0.8803634  0.84563076 0.47230074\n",
      " 0.5377385  0.70578396 0.69528854 0.53503722 0.47942883] @epoch 141\n",
      "Epoch 142: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 0, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 143/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.5424854  0.3276045  0.16421404 0.53811789 0.53003889 0.13775168\n",
      " 0.33113569 0.6245122  0.87356806 0.88050312 0.8454861  0.47187677\n",
      " 0.53829968 0.70606273 0.69570673 0.53531808 0.47957021] @epoch 142\n",
      "Epoch 143: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 1, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 144/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54275734 0.32845321 0.16521738 0.53797376 0.53335255 0.13741611\n",
      " 0.33049765 0.62537938 0.87328863 0.87938505 0.84519678 0.47215942\n",
      " 0.53745788 0.70606273 0.6965431  0.53573936 0.47999436] @epoch 143\n",
      "Epoch 144: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 2, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 145/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54298077 0.32887757 0.16505016 0.5385502  0.53320849 0.1385906\n",
      " 0.33049765 0.62624657 0.87342834 0.88008386 0.8449074  0.47314867\n",
      " 0.53829968 0.70508713 0.69668245 0.53475636 0.48027712] @epoch 144\n",
      "Epoch 145: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 3, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 146/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54288215 0.32972628 0.16438127 0.53955901 0.534217   0.13959731\n",
      " 0.33049765 0.62537938 0.87259012 0.87924528 0.84519678 0.47314867\n",
      " 0.53829968 0.70536584 0.69542795 0.53419465 0.47928745] @epoch 145\n",
      "Epoch 146: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 4, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 147/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54256215 0.32887757 0.16555184 0.53811789 0.53205591 0.13791946\n",
      " 0.33071032 0.62696922 0.87342834 0.87994409 0.84606481 0.47046354\n",
      " 0.5364759  0.70564461 0.69487035 0.53503722 0.47886327] @epoch 146\n",
      "Epoch 147: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 211ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 5, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 148/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54236907 0.32908976 0.16471572 0.5372532  0.53234404 0.13708054\n",
      " 0.33113569 0.62566847 0.8730092  0.87938505 0.84461808 0.47060487\n",
      " 0.53759819 0.70606273 0.69445217 0.53545851 0.47942883] @epoch 147\n",
      "Epoch 148: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 6, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 149/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54237108 0.32696795 0.16538462 0.53768557 0.53248811 0.13708054\n",
      " 0.33071032 0.62624657 0.87272984 0.88022363 0.84635419 0.47102883\n",
      " 0.53689677 0.70592332 0.69445217 0.53419465 0.47957021] @epoch 148\n",
      "Epoch 149: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 211ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 7, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 149: Updating Learning rate.. New value is 0.000000\n",
      "Epoch 150/151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54274725 0.33036283 0.16571906 0.53840613 0.53248811 0.13691275\n",
      " 0.33049765 0.62552392 0.87272984 0.87994409 0.84620947 0.47300735\n",
      " 0.53703701 0.704669   0.69570673 0.53602022 0.47872189] @epoch 149\n",
      "Epoch 150: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Counter: 0, Global: 0.5472063794732094, MyBest: 0.5472063794732094\n",
      "\n",
      "Epoch 151/151\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0215\n",
      "validate accuracy:\n",
      " [0.54257291 0.32930192 0.16505016 0.53797376 0.5329203  0.13842282\n",
      " 0.33092302 0.62480128 0.87370771 0.87938505 0.84592015 0.47131148\n",
      " 0.53787881 0.70550525 0.69487035 0.53489679 0.47829774] @epoch 150\n",
      "Epoch 151: val_acc did not improve from 0.547\n",
      "576/576 [==============================] - 122s 212ms/step - loss: 0.0215 - val_loss: 0.0243\n"
     ]
    }
   ],
   "source": [
    "\n",
    "net.compile(optimizer=optimizer, loss=weighted_mse_loss, metrics=[])\n",
    "#checkpointer = ModelCheckpoint(filepath=f'../cunet{nUNet}_{m}{n}_best.h5', verbose=1, monitor='val_loss', mode='auto', save_best_only=True)\n",
    "history = net.fit(train_images,train_hms,validation_data=(eval_images,eval_hms2),epochs=151, batch_size=32,shuffle=True,verbose=1, callbacks=[evalcallback,updateLR])#,use_multiprocessing=True,workers=20)#[checkpointer,updateLR])\n",
    "#np.savez_compressed(\"../history\",history)\n",
    "net.save_weights(f'../cunet{nUNet}_{m}{n}_last_sigmoidAdamQuasiDef3sx12_restartsig3.h5', overwrite=True)\n",
    "np.save('../history_sigmoidAdamQuasiDef3sx12_restartsig3.npy',history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnet.load_weights(\"../cunet2_6416_last_sigmoidAdamQuasiDef3sx12.h5\")\\noutput = net.predict(train_images)\\noutput = np.transpose(output,(0,3,1,2))\\nprint(accuracy(output,np.transpose(train_hms,(0,3,1,2))))\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "net.load_weights(\"../cunet2_6416_last_sigmoidAdamQuasiDef3sx12.h5\")\n",
    "output = net.predict(train_images)\n",
    "output = np.transpose(output,(0,3,1,2))\n",
    "print(accuracy(output,np.transpose(train_hms,(0,3,1,2))))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ho aumentato solo patience \n",
    "#Provato con dropout ma andato male"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
