{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EvalPCK.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BG3sDuEWVMYk"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_normalize(input_shape):\n",
        "    \"\"\"\n",
        "    rescale keypoint distance normalize coefficient\n",
        "    based on input shape, used for PCK evaluation\n",
        "    NOTE: 6.4 is standard normalize coefficient under\n",
        "          input shape (256,256)\n",
        "    # Arguments\n",
        "        input_shape: input image shape as (height, width)\n",
        "    # Returns\n",
        "        scale: normalize coefficient\n",
        "    \"\"\"\n",
        "    #assert input_shape[0] == input_shape[1], 'only support square input shape.'\n",
        "\n",
        "    # use averaged scale factor for non square input shape\n",
        "    scale = float((input_shape[0] + input_shape[1]) / 2) / 256.0\n",
        "\n",
        "    return 6.4*scale\n",
        "\n",
        "class EvalCallBack(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, class_names, model_input_shape):\n",
        "        self.normalize = get_normalize(model_input_shape)\n",
        "        self.model_input_shape = model_input_shape\n",
        "        self.best_acc = 0.0\n",
        "\n",
        "        self.eval_images = np.load(\"../images_val_mpii\")\n",
        "        self.eval_hms = np.load(\"../hms_val_mpii\")\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        output = self.model.predict(self.eval_images)\n",
        "        print(output.shape)\n",
        "        output = output.reshape( (output.shape[0],)+(16,64,64) )\n",
        "        val_acc = accuracy(self.model)\n",
        "        print('validate accuray', val_acc, '@epoch', epoch)\n",
        "\n",
        "        if val_acc > self.best_acc:\n",
        "            # Save best accuray value and model checkpoint\n",
        "            checkpoint_dir = os.path.join(self.log_dir, 'ep{epoch:03d}-loss{loss:.3f}-val_acc{val_acc:.3f}.h5'.format(epoch=(epoch+1), loss=logs.get('loss'), val_acc=val_acc))\n",
        "            self.model.save(checkpoint_dir)\n",
        "            print('Epoch {epoch:03d}: val_acc improved from {best_acc:.3f} to {val_acc:.3f}, saving model to {checkpoint_dir}'.format(epoch=epoch+1, best_acc=self.best_acc, val_acc=val_acc, checkpoint_dir=checkpoint_dir))\n",
        "            self.best_acc = val_acc\n",
        "        else:\n",
        "            print('Epoch {epoch:03d}: val_acc did not improve from {best_acc:.3f}'.format(epoch=epoch+1, best_acc=self.best_acc))"
      ],
      "metadata": {
        "id": "kjkpcZDdVaPs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}